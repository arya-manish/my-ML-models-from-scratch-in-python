{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 2D Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Apple/anaconda3/envs/Arya/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Sigmoid_Necessary_Functions_With_Regularization import *\n",
    "from Regularized_Gradient_Checker import *\n",
    "from Load_2D_Dataset import load_2D_dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = load_2D_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has shape :(2, 211)\n",
      "Y_train has shape :(1, 211)\n",
      "X_test has shape :(2, 200)\n",
      "Y_test has shape :(2, 200)\n"
     ]
    }
   ],
   "source": [
    "print('X_train has shape :' +str(X_train.shape))\n",
    "print('Y_train has shape :' +str(Y_train.shape))\n",
    "print('X_test has shape :' +str(X_test.shape))\n",
    "print('Y_test has shape :' +str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 0 epochs is 0.7998897120446063\n",
      "cost after 100 epochs is 0.6919564015492935\n",
      "cost after 200 epochs is 0.5758344151591623\n",
      "cost after 300 epochs is 0.48979717565598224\n",
      "cost after 400 epochs is 0.43097751266957385\n",
      "cost after 500 epochs is 0.39593870354149874\n",
      "cost after 600 epochs is 0.3762795176248187\n",
      "cost after 700 epochs is 0.36561956512192495\n",
      "cost after 800 epochs is 0.35943901711606874\n",
      "cost after 900 epochs is 0.3553624107422738\n",
      "cost after 1000 epochs is 0.35217798310913395\n",
      "cost after 1100 epochs is 0.3493435141149546\n",
      "cost after 1200 epochs is 0.34661077138853513\n",
      "cost after 1300 epochs is 0.34409118210310097\n",
      "cost after 1400 epochs is 0.34180596596180757\n",
      "cost after 1500 epochs is 0.33976026556914285\n",
      "cost after 1600 epochs is 0.337822006289182\n",
      "cost after 1700 epochs is 0.336036587808478\n",
      "cost after 1800 epochs is 0.3343639418742532\n",
      "cost after 1900 epochs is 0.33275961854703395\n",
      "cost after 2000 epochs is 0.3312061716292579\n",
      "cost after 2100 epochs is 0.3296732619185906\n",
      "cost after 2200 epochs is 0.32815008223805736\n",
      "cost after 2300 epochs is 0.3266626689665776\n",
      "cost after 2400 epochs is 0.3252404183745854\n",
      "cost after 2500 epochs is 0.323908076287107\n",
      "cost after 2600 epochs is 0.32260754646413187\n",
      "cost after 2700 epochs is 0.3213379603824783\n",
      "cost after 2800 epochs is 0.3200991452104492\n",
      "cost after 2900 epochs is 0.3188936387945514\n",
      "cost after 3000 epochs is 0.3177144433301961\n",
      "cost after 3100 epochs is 0.3165643218816214\n",
      "cost after 3200 epochs is 0.315458083060981\n",
      "cost after 3300 epochs is 0.3143751018681674\n",
      "cost after 3400 epochs is 0.3133197931683467\n",
      "cost after 3500 epochs is 0.3122898375842813\n",
      "cost after 3600 epochs is 0.31128479455004343\n",
      "cost after 3700 epochs is 0.3103027111380434\n",
      "cost after 3800 epochs is 0.3093425671943835\n",
      "cost after 3900 epochs is 0.30840342638641516\n",
      "cost after 4000 epochs is 0.3074879843586671\n",
      "cost after 4100 epochs is 0.3065939286873639\n",
      "cost after 4200 epochs is 0.3057202964251837\n",
      "cost after 4300 epochs is 0.3048668976051081\n",
      "cost after 4400 epochs is 0.30403135876681747\n",
      "cost after 4500 epochs is 0.30321407942272116\n",
      "cost after 4600 epochs is 0.3024153022500746\n",
      "cost after 4700 epochs is 0.30163485315904903\n",
      "cost after 4800 epochs is 0.30087226058325056\n",
      "cost after 4900 epochs is 0.30012676555030915\n",
      "cost after 5000 epochs is 0.2993876746832313\n",
      "cost after 5100 epochs is 0.2986663288665382\n",
      "cost after 5200 epochs is 0.2979691249679891\n",
      "cost after 5300 epochs is 0.2972904884356833\n",
      "cost after 5400 epochs is 0.29662765993482115\n",
      "cost after 5500 epochs is 0.2959815697159996\n",
      "cost after 5600 epochs is 0.29534624926039893\n",
      "cost after 5700 epochs is 0.29472579983797254\n",
      "cost after 5800 epochs is 0.2941216311261839\n",
      "cost after 5900 epochs is 0.2935310239956575\n",
      "cost after 6000 epochs is 0.2929540227046384\n",
      "cost after 6100 epochs is 0.2923914935723114\n",
      "cost after 6200 epochs is 0.29184140695628613\n",
      "cost after 6300 epochs is 0.2913039135996184\n",
      "cost after 6400 epochs is 0.29077719586461365\n",
      "cost after 6500 epochs is 0.29026111097968726\n",
      "cost after 6600 epochs is 0.28975740132858724\n",
      "cost after 6700 epochs is 0.2892652653662591\n",
      "cost after 6800 epochs is 0.2887832753986237\n",
      "cost after 6900 epochs is 0.28831463004515556\n",
      "cost after 7000 epochs is 0.2878582673034903\n",
      "cost after 7100 epochs is 0.28741257225209554\n",
      "cost after 7200 epochs is 0.28697607958041094\n",
      "cost after 7300 epochs is 0.2865503214283767\n",
      "cost after 7400 epochs is 0.2861339874597904\n",
      "cost after 7500 epochs is 0.2857249214945609\n",
      "cost after 7600 epochs is 0.2853248664848297\n",
      "cost after 7700 epochs is 0.28493433994960793\n",
      "cost after 7800 epochs is 0.2845525422067615\n",
      "cost after 7900 epochs is 0.284179682783118\n",
      "cost after 8000 epochs is 0.28381614829178625\n",
      "cost after 8100 epochs is 0.2834585519468442\n",
      "cost after 8200 epochs is 0.28310991812216657\n",
      "cost after 8300 epochs is 0.28276831841564287\n",
      "cost after 8400 epochs is 0.28243441094190735\n",
      "cost after 8500 epochs is 0.2821081603934577\n",
      "cost after 8600 epochs is 0.28178897805281233\n",
      "cost after 8700 epochs is 0.2814775001636673\n",
      "cost after 8800 epochs is 0.28117187445440844\n",
      "cost after 8900 epochs is 0.28087271250272844\n",
      "cost after 9000 epochs is 0.28057995426967813\n",
      "cost after 9100 epochs is 0.2802948123232999\n",
      "cost after 9200 epochs is 0.2800152819025557\n",
      "cost after 9300 epochs is 0.279743043203461\n",
      "cost after 9400 epochs is 0.2794751855549927\n",
      "cost after 9500 epochs is 0.2792158695810637\n",
      "cost after 9600 epochs is 0.27896068566061827\n",
      "cost after 9700 epochs is 0.2787103082226518\n",
      "cost after 9800 epochs is 0.2784676836249545\n",
      "cost after 9900 epochs is 0.27822733681425177\n",
      "cost after 10000 epochs is 0.27799436726505683\n",
      "cost after 10100 epochs is 0.2777660128215931\n",
      "cost after 10200 epochs is 0.277544520111755\n",
      "cost after 10300 epochs is 0.27732608655055396\n",
      "cost after 10400 epochs is 0.2771137217331977\n",
      "cost after 10500 epochs is 0.27690431502660523\n",
      "cost after 10600 epochs is 0.2767021392346712\n",
      "cost after 10700 epochs is 0.27650296826457643\n",
      "cost after 10800 epochs is 0.2763073302808026\n",
      "cost after 10900 epochs is 0.27611611396346186\n",
      "cost after 11000 epochs is 0.27592654970972064\n",
      "cost after 11100 epochs is 0.2757416941696812\n",
      "cost after 11200 epochs is 0.2755594687394275\n",
      "cost after 11300 epochs is 0.2753743943074707\n",
      "cost after 11400 epochs is 0.2751948816630361\n",
      "cost after 11500 epochs is 0.27501940761682586\n",
      "cost after 11600 epochs is 0.274847152232741\n",
      "cost after 11700 epochs is 0.2746799963100213\n",
      "cost after 11800 epochs is 0.27451261736009186\n",
      "cost after 11900 epochs is 0.2743517925831096\n",
      "cost after 12000 epochs is 0.27419196417608704\n",
      "cost after 12100 epochs is 0.2740375055130214\n",
      "cost after 12200 epochs is 0.27388535127888425\n",
      "cost after 12300 epochs is 0.27373472770208584\n",
      "cost after 12400 epochs is 0.2735890135897941\n",
      "cost after 12500 epochs is 0.2734457918528838\n",
      "cost after 12600 epochs is 0.27330422956175227\n",
      "cost after 12700 epochs is 0.2731660575398879\n",
      "cost after 12800 epochs is 0.27303154730400625\n",
      "cost after 12900 epochs is 0.27290129915256955\n",
      "cost after 13000 epochs is 0.2727712202669294\n",
      "cost after 13100 epochs is 0.2726444918034572\n",
      "cost after 13200 epochs is 0.2725215508206753\n",
      "cost after 13300 epochs is 0.2723997095825404\n",
      "cost after 13400 epochs is 0.2722811932927406\n",
      "cost after 13500 epochs is 0.2721660501485167\n",
      "cost after 13600 epochs is 0.2720573720744815\n",
      "cost after 13700 epochs is 0.2719503680393186\n",
      "cost after 13800 epochs is 0.2718444686181636\n",
      "cost after 13900 epochs is 0.2717418799327479\n",
      "cost after 14000 epochs is 0.2716424849279896\n",
      "cost after 14100 epochs is 0.27154353695376954\n",
      "cost after 14200 epochs is 0.27144832027755605\n",
      "cost after 14300 epochs is 0.2713541091545601\n",
      "cost after 14400 epochs is 0.2712618601253323\n",
      "cost after 14500 epochs is 0.2711711545806142\n",
      "cost after 14600 epochs is 0.2710829770923861\n",
      "cost after 14700 epochs is 0.27099763407664235\n",
      "cost after 14800 epochs is 0.2709129142930238\n",
      "cost after 14900 epochs is 0.27082980514576005\n",
      "cost after 15000 epochs is 0.2707469037685795\n",
      "cost after 15100 epochs is 0.2706671668172458\n",
      "cost after 15200 epochs is 0.27058793744711146\n",
      "cost after 15300 epochs is 0.2705129055189159\n",
      "cost after 15400 epochs is 0.27043559009122486\n",
      "cost after 15500 epochs is 0.27036250849412324\n",
      "cost after 15600 epochs is 0.270289954924629\n",
      "cost after 15700 epochs is 0.27021688439293956\n",
      "cost after 15800 epochs is 0.2701422634128814\n",
      "cost after 15900 epochs is 0.2700708876868799\n",
      "cost after 16000 epochs is 0.27000023598150574\n",
      "cost after 16100 epochs is 0.2699311528019464\n",
      "cost after 16200 epochs is 0.2698626675521777\n",
      "cost after 16300 epochs is 0.269796380617473\n",
      "cost after 16400 epochs is 0.26973090514219744\n",
      "cost after 16500 epochs is 0.2696656548556555\n",
      "cost after 16600 epochs is 0.26960284668068074\n",
      "cost after 16700 epochs is 0.26954038491270055\n",
      "cost after 16800 epochs is 0.2694789094609857\n",
      "cost after 16900 epochs is 0.26941828687426406\n",
      "cost after 17000 epochs is 0.26935949469055875\n",
      "cost after 17100 epochs is 0.2693016406033296\n",
      "cost after 17200 epochs is 0.26924554531440953\n",
      "cost after 17300 epochs is 0.26918845805960967\n",
      "cost after 17400 epochs is 0.2691339952506617\n",
      "cost after 17500 epochs is 0.2690797985526274\n",
      "cost after 17600 epochs is 0.2690272651446564\n",
      "cost after 17700 epochs is 0.26897534602957085\n",
      "cost after 17800 epochs is 0.2689256047760643\n",
      "cost after 17900 epochs is 0.2688759367702425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 18000 epochs is 0.2688262742507551\n",
      "cost after 18100 epochs is 0.2687773386549052\n",
      "cost after 18200 epochs is 0.26873081796798887\n",
      "cost after 18300 epochs is 0.26868404098514653\n",
      "cost after 18400 epochs is 0.26863796635733533\n",
      "cost after 18500 epochs is 0.2685922891586265\n",
      "cost after 18600 epochs is 0.26854775544277976\n",
      "cost after 18700 epochs is 0.26850468394458626\n",
      "cost after 18800 epochs is 0.2684627755810295\n",
      "cost after 18900 epochs is 0.26842118157786055\n",
      "cost after 19000 epochs is 0.26837986913138157\n",
      "cost after 19100 epochs is 0.26834058037780734\n",
      "cost after 19200 epochs is 0.26830257114958034\n",
      "cost after 19300 epochs is 0.26826371196154475\n",
      "cost after 19400 epochs is 0.2682266382406985\n",
      "cost after 19500 epochs is 0.26819027748857976\n",
      "cost after 19600 epochs is 0.2681551089960489\n",
      "cost after 19700 epochs is 0.2681197742681778\n",
      "cost after 19800 epochs is 0.26808437453828476\n",
      "cost after 19900 epochs is 0.2680509575789623\n",
      "cost after 20000 epochs is 0.26801695191864594\n",
      "cost after 20100 epochs is 0.2679838541772085\n",
      "cost after 20200 epochs is 0.267951767402571\n",
      "cost after 20300 epochs is 0.2679199358725499\n",
      "cost after 20400 epochs is 0.2678886917831359\n",
      "cost after 20500 epochs is 0.26785815537935515\n",
      "cost after 20600 epochs is 0.26782761857740084\n",
      "cost after 20700 epochs is 0.2677992338634898\n",
      "cost after 20800 epochs is 0.26776951471538984\n",
      "cost after 20900 epochs is 0.26774055621030896\n",
      "cost after 21000 epochs is 0.2677132044378857\n",
      "cost after 21100 epochs is 0.26768429018759754\n",
      "cost after 21200 epochs is 0.26765740320165804\n",
      "cost after 21300 epochs is 0.26763008745147615\n",
      "cost after 21400 epochs is 0.26760357291825565\n",
      "cost after 21500 epochs is 0.2675780116568314\n",
      "cost after 21600 epochs is 0.26755305359662035\n",
      "cost after 21700 epochs is 0.26752757404663646\n",
      "cost after 21800 epochs is 0.26750392694666414\n",
      "cost after 21900 epochs is 0.2674801835709456\n",
      "cost after 22000 epochs is 0.2674559483348601\n",
      "cost after 22100 epochs is 0.26743220107102766\n",
      "cost after 22200 epochs is 0.267409370468396\n",
      "cost after 22300 epochs is 0.2673754101485442\n",
      "cost after 22400 epochs is 0.26733192515338655\n",
      "cost after 22500 epochs is 0.2672887609969128\n",
      "cost after 22600 epochs is 0.2672480096074893\n",
      "cost after 22700 epochs is 0.26720811699925884\n",
      "cost after 22800 epochs is 0.26716874013013997\n",
      "cost after 22900 epochs is 0.2671308074653356\n",
      "cost after 23000 epochs is 0.2670923293485176\n",
      "cost after 23100 epochs is 0.26705541433265056\n",
      "cost after 23200 epochs is 0.2670191534420463\n",
      "cost after 23300 epochs is 0.2669824390744117\n",
      "cost after 23400 epochs is 0.2669477396832612\n",
      "cost after 23500 epochs is 0.26691285097382805\n",
      "cost after 23600 epochs is 0.26687846785207064\n",
      "cost after 23700 epochs is 0.26684499090657604\n",
      "cost after 23800 epochs is 0.26681198522138866\n",
      "cost after 23900 epochs is 0.2667794933229408\n",
      "cost after 24000 epochs is 0.26674719267332175\n",
      "cost after 24100 epochs is 0.2667161688251344\n",
      "cost after 24200 epochs is 0.266683841775495\n",
      "cost after 24300 epochs is 0.2666530818136574\n",
      "cost after 24400 epochs is 0.26662223625878084\n",
      "cost after 24500 epochs is 0.2665932786600249\n",
      "cost after 24600 epochs is 0.2665635897039678\n",
      "cost after 24700 epochs is 0.266534653659013\n",
      "cost after 24800 epochs is 0.266506585964846\n",
      "cost after 24900 epochs is 0.26647887217476074\n",
      "cost after 25000 epochs is 0.2664517324126662\n",
      "cost after 25100 epochs is 0.2664252602737139\n",
      "cost after 25200 epochs is 0.2663992938490382\n",
      "cost after 25300 epochs is 0.2663726838507556\n",
      "cost after 25400 epochs is 0.2663475087577178\n",
      "cost after 25500 epochs is 0.2663221258822976\n",
      "cost after 25600 epochs is 0.26629740633980004\n",
      "cost after 25700 epochs is 0.26627334637355904\n",
      "cost after 25800 epochs is 0.2662492781924637\n",
      "cost after 25900 epochs is 0.26622651866785135\n",
      "cost after 26000 epochs is 0.2662044811135749\n",
      "cost after 26100 epochs is 0.26618286939948504\n",
      "cost after 26200 epochs is 0.266162076929096\n",
      "cost after 26300 epochs is 0.2661414908998744\n",
      "cost after 26400 epochs is 0.2661208342903523\n",
      "cost after 26500 epochs is 0.2661000835633885\n",
      "cost after 26600 epochs is 0.26608067216776227\n",
      "cost after 26700 epochs is 0.26606028040229224\n",
      "cost after 26800 epochs is 0.26604088672345955\n",
      "cost after 26900 epochs is 0.2660224691550463\n",
      "cost after 27000 epochs is 0.26600332589859615\n",
      "cost after 27100 epochs is 0.26598496898884544\n",
      "cost after 27200 epochs is 0.26596603551198306\n",
      "cost after 27300 epochs is 0.2659477303971387\n",
      "cost after 27400 epochs is 0.26592955603884033\n",
      "cost after 27500 epochs is 0.2659120730405327\n",
      "cost after 27600 epochs is 0.2658938976449064\n",
      "cost after 27700 epochs is 0.26587681583864176\n",
      "cost after 27800 epochs is 0.2658594106915062\n",
      "cost after 27900 epochs is 0.265841768624016\n",
      "cost after 28000 epochs is 0.2658259106945423\n",
      "cost after 28100 epochs is 0.26580956939588585\n",
      "cost after 28200 epochs is 0.26579515593949143\n",
      "cost after 28300 epochs is 0.2657804465998446\n",
      "cost after 28400 epochs is 0.2657674180395701\n",
      "cost after 28500 epochs is 0.265752942057297\n",
      "cost after 28600 epochs is 0.265738842250419\n",
      "cost after 28700 epochs is 0.2657254005434\n",
      "cost after 28800 epochs is 0.26571130456290526\n",
      "cost after 28900 epochs is 0.26569786181629285\n",
      "cost after 29000 epochs is 0.265684938957499\n",
      "cost after 29100 epochs is 0.2656713992253853\n",
      "cost after 29200 epochs is 0.26565769427358127\n",
      "cost after 29300 epochs is 0.2656442748922322\n",
      "cost after 29400 epochs is 0.26563153990886545\n",
      "cost after 29500 epochs is 0.2656193075851951\n",
      "cost after 29600 epochs is 0.2656060525496727\n",
      "cost after 29700 epochs is 0.2655931804671723\n",
      "cost after 29800 epochs is 0.26558060477983036\n",
      "cost after 29900 epochs is 0.26556791316777484\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is: 0.933649289099526\n",
      "Test accuracy is: 0.93\n"
     ]
    }
   ],
   "source": [
    "parameters = regularized_model_sigmoid(X_train, Y_train, 0.03, 30000, [X_train.shape[0],25,12,1], lambd = 0.7)\n",
    "train_accuracy = predict_accuracy(X_train, Y_train, parameters)\n",
    "test_accuracy = predict_accuracy(X_test, Y_test, parameters)\n",
    "print('Train accuracy is: '+str(train_accuracy))\n",
    "print('Test accuracy is: '+str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient using grad checker is[-2.27937114e-05]\n",
      "gradient using back prop is[-2.27938724e-05]\n",
      "gradient using grad checker is[0.00013499]\n",
      "gradient using back prop is[0.00013499]\n",
      "gradient using grad checker is[1.75312542e-05]\n",
      "gradient using back prop is[1.75310139e-05]\n",
      "gradient using grad checker is[0.00046071]\n",
      "gradient using back prop is[0.00046071]\n",
      "gradient using grad checker is[0.0001067]\n",
      "gradient using back prop is[0.0001067]\n",
      "gradient using grad checker is[-0.00014411]\n",
      "gradient using back prop is[-0.00014411]\n",
      "gradient using grad checker is[0.00024134]\n",
      "gradient using back prop is[0.00024134]\n",
      "gradient using grad checker is[-0.00010956]\n",
      "gradient using back prop is[-0.00010955]\n",
      "gradient using grad checker is[2.00831018e-05]\n",
      "gradient using back prop is[2.00829565e-05]\n",
      "gradient using grad checker is[0.00023947]\n",
      "gradient using back prop is[0.00023947]\n",
      "gradient using grad checker is[-0.00024243]\n",
      "gradient using back prop is[-0.00024243]\n",
      "gradient using grad checker is[-6.93345381e-05]\n",
      "gradient using back prop is[-6.93344563e-05]\n",
      "gradient using grad checker is[-0.00097889]\n",
      "gradient using back prop is[-0.00097889]\n",
      "gradient using grad checker is[-0.00060916]\n",
      "gradient using back prop is[-0.00060916]\n",
      "gradient using grad checker is[6.94119762e-05]\n",
      "gradient using back prop is[6.9412192e-05]\n",
      "gradient using grad checker is[-9.62613322e-05]\n",
      "gradient using back prop is[-9.6261114e-05]\n",
      "gradient using grad checker is[3.32206485e-05]\n",
      "gradient using back prop is[3.32204691e-05]\n",
      "gradient using grad checker is[-9.92345095e-06]\n",
      "gradient using back prop is[-9.9234619e-06]\n",
      "gradient using grad checker is[4.12225809e-06]\n",
      "gradient using back prop is[4.12273954e-06]\n",
      "gradient using grad checker is[0.00019792]\n",
      "gradient using back prop is[0.00019792]\n",
      "gradient using grad checker is[-2.28436714e-05]\n",
      "gradient using back prop is[-2.28437117e-05]\n",
      "gradient using grad checker is[0.00015558]\n",
      "gradient using back prop is[0.00015558]\n",
      "gradient using grad checker is[-0.00027198]\n",
      "gradient using back prop is[-0.00027198]\n",
      "gradient using grad checker is[-0.00020747]\n",
      "gradient using back prop is[-0.00020747]\n",
      "gradient using grad checker is[-8.6617935e-05]\n",
      "gradient using back prop is[-8.66179098e-05]\n",
      "gradient using grad checker is[-6.85254631e-05]\n",
      "gradient using back prop is[-6.85256951e-05]\n",
      "gradient using grad checker is[-8.99835761e-05]\n",
      "gradient using back prop is[-8.99833613e-05]\n",
      "gradient using grad checker is[3.77972653e-05]\n",
      "gradient using back prop is[3.77972561e-05]\n",
      "gradient using grad checker is[4.70079531e-05]\n",
      "gradient using back prop is[4.7007883e-05]\n",
      "gradient using grad checker is[-0.0001421]\n",
      "gradient using back prop is[-0.0001421]\n",
      "gradient using grad checker is[-0.00230533]\n",
      "gradient using back prop is[-0.00230533]\n",
      "gradient using grad checker is[-0.00173452]\n",
      "gradient using back prop is[-0.00173452]\n",
      "gradient using grad checker is[-4.90327223e-05]\n",
      "gradient using back prop is[-4.90328839e-05]\n",
      "gradient using grad checker is[-3.228251e-06]\n",
      "gradient using back prop is[-3.22819289e-06]\n",
      "gradient using grad checker is[-9.34954891e-05]\n",
      "gradient using back prop is[-9.34951774e-05]\n",
      "gradient using grad checker is[-6.29926666e-05]\n",
      "gradient using back prop is[-6.29924827e-05]\n",
      "gradient using grad checker is[0.00010508]\n",
      "gradient using back prop is[0.00010508]\n",
      "gradient using grad checker is[0.00038541]\n",
      "gradient using back prop is[0.00038541]\n",
      "gradient using grad checker is[-0.0006627]\n",
      "gradient using back prop is[-0.0006627]\n",
      "gradient using grad checker is[-0.00075243]\n",
      "gradient using back prop is[-0.00075243]\n",
      "gradient using grad checker is[-0.00012264]\n",
      "gradient using back prop is[-0.00012264]\n",
      "gradient using grad checker is[-5.10036458e-06]\n",
      "gradient using back prop is[-5.10031543e-06]\n",
      "gradient using grad checker is[-0.00033073]\n",
      "gradient using back prop is[-0.00033073]\n",
      "gradient using grad checker is[-0.00021388]\n",
      "gradient using back prop is[-0.00021388]\n",
      "gradient using grad checker is[-0.0001182]\n",
      "gradient using back prop is[-0.0001182]\n",
      "gradient using grad checker is[0.00012915]\n",
      "gradient using back prop is[0.00012915]\n",
      "gradient using grad checker is[1.87283522e-05]\n",
      "gradient using back prop is[1.87282805e-05]\n",
      "gradient using grad checker is[9.21024368e-05]\n",
      "gradient using back prop is[9.21022846e-05]\n",
      "gradient using grad checker is[4.50364745e-05]\n",
      "gradient using back prop is[4.50364613e-05]\n",
      "gradient using grad checker is[-0.00019593]\n",
      "gradient using back prop is[-0.00019593]\n",
      "gradient using grad checker is[-0.00026128]\n",
      "gradient using back prop is[-0.00026128]\n",
      "gradient using grad checker is[-0.00097373]\n",
      "gradient using back prop is[-0.00097373]\n",
      "gradient using grad checker is[0.00150792]\n",
      "gradient using back prop is[0.00150792]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[-0.00046225]\n",
      "gradient using back prop is[-0.00046225]\n",
      "gradient using grad checker is[-0.00081415]\n",
      "gradient using back prop is[-0.00081415]\n",
      "gradient using grad checker is[0.00242882]\n",
      "gradient using back prop is[0.00242882]\n",
      "gradient using grad checker is[0.00090743]\n",
      "gradient using back prop is[0.00090743]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[-0.00042154]\n",
      "gradient using back prop is[-0.00042154]\n",
      "gradient using grad checker is[-0.00029358]\n",
      "gradient using back prop is[-0.00029358]\n",
      "gradient using grad checker is[-0.00144044]\n",
      "gradient using back prop is[-0.00144044]\n",
      "gradient using grad checker is[0.00090581]\n",
      "gradient using back prop is[0.00090581]\n",
      "gradient using grad checker is[-0.00022623]\n",
      "gradient using back prop is[-0.00022623]\n",
      "gradient using grad checker is[0.00018629]\n",
      "gradient using back prop is[0.00018629]\n",
      "gradient using grad checker is[0.00365083]\n",
      "gradient using back prop is[0.00365083]\n",
      "gradient using grad checker is[-0.00018989]\n",
      "gradient using back prop is[-0.00018989]\n",
      "gradient using grad checker is[-0.0002676]\n",
      "gradient using back prop is[-0.0002676]\n",
      "gradient using grad checker is[-0.00030822]\n",
      "gradient using back prop is[-0.00030822]\n",
      "gradient using grad checker is[0.00581501]\n",
      "gradient using back prop is[0.00581501]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[-0.00161823]\n",
      "gradient using back prop is[-0.00161823]\n",
      "gradient using grad checker is[0.00065393]\n",
      "gradient using back prop is[0.00065393]\n",
      "gradient using grad checker is[-0.00016722]\n",
      "gradient using back prop is[-0.00016722]\n",
      "gradient using grad checker is[0.0002399]\n",
      "gradient using back prop is[0.0002399]\n",
      "gradient using grad checker is[-2.29860575e-05]\n",
      "gradient using back prop is[-2.29860009e-05]\n",
      "gradient using grad checker is[5.69183589e-06]\n",
      "gradient using back prop is[5.69181823e-06]\n",
      "gradient using grad checker is[-2.83653656e-05]\n",
      "gradient using back prop is[-2.83654044e-05]\n",
      "gradient using grad checker is[-4.5782822e-05]\n",
      "gradient using back prop is[-4.57827896e-05]\n",
      "gradient using grad checker is[-4.87701546e-05]\n",
      "gradient using back prop is[-4.87702167e-05]\n",
      "gradient using grad checker is[-4.72230588e-05]\n",
      "gradient using back prop is[-4.72230402e-05]\n",
      "gradient using grad checker is[-9.68583547e-05]\n",
      "gradient using back prop is[-9.68583673e-05]\n",
      "gradient using grad checker is[-5.13172838e-05]\n",
      "gradient using back prop is[-5.13173725e-05]\n",
      "gradient using grad checker is[-4.23303059e-05]\n",
      "gradient using back prop is[-4.23302201e-05]\n",
      "gradient using grad checker is[-2.21078711e-05]\n",
      "gradient using back prop is[-2.21077401e-05]\n",
      "gradient using grad checker is[-2.21589413e-05]\n",
      "gradient using back prop is[-2.21589696e-05]\n",
      "gradient using grad checker is[-1.02734488e-05]\n",
      "gradient using back prop is[-1.02734856e-05]\n",
      "gradient using grad checker is[-2.00478523e-06]\n",
      "gradient using back prop is[-2.0048302e-06]\n",
      "gradient using grad checker is[-2.65029665e-05]\n",
      "gradient using back prop is[-2.65029908e-05]\n",
      "gradient using grad checker is[1.05646047e-05]\n",
      "gradient using back prop is[1.05646129e-05]\n",
      "gradient using grad checker is[-1.55384039e-05]\n",
      "gradient using back prop is[-1.55384488e-05]\n",
      "gradient using grad checker is[1.50676693e-05]\n",
      "gradient using back prop is[1.50677495e-05]\n",
      "gradient using grad checker is[2.68668421e-05]\n",
      "gradient using back prop is[2.68666886e-05]\n",
      "gradient using grad checker is[-9.71756009e-05]\n",
      "gradient using back prop is[-9.71756143e-05]\n",
      "gradient using grad checker is[-2.85382828e-05]\n",
      "gradient using back prop is[-2.85381866e-05]\n",
      "gradient using grad checker is[7.72229503e-05]\n",
      "gradient using back prop is[7.72229029e-05]\n",
      "gradient using grad checker is[-8.24790236e-05]\n",
      "gradient using back prop is[-8.24788828e-05]\n",
      "gradient using grad checker is[1.21633259e-05]\n",
      "gradient using back prop is[1.21633184e-05]\n",
      "gradient using grad checker is[-4.59923766e-05]\n",
      "gradient using back prop is[-4.59924287e-05]\n",
      "gradient using grad checker is[5.61051205e-06]\n",
      "gradient using back prop is[5.61041554e-06]\n",
      "gradient using grad checker is[9.75788894e-05]\n",
      "gradient using back prop is[9.75787785e-05]\n",
      "gradient using grad checker is[4.23291957e-05]\n",
      "gradient using back prop is[4.23293788e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient using grad checker is[-6.88066271e-05]\n",
      "gradient using back prop is[-6.88067007e-05]\n",
      "gradient using grad checker is[-6.10886342e-05]\n",
      "gradient using back prop is[-6.10886366e-05]\n",
      "gradient using grad checker is[-5.76999559e-05]\n",
      "gradient using back prop is[-5.76995699e-05]\n",
      "gradient using grad checker is[2.73753242e-05]\n",
      "gradient using back prop is[2.73752215e-05]\n",
      "gradient using grad checker is[3.81286669e-05]\n",
      "gradient using back prop is[3.81284686e-05]\n",
      "gradient using grad checker is[-1.36751721e-06]\n",
      "gradient using back prop is[-1.36738593e-06]\n",
      "gradient using grad checker is[3.5513259e-05]\n",
      "gradient using back prop is[3.55131234e-05]\n",
      "gradient using grad checker is[0.00010076]\n",
      "gradient using back prop is[0.00010076]\n",
      "gradient using grad checker is[7.88674681e-05]\n",
      "gradient using back prop is[7.88672451e-05]\n",
      "gradient using grad checker is[4.71969686e-05]\n",
      "gradient using back prop is[4.71970783e-05]\n",
      "gradient using grad checker is[-5.52247137e-05]\n",
      "gradient using back prop is[-5.52247895e-05]\n",
      "gradient using grad checker is[8.34082803e-06]\n",
      "gradient using back prop is[8.34084152e-06]\n",
      "gradient using grad checker is[6.73433531e-06]\n",
      "gradient using back prop is[6.73442842e-06]\n",
      "gradient using grad checker is[-0.00023651]\n",
      "gradient using back prop is[-0.00023651]\n",
      "gradient using grad checker is[-4.19025925e-05]\n",
      "gradient using back prop is[-4.19027974e-05]\n",
      "gradient using grad checker is[3.95578015e-05]\n",
      "gradient using back prop is[3.95579534e-05]\n",
      "gradient using grad checker is[5.44253531e-05]\n",
      "gradient using back prop is[5.44251191e-05]\n",
      "gradient using grad checker is[5.34455813e-05]\n",
      "gradient using back prop is[5.34455316e-05]\n",
      "gradient using grad checker is[-1.61343161e-05]\n",
      "gradient using back prop is[-1.61341495e-05]\n",
      "gradient using grad checker is[-6.26734775e-05]\n",
      "gradient using back prop is[-6.26735966e-05]\n",
      "gradient using grad checker is[-7.90509325e-05]\n",
      "gradient using back prop is[-7.90506173e-05]\n",
      "gradient using grad checker is[-7.09987624e-07]\n",
      "gradient using back prop is[-7.09657356e-07]\n",
      "gradient using grad checker is[1.69866898e-05]\n",
      "gradient using back prop is[1.69870226e-05]\n",
      "gradient using grad checker is[-1.17417187e-05]\n",
      "gradient using back prop is[-1.17419163e-05]\n",
      "gradient using grad checker is[-6.86922741e-06]\n",
      "gradient using back prop is[-6.86914067e-06]\n",
      "gradient using grad checker is[-5.29026822e-05]\n",
      "gradient using back prop is[-5.2902426e-05]\n",
      "gradient using grad checker is[2.57330268e-05]\n",
      "gradient using back prop is[2.5733026e-05]\n",
      "gradient using grad checker is[1.35758071e-05]\n",
      "gradient using back prop is[1.35759121e-05]\n",
      "gradient using grad checker is[-5.71964698e-05]\n",
      "gradient using back prop is[-5.71966453e-05]\n",
      "gradient using grad checker is[-1.19812493e-05]\n",
      "gradient using back prop is[-1.19810636e-05]\n",
      "gradient using grad checker is[2.19749219e-05]\n",
      "gradient using back prop is[2.19750232e-05]\n",
      "gradient using grad checker is[-0.00010959]\n",
      "gradient using back prop is[-0.00010959]\n",
      "gradient using grad checker is[5.69250203e-05]\n",
      "gradient using back prop is[5.69251367e-05]\n",
      "gradient using grad checker is[-5.01951258e-05]\n",
      "gradient using back prop is[-5.01952914e-05]\n",
      "gradient using grad checker is[-4.6994908e-05]\n",
      "gradient using back prop is[-4.69949332e-05]\n",
      "gradient using grad checker is[6.63138988e-05]\n",
      "gradient using back prop is[6.63139606e-05]\n",
      "gradient using grad checker is[-6.73797129e-05]\n",
      "gradient using back prop is[-6.73796414e-05]\n",
      "gradient using grad checker is[7.75990383e-06]\n",
      "gradient using back prop is[7.76009286e-06]\n",
      "gradient using grad checker is[-3.28392868e-05]\n",
      "gradient using back prop is[-3.28393351e-05]\n",
      "gradient using grad checker is[4.28093672e-05]\n",
      "gradient using back prop is[4.28093031e-05]\n",
      "gradient using grad checker is[-4.25381952e-06]\n",
      "gradient using back prop is[-4.25395994e-06]\n",
      "gradient using grad checker is[4.56099047e-05]\n",
      "gradient using back prop is[4.56103686e-05]\n",
      "gradient using grad checker is[-2.67050271e-05]\n",
      "gradient using back prop is[-2.67051187e-05]\n",
      "gradient using grad checker is[-8.5983165e-05]\n",
      "gradient using back prop is[-8.59832835e-05]\n",
      "gradient using grad checker is[-0.00018651]\n",
      "gradient using back prop is[-0.00018651]\n",
      "gradient using grad checker is[2.86204394e-05]\n",
      "gradient using back prop is[2.862032e-05]\n",
      "gradient using grad checker is[-1.00625064e-05]\n",
      "gradient using back prop is[-1.00625408e-05]\n",
      "gradient using grad checker is[-5.44075895e-05]\n",
      "gradient using back prop is[-5.44076535e-05]\n",
      "gradient using grad checker is[-0.00015125]\n",
      "gradient using back prop is[-0.00015125]\n",
      "gradient using grad checker is[0.00015935]\n",
      "gradient using back prop is[0.00015935]\n",
      "gradient using grad checker is[4.37594405e-06]\n",
      "gradient using back prop is[4.37613693e-06]\n",
      "gradient using grad checker is[-5.43032286e-05]\n",
      "gradient using back prop is[-5.43032699e-05]\n",
      "gradient using grad checker is[5.74501557e-05]\n",
      "gradient using back prop is[5.74504807e-05]\n",
      "gradient using grad checker is[-0.00013831]\n",
      "gradient using back prop is[-0.00013832]\n",
      "gradient using grad checker is[8.53730975e-05]\n",
      "gradient using back prop is[8.53732139e-05]\n",
      "gradient using grad checker is[3.7683745e-06]\n",
      "gradient using back prop is[3.76836445e-06]\n",
      "gradient using grad checker is[1.28724809e-05]\n",
      "gradient using back prop is[1.28723881e-05]\n",
      "gradient using grad checker is[5.58275648e-05]\n",
      "gradient using back prop is[5.58274366e-05]\n",
      "gradient using grad checker is[-0.00016335]\n",
      "gradient using back prop is[-0.00016335]\n",
      "gradient using grad checker is[9.89902604e-05]\n",
      "gradient using back prop is[9.89902344e-05]\n",
      "gradient using grad checker is[3.7813086e-05]\n",
      "gradient using back prop is[3.78131518e-05]\n",
      "gradient using grad checker is[2.67183498e-05]\n",
      "gradient using back prop is[2.67180729e-05]\n",
      "gradient using grad checker is[-0.00031341]\n",
      "gradient using back prop is[-0.00031341]\n",
      "gradient using grad checker is[-9.10957421e-05]\n",
      "gradient using back prop is[-9.10959584e-05]\n",
      "gradient using grad checker is[-1.12651555e-05]\n",
      "gradient using back prop is[-1.12655485e-05]\n",
      "gradient using grad checker is[-0.0001083]\n",
      "gradient using back prop is[-0.0001083]\n",
      "gradient using grad checker is[7.6139095e-06]\n",
      "gradient using back prop is[7.61393211e-06]\n",
      "gradient using grad checker is[-1.77552417e-05]\n",
      "gradient using back prop is[-1.77554746e-05]\n",
      "gradient using grad checker is[-4.85317342e-05]\n",
      "gradient using back prop is[-4.85315778e-05]\n",
      "gradient using grad checker is[-0.00011033]\n",
      "gradient using back prop is[-0.00011033]\n",
      "gradient using grad checker is[2.83134627e-05]\n",
      "gradient using back prop is[2.83137093e-05]\n",
      "gradient using grad checker is[5.00433028e-05]\n",
      "gradient using back prop is[5.00433e-05]\n",
      "gradient using grad checker is[-0.0003012]\n",
      "gradient using back prop is[-0.0003012]\n",
      "gradient using grad checker is[-5.60107516e-05]\n",
      "gradient using back prop is[-5.60104452e-05]\n",
      "gradient using grad checker is[-7.81752441e-05]\n",
      "gradient using back prop is[-7.81755067e-05]\n",
      "gradient using grad checker is[6.77274903e-05]\n",
      "gradient using back prop is[6.77276005e-05]\n",
      "gradient using grad checker is[-2.95879987e-05]\n",
      "gradient using back prop is[-2.95878951e-05]\n",
      "gradient using grad checker is[-4.04903888e-05]\n",
      "gradient using back prop is[-4.04903051e-05]\n",
      "gradient using grad checker is[-1.38417056e-05]\n",
      "gradient using back prop is[-1.38414e-05]\n",
      "gradient using grad checker is[-2.22533103e-05]\n",
      "gradient using back prop is[-2.22531632e-05]\n",
      "gradient using grad checker is[6.43235465e-05]\n",
      "gradient using back prop is[6.43237712e-05]\n",
      "gradient using grad checker is[-4.72816231e-06]\n",
      "gradient using back prop is[-4.72821297e-06]\n",
      "gradient using grad checker is[-4.69524419e-05]\n",
      "gradient using back prop is[-4.695254e-05]\n",
      "gradient using grad checker is[-5.02589637e-05]\n",
      "gradient using back prop is[-5.02586734e-05]\n",
      "gradient using grad checker is[0.00011816]\n",
      "gradient using back prop is[0.00011816]\n",
      "gradient using grad checker is[3.69973496e-05]\n",
      "gradient using back prop is[3.6997714e-05]\n",
      "gradient using grad checker is[-5.95698491e-05]\n",
      "gradient using back prop is[-5.95698453e-05]\n",
      "gradient using grad checker is[0.00017525]\n",
      "gradient using back prop is[0.00017525]\n",
      "gradient using grad checker is[0.00074542]\n",
      "gradient using back prop is[0.00074542]\n",
      "gradient using grad checker is[-1.30931377e-05]\n",
      "gradient using back prop is[-1.30930743e-05]\n",
      "gradient using grad checker is[-1.8687274e-05]\n",
      "gradient using back prop is[-1.86870902e-05]\n",
      "gradient using grad checker is[-8.39137093e-05]\n",
      "gradient using back prop is[-8.39136698e-05]\n",
      "gradient using grad checker is[-5.7670535e-06]\n",
      "gradient using back prop is[-5.76725165e-06]\n",
      "gradient using grad checker is[1.95216066e-05]\n",
      "gradient using back prop is[1.95216213e-05]\n",
      "gradient using grad checker is[8.58976779e-05]\n",
      "gradient using back prop is[8.58977532e-05]\n",
      "gradient using grad checker is[5.74756909e-05]\n",
      "gradient using back prop is[5.74755358e-05]\n",
      "gradient using grad checker is[9.4562691e-05]\n",
      "gradient using back prop is[9.45630055e-05]\n",
      "gradient using grad checker is[0.0001642]\n",
      "gradient using back prop is[0.0001642]\n",
      "gradient using grad checker is[3.24559823e-05]\n",
      "gradient using back prop is[3.2455994e-05]\n",
      "gradient using grad checker is[2.06892836e-05]\n",
      "gradient using back prop is[2.06891965e-05]\n",
      "gradient using grad checker is[-5.82925375e-05]\n",
      "gradient using back prop is[-5.82925891e-05]\n",
      "gradient using grad checker is[-7.16021686e-05]\n",
      "gradient using back prop is[-7.16019998e-05]\n",
      "gradient using grad checker is[1.13015153e-05]\n",
      "gradient using back prop is[1.13015796e-05]\n",
      "gradient using grad checker is[-2.97786795e-05]\n",
      "gradient using back prop is[-2.97788045e-05]\n",
      "gradient using grad checker is[-0.00013019]\n",
      "gradient using back prop is[-0.00013019]\n",
      "gradient using grad checker is[7.05507874e-05]\n",
      "gradient using back prop is[7.05508033e-05]\n",
      "gradient using grad checker is[3.59795527e-06]\n",
      "gradient using back prop is[3.59790681e-06]\n",
      "gradient using grad checker is[-6.0567662e-05]\n",
      "gradient using back prop is[-6.05677407e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient using grad checker is[-7.228107e-06]\n",
      "gradient using back prop is[-7.22807559e-06]\n",
      "gradient using grad checker is[-2.28000951e-05]\n",
      "gradient using back prop is[-2.28001616e-05]\n",
      "gradient using grad checker is[-7.86581911e-05]\n",
      "gradient using back prop is[-7.86583343e-05]\n",
      "gradient using grad checker is[3.17956772e-05]\n",
      "gradient using back prop is[3.17956018e-05]\n",
      "gradient using grad checker is[4.14776546e-05]\n",
      "gradient using back prop is[4.14777895e-05]\n",
      "gradient using grad checker is[-2.93956526e-05]\n",
      "gradient using back prop is[-2.93956902e-05]\n",
      "gradient using grad checker is[-1.68756675e-05]\n",
      "gradient using back prop is[-1.6875643e-05]\n",
      "gradient using grad checker is[-4.07690548e-05]\n",
      "gradient using back prop is[-4.07690424e-05]\n",
      "gradient using grad checker is[2.0619062e-05]\n",
      "gradient using back prop is[2.06190319e-05]\n",
      "gradient using grad checker is[4.21235269e-05]\n",
      "gradient using back prop is[4.21236222e-05]\n",
      "gradient using grad checker is[8.51080317e-05]\n",
      "gradient using back prop is[8.51080742e-05]\n",
      "gradient using grad checker is[1.97350469e-05]\n",
      "gradient using back prop is[1.97351422e-05]\n",
      "gradient using grad checker is[1.48672741e-05]\n",
      "gradient using back prop is[1.48672874e-05]\n",
      "gradient using grad checker is[4.60662064e-05]\n",
      "gradient using back prop is[4.60662886e-05]\n",
      "gradient using grad checker is[-5.19609356e-05]\n",
      "gradient using back prop is[-5.1960767e-05]\n",
      "gradient using grad checker is[-8.25270408e-05]\n",
      "gradient using back prop is[-8.2527039e-05]\n",
      "gradient using grad checker is[0.00020424]\n",
      "gradient using back prop is[0.00020424]\n",
      "gradient using grad checker is[-1.66197611e-05]\n",
      "gradient using back prop is[-1.66197115e-05]\n",
      "gradient using grad checker is[1.36948786e-05]\n",
      "gradient using back prop is[1.36948401e-05]\n",
      "gradient using grad checker is[0.00018994]\n",
      "gradient using back prop is[0.00018994]\n",
      "gradient using grad checker is[-0.00014774]\n",
      "gradient using back prop is[-0.00014774]\n",
      "gradient using grad checker is[-1.56008539e-05]\n",
      "gradient using back prop is[-1.56009057e-05]\n",
      "gradient using grad checker is[1.45522483e-06]\n",
      "gradient using back prop is[1.45524084e-06]\n",
      "gradient using grad checker is[-3.37535555e-05]\n",
      "gradient using back prop is[-3.37534426e-05]\n",
      "gradient using grad checker is[0.00010816]\n",
      "gradient using back prop is[0.00010816]\n",
      "gradient using grad checker is[-0.00012072]\n",
      "gradient using back prop is[-0.00012072]\n",
      "gradient using grad checker is[0.00014315]\n",
      "gradient using back prop is[0.00014315]\n",
      "gradient using grad checker is[-2.22805108e-05]\n",
      "gradient using back prop is[-2.22807564e-05]\n",
      "gradient using grad checker is[1.40387701e-05]\n",
      "gradient using back prop is[1.40387716e-05]\n",
      "gradient using grad checker is[-0.00017983]\n",
      "gradient using back prop is[-0.00017983]\n",
      "gradient using grad checker is[-0.00012761]\n",
      "gradient using back prop is[-0.00012761]\n",
      "gradient using grad checker is[-2.9236058e-05]\n",
      "gradient using back prop is[-2.92356761e-05]\n",
      "gradient using grad checker is[-6.75415279e-05]\n",
      "gradient using back prop is[-6.75416205e-05]\n",
      "gradient using grad checker is[6.73658351e-05]\n",
      "gradient using back prop is[6.73660211e-05]\n",
      "gradient using grad checker is[6.62303545e-06]\n",
      "gradient using back prop is[6.62318286e-06]\n",
      "gradient using grad checker is[-5.20364307e-05]\n",
      "gradient using back prop is[-5.20363177e-05]\n",
      "gradient using grad checker is[-0.00010762]\n",
      "gradient using back prop is[-0.00010762]\n",
      "gradient using grad checker is[1.58345559e-06]\n",
      "gradient using back prop is[1.58305099e-06]\n",
      "gradient using grad checker is[-5.16667265e-05]\n",
      "gradient using back prop is[-5.16666325e-05]\n",
      "gradient using grad checker is[-0.00017016]\n",
      "gradient using back prop is[-0.00017016]\n",
      "gradient using grad checker is[-4.79927209e-05]\n",
      "gradient using back prop is[-4.79928029e-05]\n",
      "gradient using grad checker is[5.41708345e-05]\n",
      "gradient using back prop is[5.41706084e-05]\n",
      "gradient using grad checker is[3.1197267e-05]\n",
      "gradient using back prop is[3.11972325e-05]\n",
      "gradient using grad checker is[-1.82726057e-05]\n",
      "gradient using back prop is[-1.82723827e-05]\n",
      "gradient using grad checker is[1.50723878e-05]\n",
      "gradient using back prop is[1.5072462e-05]\n",
      "gradient using grad checker is[3.71769282e-05]\n",
      "gradient using back prop is[3.71768054e-05]\n",
      "gradient using grad checker is[-4.94720931e-05]\n",
      "gradient using back prop is[-4.94718677e-05]\n",
      "gradient using grad checker is[-4.74031925e-05]\n",
      "gradient using back prop is[-4.74034398e-05]\n",
      "gradient using grad checker is[-3.51912943e-06]\n",
      "gradient using back prop is[-3.5191309e-06]\n",
      "gradient using grad checker is[-8.34302072e-05]\n",
      "gradient using back prop is[-8.34300802e-05]\n",
      "gradient using grad checker is[2.80891976e-05]\n",
      "gradient using back prop is[2.80893517e-05]\n",
      "gradient using grad checker is[2.77261547e-05]\n",
      "gradient using back prop is[2.77262369e-05]\n",
      "gradient using grad checker is[-2.17567631e-05]\n",
      "gradient using back prop is[-2.17567048e-05]\n",
      "gradient using grad checker is[6.68812228e-05]\n",
      "gradient using back prop is[6.68810983e-05]\n",
      "gradient using grad checker is[-2.2752078e-05]\n",
      "gradient using back prop is[-2.27524118e-05]\n",
      "gradient using grad checker is[-3.12033732e-05]\n",
      "gradient using back prop is[-3.12036246e-05]\n",
      "gradient using grad checker is[-4.13441503e-05]\n",
      "gradient using back prop is[-4.13443133e-05]\n",
      "gradient using grad checker is[-3.91697785e-05]\n",
      "gradient using back prop is[-3.91698874e-05]\n",
      "gradient using grad checker is[9.56734691e-07]\n",
      "gradient using back prop is[9.56390238e-07]\n",
      "gradient using grad checker is[-3.26358385e-05]\n",
      "gradient using back prop is[-3.2635975e-05]\n",
      "gradient using grad checker is[6.32777164e-05]\n",
      "gradient using back prop is[6.3277638e-05]\n",
      "gradient using grad checker is[-0.00011337]\n",
      "gradient using back prop is[-0.00011337]\n",
      "gradient using grad checker is[-3.01342284e-06]\n",
      "gradient using back prop is[-3.01363387e-06]\n",
      "gradient using grad checker is[5.04418729e-05]\n",
      "gradient using back prop is[5.04417088e-05]\n",
      "gradient using grad checker is[-5.40203993e-05]\n",
      "gradient using back prop is[-5.40203588e-05]\n",
      "gradient using grad checker is[-2.6961211e-05]\n",
      "gradient using back prop is[-2.696146e-05]\n",
      "gradient using grad checker is[7.92116372e-05]\n",
      "gradient using back prop is[7.92115627e-05]\n",
      "gradient using grad checker is[-2.35395037e-05]\n",
      "gradient using back prop is[-2.35396432e-05]\n",
      "gradient using grad checker is[-3.81411569e-05]\n",
      "gradient using back prop is[-3.81413327e-05]\n",
      "gradient using grad checker is[-2.46158649e-05]\n",
      "gradient using back prop is[-2.46158595e-05]\n",
      "gradient using grad checker is[6.47620846e-05]\n",
      "gradient using back prop is[6.47617954e-05]\n",
      "gradient using grad checker is[5.94482796e-05]\n",
      "gradient using back prop is[5.94485383e-05]\n",
      "gradient using grad checker is[2.95427571e-05]\n",
      "gradient using back prop is[2.95425959e-05]\n",
      "gradient using grad checker is[-9.56118518e-05]\n",
      "gradient using back prop is[-9.56116908e-05]\n",
      "gradient using grad checker is[1.27214905e-05]\n",
      "gradient using back prop is[1.27213454e-05]\n",
      "gradient using grad checker is[-1.1655954e-05]\n",
      "gradient using back prop is[-1.16561379e-05]\n",
      "gradient using grad checker is[2.80639401e-05]\n",
      "gradient using back prop is[2.80638329e-05]\n",
      "gradient using grad checker is[7.83223486e-05]\n",
      "gradient using back prop is[7.83223597e-05]\n",
      "gradient using grad checker is[3.35625971e-05]\n",
      "gradient using back prop is[3.3562503e-05]\n",
      "gradient using grad checker is[2.2032931e-05]\n",
      "gradient using back prop is[2.20326587e-05]\n",
      "gradient using grad checker is[-0.00014378]\n",
      "gradient using back prop is[-0.00014378]\n",
      "gradient using grad checker is[6.81732448e-06]\n",
      "gradient using back prop is[6.8174062e-06]\n",
      "gradient using grad checker is[2.48029375e-05]\n",
      "gradient using back prop is[2.48024758e-05]\n",
      "gradient using grad checker is[6.28186392e-05]\n",
      "gradient using back prop is[6.28189478e-05]\n",
      "gradient using grad checker is[-9.01390074e-06]\n",
      "gradient using back prop is[-9.01390508e-06]\n",
      "gradient using grad checker is[-4.47306081e-05]\n",
      "gradient using back prop is[-4.47306919e-05]\n",
      "gradient using grad checker is[-0.00011618]\n",
      "gradient using back prop is[-0.00011618]\n",
      "gradient using grad checker is[-3.88050703e-05]\n",
      "gradient using back prop is[-3.88046507e-05]\n",
      "gradient using grad checker is[7.31087413e-05]\n",
      "gradient using back prop is[7.31092155e-05]\n",
      "gradient using grad checker is[8.59340377e-06]\n",
      "gradient using back prop is[8.59334398e-06]\n",
      "gradient using grad checker is[2.39777642e-05]\n",
      "gradient using back prop is[2.39779346e-05]\n",
      "gradient using grad checker is[0.0001356]\n",
      "gradient using back prop is[0.0001356]\n",
      "gradient using grad checker is[9.6533892e-07]\n",
      "gradient using back prop is[9.65236504e-07]\n",
      "gradient using grad checker is[3.05255821e-06]\n",
      "gradient using back prop is[3.05270911e-06]\n",
      "gradient using grad checker is[2.80378498e-05]\n",
      "gradient using back prop is[2.80374891e-05]\n",
      "gradient using grad checker is[1.0259571e-05]\n",
      "gradient using back prop is[1.02592624e-05]\n",
      "gradient using grad checker is[-2.80941936e-05]\n",
      "gradient using back prop is[-2.80942625e-05]\n",
      "gradient using grad checker is[-9.24846311e-05]\n",
      "gradient using back prop is[-9.24847018e-05]\n",
      "gradient using grad checker is[2.94816949e-05]\n",
      "gradient using back prop is[2.948169e-05]\n",
      "gradient using grad checker is[-1.34586786e-05]\n",
      "gradient using back prop is[-1.34586229e-05]\n",
      "gradient using grad checker is[5.72458747e-05]\n",
      "gradient using back prop is[5.72459262e-05]\n",
      "gradient using grad checker is[-0.00011572]\n",
      "gradient using back prop is[-0.00011572]\n",
      "gradient using grad checker is[-3.17060267e-05]\n",
      "gradient using back prop is[-3.17061578e-05]\n",
      "gradient using grad checker is[-2.54651855e-05]\n",
      "gradient using back prop is[-2.54649633e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient using grad checker is[-3.37235795e-05]\n",
      "gradient using back prop is[-3.37235654e-05]\n",
      "gradient using grad checker is[9.25551302e-05]\n",
      "gradient using back prop is[9.25548426e-05]\n",
      "gradient using grad checker is[-5.61001245e-05]\n",
      "gradient using back prop is[-5.61002472e-05]\n",
      "gradient using grad checker is[1.02828857e-05]\n",
      "gradient using back prop is[1.02830427e-05]\n",
      "gradient using grad checker is[-1.67621472e-05]\n",
      "gradient using back prop is[-1.67622138e-05]\n",
      "gradient using grad checker is[-0.00011938]\n",
      "gradient using back prop is[-0.00011938]\n",
      "gradient using grad checker is[-7.042672e-05]\n",
      "gradient using back prop is[-7.04268125e-05]\n",
      "gradient using grad checker is[-5.66838243e-05]\n",
      "gradient using back prop is[-5.66840894e-05]\n",
      "gradient using grad checker is[-2.56805688e-05]\n",
      "gradient using back prop is[-2.56803787e-05]\n",
      "gradient using grad checker is[5.05978592e-05]\n",
      "gradient using back prop is[5.05977574e-05]\n",
      "gradient using grad checker is[-3.57766594e-05]\n",
      "gradient using back prop is[-3.57768694e-05]\n",
      "gradient using grad checker is[-7.80958631e-06]\n",
      "gradient using back prop is[-7.80952309e-06]\n",
      "gradient using grad checker is[-2.63417066e-05]\n",
      "gradient using back prop is[-2.63417922e-05]\n",
      "gradient using grad checker is[-7.0844719e-05]\n",
      "gradient using back prop is[-7.08448216e-05]\n",
      "gradient using grad checker is[1.48045465e-05]\n",
      "gradient using back prop is[1.48045712e-05]\n",
      "gradient using grad checker is[-2.89451796e-05]\n",
      "gradient using back prop is[-2.89452807e-05]\n",
      "gradient using grad checker is[7.75984832e-05]\n",
      "gradient using back prop is[7.75985226e-05]\n",
      "gradient using grad checker is[0.00015239]\n",
      "gradient using back prop is[0.00015238]\n",
      "gradient using grad checker is[7.95288835e-05]\n",
      "gradient using back prop is[7.95293921e-05]\n",
      "gradient using grad checker is[5.62477842e-05]\n",
      "gradient using back prop is[5.62479285e-05]\n",
      "gradient using grad checker is[-6.64829303e-05]\n",
      "gradient using back prop is[-6.64829536e-05]\n",
      "gradient using grad checker is[2.61962674e-05]\n",
      "gradient using back prop is[2.61963681e-05]\n",
      "gradient using grad checker is[9.19264664e-07]\n",
      "gradient using back prop is[9.18972339e-07]\n",
      "gradient using grad checker is[-6.50840493e-05]\n",
      "gradient using back prop is[-6.50840908e-05]\n",
      "gradient using grad checker is[3.95991573e-05]\n",
      "gradient using back prop is[3.95989113e-05]\n",
      "gradient using grad checker is[-1.02257092e-05]\n",
      "gradient using back prop is[-1.0225545e-05]\n",
      "gradient using grad checker is[-0.00022124]\n",
      "gradient using back prop is[-0.00022124]\n",
      "gradient using grad checker is[2.64743782e-05]\n",
      "gradient using back prop is[2.64747491e-05]\n",
      "gradient using grad checker is[3.81811249e-05]\n",
      "gradient using back prop is[3.81814368e-05]\n",
      "gradient using grad checker is[7.38550887e-05]\n",
      "gradient using back prop is[7.38552727e-05]\n",
      "gradient using grad checker is[-8.57308669e-05]\n",
      "gradient using back prop is[-8.57309816e-05]\n",
      "gradient using grad checker is[4.91651164e-05]\n",
      "gradient using back prop is[4.91651075e-05]\n",
      "gradient using grad checker is[-0.00012185]\n",
      "gradient using back prop is[-0.00012185]\n",
      "gradient using grad checker is[5.17547116e-05]\n",
      "gradient using back prop is[5.17545292e-05]\n",
      "gradient using grad checker is[1.67932335e-05]\n",
      "gradient using back prop is[1.67932011e-05]\n",
      "gradient using grad checker is[-2.41828779e-05]\n",
      "gradient using back prop is[-2.41831318e-05]\n",
      "gradient using grad checker is[-4.87435092e-05]\n",
      "gradient using back prop is[-4.8743501e-05]\n",
      "gradient using grad checker is[-7.51310125e-05]\n",
      "gradient using back prop is[-7.51310335e-05]\n",
      "gradient using grad checker is[0.0001201]\n",
      "gradient using back prop is[0.0001201]\n",
      "gradient using grad checker is[-2.81172308e-05]\n",
      "gradient using back prop is[-2.81173298e-05]\n",
      "gradient using grad checker is[2.17956209e-05]\n",
      "gradient using back prop is[2.17954557e-05]\n",
      "gradient using grad checker is[0.0002197]\n",
      "gradient using back prop is[0.0002197]\n",
      "gradient using grad checker is[0.0001126]\n",
      "gradient using back prop is[0.0001126]\n",
      "gradient using grad checker is[0.00013981]\n",
      "gradient using back prop is[0.00013981]\n",
      "gradient using grad checker is[-1.50227053e-05]\n",
      "gradient using back prop is[-1.50227056e-05]\n",
      "gradient using grad checker is[-3.9075132e-05]\n",
      "gradient using back prop is[-3.90751488e-05]\n",
      "gradient using grad checker is[-6.54998278e-05]\n",
      "gradient using back prop is[-6.55000479e-05]\n",
      "gradient using grad checker is[0.00021045]\n",
      "gradient using back prop is[0.00021045]\n",
      "gradient using grad checker is[-6.24555963e-06]\n",
      "gradient using back prop is[-6.24561599e-06]\n",
      "gradient using grad checker is[3.18467475e-06]\n",
      "gradient using back prop is[3.18470306e-06]\n",
      "gradient using grad checker is[0.00015352]\n",
      "gradient using back prop is[0.00015352]\n",
      "gradient using grad checker is[0.00019781]\n",
      "gradient using back prop is[0.00019781]\n",
      "gradient using grad checker is[-1.78720927e-05]\n",
      "gradient using back prop is[-1.78717191e-05]\n",
      "gradient using grad checker is[0.00016496]\n",
      "gradient using back prop is[0.00016496]\n",
      "gradient using grad checker is[0.00019861]\n",
      "gradient using back prop is[0.00019861]\n",
      "gradient using grad checker is[3.68607922e-05]\n",
      "gradient using back prop is[3.68608167e-05]\n",
      "gradient using grad checker is[-6.38378239e-07]\n",
      "gradient using back prop is[-6.38266127e-07]\n",
      "gradient using grad checker is[0.00020328]\n",
      "gradient using back prop is[0.00020328]\n",
      "gradient using grad checker is[-1.88010718e-05]\n",
      "gradient using back prop is[-1.8801188e-05]\n",
      "gradient using grad checker is[-3.47333273e-06]\n",
      "gradient using back prop is[-3.47375507e-06]\n",
      "gradient using grad checker is[0.00030946]\n",
      "gradient using back prop is[0.00030946]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[-0.0001784]\n",
      "gradient using back prop is[-0.0001784]\n",
      "gradient using grad checker is[-1.75942594e-06]\n",
      "gradient using back prop is[-1.75936658e-06]\n",
      "gradient using grad checker is[-0.0006879]\n",
      "gradient using back prop is[-0.0006879]\n",
      "gradient using grad checker is[-0.00028721]\n",
      "gradient using back prop is[-0.00028721]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[-0.0004977]\n",
      "gradient using back prop is[-0.0004977]\n",
      "gradient using grad checker is[9.4582675e-06]\n",
      "gradient using back prop is[9.45819772e-06]\n",
      "gradient using grad checker is[-0.0001669]\n",
      "gradient using back prop is[-0.0001669]\n",
      "gradient using grad checker is[3.08814085e-05]\n",
      "gradient using back prop is[3.08813848e-05]\n",
      "gradient using grad checker is[-9.92861349e-05]\n",
      "gradient using back prop is[-9.92857684e-05]\n",
      "gradient using grad checker is[0.00024181]\n",
      "gradient using back prop is[0.00024181]\n",
      "gradient using grad checker is[-2.23276952e-05]\n",
      "gradient using back prop is[-2.23275466e-05]\n",
      "gradient using grad checker is[-4.3378634e-05]\n",
      "gradient using back prop is[-4.33786609e-05]\n",
      "gradient using grad checker is[-2.50405252e-05]\n",
      "gradient using back prop is[-2.50408346e-05]\n",
      "gradient using grad checker is[-6.59150512e-05]\n",
      "gradient using back prop is[-6.5914983e-05]\n",
      "gradient using grad checker is[5.50057222e-05]\n",
      "gradient using back prop is[5.50057616e-05]\n",
      "gradient using grad checker is[9.21357435e-05]\n",
      "gradient using back prop is[9.21358885e-05]\n",
      "gradient using grad checker is[-4.18010071e-05]\n",
      "gradient using back prop is[-4.18012031e-05]\n",
      "gradient using grad checker is[5.89361893e-06]\n",
      "gradient using back prop is[5.89380224e-06]\n",
      "gradient using grad checker is[-4.99209007e-05]\n",
      "gradient using back prop is[-4.9920895e-05]\n",
      "gradient using grad checker is[0.00024279]\n",
      "gradient using back prop is[0.00024279]\n",
      "gradient using grad checker is[-5.09567388e-05]\n",
      "gradient using back prop is[-5.09564267e-05]\n",
      "gradient using grad checker is[-0.00031229]\n",
      "gradient using back prop is[-0.00031229]\n",
      "gradient using grad checker is[-0.00012862]\n",
      "gradient using back prop is[-0.00012862]\n",
      "Your back prop is working absolutely fine. Difference is 1.9514277195304161e-07\n"
     ]
    }
   ],
   "source": [
    "AL, cache = forward_prop(X_train, parameters)\n",
    "gradients = back_prop_with_regularization(X_train, Y_train, cache, lambd = 0.7)\n",
    "difference = regularized_gradient_checker(X_train, Y_train, parameters, gradients, lambd = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
