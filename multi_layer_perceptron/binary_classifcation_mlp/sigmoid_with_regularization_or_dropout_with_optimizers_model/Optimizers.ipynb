{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent( Batch Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_update(parameters, gradients, learning_rate):\n",
    "    L = int(len(parameters)/2)\n",
    "    for l in range (1,L+1):\n",
    "        parameters['W' +str(l)] = parameters['W' + str(l)] - learning_rate*gradients['dW' + str(l)]\n",
    "        parameters['b' +str(l)] = parameters['b' + str(l)] - learning_rate*gradients['db' +str(l)]\n",
    "    return parameters   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Random Mini Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_minibatches(X_train, Y_train, minibatch_size):\n",
    "    m = X_train.shape[1]\n",
    "    # To shuffle X and Y train.\n",
    "    #np.random.seed(0)\n",
    "    K = list(np.random.permutation(m))  # k is an array, list() changes an array into a list. https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.permutation.html\n",
    "    shuffled_X = X_train[:,K]\n",
    "    shuffled_Y = Y_train[:,K].reshape((1,m))\n",
    "    \n",
    "    \n",
    "    \n",
    "    minibatches = []\n",
    "    num_complete_minibatches = int(np.floor(m/minibatch_size))\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        minibatch_X = shuffled_X[:, k*minibatch_size:(k+1)*minibatch_size]\n",
    "        minibatch_Y = shuffled_Y[:,k*minibatch_size:(k+1)*minibatch_size]\n",
    "        minibatch = (minibatch_X, minibatch_Y)\n",
    "        minibatches.append(minibatch)\n",
    "        \n",
    "    # end case of mini batch\n",
    "    if m % minibatch_size != 0:\n",
    "        minibatch_X = shuffled_X[:,num_complete_minibatches*minibatch_size:m]\n",
    "        minibatch_Y = shuffled_Y[:,num_complete_minibatches*minibatch_size:m]\n",
    "        minibatch = (minibatch_X, minibatch_Y)\n",
    "        minibatches.append(minibatch)\n",
    "    \n",
    "    return minibatches    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Velocities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_velocity(parameters):\n",
    "    \n",
    "    L = int((1/2)*len(parameters))\n",
    "    V = {}\n",
    "    for l in range(1, L+1):\n",
    "        V['dW'+ str(l)] = np.zeros(((parameters['W'+str(l)]).shape))\n",
    "        V['db'+ str(l)] = np.zeros(((parameters['b'+str(l)]).shape))\n",
    "    \n",
    "    return V     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Parameters with Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum_update(parameters, gradients, learning_rate, V, beta1):\n",
    "    \n",
    "    L = int((1/2)*len(parameters))\n",
    "    for l in range(1,L+1):\n",
    "        V['dW'+str(l)] = beta1*V['dW'+str(l)] + (1-beta1)*gradients['dW'+str(l)]\n",
    "        V['db'+str(l)] = beta1*V['db'+str(l)] + (1-beta1)*gradients['db'+str(l)]\n",
    "        \n",
    "        # parameters update\n",
    "        parameters['W'+str(l)] = parameters['W'+str(l)] - learning_rate*V['dW'+str(l)]\n",
    "        parameters['b'+str(l)] = parameters['b'+str(l)] - learning_rate*V['db'+str(l)]\n",
    "        \n",
    "    return parameters, V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMS Prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Squared Velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_rms_prop(parameters):\n",
    "    \n",
    "    L = int((1/2)*len(parameters))\n",
    "    S = {}\n",
    "    for l in range(1, L+1):\n",
    "        S['dW'+ str(l)] = np.zeros(((parameters['W'+str(l)]).shape))\n",
    "        S['db'+ str(l)] = np.zeros(((parameters['b'+str(l)]).shape))\n",
    "    \n",
    "    return S     \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Parameters with RMS Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms_prop_update(parameters, gradients, learning_rate, S, beta2, epsilon = 1e-8):\n",
    "    \n",
    "    L = int((1/2)*len(parameters))\n",
    "    \n",
    "    for l in range(1, L+1):\n",
    "        S['dW'+str(l)] = beta2*S['dW'+str(l)] + (1-beta2)*np.square(gradients['dW'+str(l)])\n",
    "        S['db' + str(l)] = beta2*S['db' +str(l)] + (1-beta2)*np.square(gradients['db' +str(l)])\n",
    "        \n",
    "        #parameters update\n",
    "        parameters['W'+str(l)] = parameters['W' +str(l)] - (learning_rate/(np.sqrt(S['dW'+str(l)])+ epsilon))*gradients['dW'+str(l)]\n",
    "        parameters['b'+str(l)] = parameters['b' +str(l)] - (learning_rate/(np.sqrt(S['db'+str(l)])+ epsilon))*gradients['db'+str(l)]\n",
    "        \n",
    "    return parameters, S    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_adam(parameters):\n",
    "    \n",
    "    L = int((1/2)*len(parameters))\n",
    "    V= {}\n",
    "    S = {}\n",
    "    for l in range(1, L+1):\n",
    "        V['dW'+ str(l)] = np.zeros(((parameters['W'+str(l)]).shape))\n",
    "        V['db'+ str(l)] = np.zeros(((parameters['b'+str(l)]).shape))\n",
    "        S['dW'+ str(l)] = np.zeros(((parameters['W'+str(l)]).shape))\n",
    "        S['db'+ str(l)] = np.zeros(((parameters['b'+str(l)]).shape))\n",
    "        \n",
    "    return V, S    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Parameters with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adam_update(parameters, gradients, learning_rate, V, S, t,  beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8):\n",
    "    \n",
    "    L = int((1/2)*len(parameters))\n",
    "    V_corrected = {}\n",
    "    S_corrected = {}\n",
    "    \n",
    "    for l in range(1, L+1):\n",
    "        \n",
    "        V['dW'+str(l)] = beta1*V['dW'+str(l)] + (1-beta1)*gradients['dW'+str(l)]\n",
    "        V_corrected['dW'+str(l)] = V['dW'+str(l)]/(1- (beta1)**t)\n",
    "        \n",
    "        V['db'+str(l)] = beta1*V['db'+str(l)] + (1-beta1)*gradients['db'+str(l)]\n",
    "        V_corrected['db'+str(l)] = V['db'+str(l)]/(1- (beta1)**t)\n",
    "        \n",
    "        S['dW'+str(l)] = beta2*S['dW'+str(l)] + (1-beta2)*np.square(gradients['dW'+str(l)])\n",
    "        S_corrected['dW'+str(l)] = S['dW'+str(l)]/(1- (beta2)**t)\n",
    "        \n",
    "        S['db'+str(l)] = beta2*S['db'+str(l)] + (1-beta2)*np.square(gradients['db'+str(l)])\n",
    "        S_corrected['db'+str(l)] = S['db'+str(l)]/(1- (beta2)**t)\n",
    "        \n",
    "        #parameters update\n",
    "        parameters['W'+str(l)] = parameters['W'+str(l)] - (learning_rate/(np.sqrt(S_corrected['dW'+str(l)]) + epsilon))*V_corrected['dW'+str(l)]\n",
    "        parameters['b'+str(l)] = parameters['b'+str(l)] - (learning_rate/(np.sqrt(S_corrected['db'+str(l)]) + epsilon))*V_corrected['db'+str(l)]\n",
    "    \n",
    "    return parameters, V, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
