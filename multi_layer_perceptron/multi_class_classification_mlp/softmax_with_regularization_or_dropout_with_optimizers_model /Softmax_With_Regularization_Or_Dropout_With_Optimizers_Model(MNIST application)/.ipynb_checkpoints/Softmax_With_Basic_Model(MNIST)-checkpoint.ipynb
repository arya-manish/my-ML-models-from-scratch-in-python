{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Apple/anaconda3/envs/Arya/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n",
      "/Users/Apple/anaconda3/envs/Arya/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Softmax_Necessary_Functions_With_Basic import *\n",
    "from Softmax_Gradient_Checker_With_Basic import *\n",
    "from Load_Dataset import read_input_file\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Apple/Google Drive/My Deep Learning practice & innovation/My own model/Softmax_With_Basic_Model/Softmax_With_Basic_Model(MNIST application)/Load_Dataset.py:15: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/Apple/anaconda3/envs/Arya/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/Apple/anaconda3/envs/Arya/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/Apple/anaconda3/envs/Arya/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/Apple/anaconda3/envs/Arya/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/Apple/anaconda3/envs/Arya/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig = read_input_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train has shape: (784, 55000)\n",
      "Y_train has shape: (10, 55000)\n",
      "X_test has shape: (784, 10000)\n",
      "Y_test has shape: (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train_orig.T\n",
    "Y_train = Y_train_orig.T\n",
    "X_test = X_test_orig.T\n",
    "Y_test = Y_test_orig.T\n",
    "print(\"X_train has shape: \" +str(X_train.shape))\n",
    "print(\"Y_train has shape: \" +str(Y_train.shape))\n",
    "print(\"X_test has shape: \" + str(X_test.shape))\n",
    "print(\"Y_test has shape: \" +str(Y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after 0 iterations is 2.4191576377779898\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "parameters = basic_model_softmax(X_train, Y_train, 0.0075, 200, [784,6,3,10])\n",
    "tac = time.time()\n",
    "print('Time taken in training is :' + str(tac-tic) +' seconds')\n",
    "train_accuracy = pred_accuracy_softmax(X_train, Y_train, parameters)\n",
    "test_accuracy = pred_accuracy_softmax(X_test, Y_test, parameters)\n",
    "print('Train accuracy is : '+str(train_accuracy))\n",
    "print('Test accuracy is : '+str(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[2.87214696e-05]\n",
      "gradient using back prop is[2.87200241e-05]\n",
      "gradient using grad checker is[8.67972361e-06]\n",
      "gradient using back prop is[8.68121638e-06]\n",
      "gradient using grad checker is[-2.95541369e-06]\n",
      "gradient using back prop is[-2.95521419e-06]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[1.93400851e-06]\n",
      "gradient using back prop is[1.93466992e-06]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[-3.17523785e-07]\n",
      "gradient using back prop is[-3.17578551e-07]\n",
      "gradient using grad checker is[-9.48130463e-07]\n",
      "gradient using back prop is[-9.4777345e-07]\n",
      "gradient using grad checker is[-2.04725126e-06]\n",
      "gradient using back prop is[-2.04639258e-06]\n",
      "gradient using grad checker is[-2.12940776e-06]\n",
      "gradient using back prop is[-2.12875435e-06]\n",
      "gradient using grad checker is[2.36610731e-05]\n",
      "gradient using back prop is[2.36603727e-05]\n",
      "gradient using grad checker is[3.70792286e-05]\n",
      "gradient using back prop is[3.70832889e-05]\n",
      "gradient using grad checker is[4.13247214e-05]\n",
      "gradient using back prop is[4.13229206e-05]\n",
      "gradient using grad checker is[3.7967407e-05]\n",
      "gradient using back prop is[3.79713997e-05]\n",
      "gradient using grad checker is[4.24171809e-05]\n",
      "gradient using back prop is[4.24191582e-05]\n",
      "gradient using grad checker is[5.02908826e-05]\n",
      "gradient using back prop is[5.02919345e-05]\n",
      "gradient using grad checker is[5.04551956e-05]\n",
      "gradient using back prop is[5.04566462e-05]\n",
      "gradient using grad checker is[3.61466412e-05]\n",
      "gradient using back prop is[3.61475408e-05]\n",
      "gradient using grad checker is[7.76756437e-05]\n",
      "gradient using back prop is[7.76749086e-05]\n",
      "gradient using grad checker is[0.00010475]\n",
      "gradient using back prop is[0.00010475]\n",
      "gradient using grad checker is[4.45044002e-05]\n",
      "gradient using back prop is[4.45042055e-05]\n",
      "gradient using grad checker is[6.31494856e-06]\n",
      "gradient using back prop is[6.31482993e-06]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[1.04360964e-07]\n",
      "gradient using back prop is[1.05062236e-07]\n",
      "gradient using grad checker is[-6.70574707e-07]\n",
      "gradient using back prop is[-6.71142009e-07]\n",
      "gradient using grad checker is[-1.99174011e-06]\n",
      "gradient using back prop is[-1.99092929e-06]\n",
      "gradient using grad checker is[3.13082893e-07]\n",
      "gradient using back prop is[3.10203529e-07]\n",
      "gradient using grad checker is[2.03481676e-05]\n",
      "gradient using back prop is[2.03469195e-05]\n",
      "gradient using grad checker is[4.28124203e-05]\n",
      "gradient using back prop is[4.28132962e-05]\n",
      "gradient using grad checker is[0.00012091]\n",
      "gradient using back prop is[0.00012091]\n",
      "gradient using grad checker is[0.00013105]\n",
      "gradient using back prop is[0.00013104]\n",
      "gradient using grad checker is[9.60165281e-05]\n",
      "gradient using back prop is[9.60154888e-05]\n",
      "gradient using grad checker is[0.00013142]\n",
      "gradient using back prop is[0.00013142]\n",
      "gradient using grad checker is[0.00018558]\n",
      "gradient using back prop is[0.00018558]\n",
      "gradient using grad checker is[0.00015729]\n",
      "gradient using back prop is[0.00015729]\n",
      "gradient using grad checker is[0.00011639]\n",
      "gradient using back prop is[0.00011639]\n",
      "gradient using grad checker is[0.00013273]\n",
      "gradient using back prop is[0.00013273]\n",
      "gradient using grad checker is[9.91384752e-05]\n",
      "gradient using back prop is[9.91377191e-05]\n",
      "gradient using grad checker is[2.18580709e-05]\n",
      "gradient using back prop is[2.18568451e-05]\n",
      "gradient using grad checker is[1.3993251e-05]\n",
      "gradient using back prop is[1.39958009e-05]\n",
      "gradient using grad checker is[1.59783298e-05]\n",
      "gradient using back prop is[1.59789986e-05]\n",
      "gradient using grad checker is[8.5154106e-06]\n",
      "gradient using back prop is[8.51435685e-06]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[1.02362563e-06]\n",
      "gradient using back prop is[1.02712792e-06]\n",
      "gradient using grad checker is[7.86704035e-06]\n",
      "gradient using back prop is[7.86705508e-06]\n",
      "gradient using grad checker is[3.47877283e-05]\n",
      "gradient using back prop is[3.4785807e-05]\n",
      "gradient using grad checker is[9.36051237e-05]\n",
      "gradient using back prop is[9.36047262e-05]\n",
      "gradient using grad checker is[0.00015613]\n",
      "gradient using back prop is[0.00015613]\n",
      "gradient using grad checker is[0.00024505]\n",
      "gradient using back prop is[0.00024505]\n",
      "gradient using grad checker is[0.00039343]\n",
      "gradient using back prop is[0.00039343]\n",
      "gradient using grad checker is[0.00054446]\n",
      "gradient using back prop is[0.00054446]\n",
      "gradient using grad checker is[0.00062778]\n",
      "gradient using back prop is[0.00062778]\n",
      "gradient using grad checker is[0.00055277]\n",
      "gradient using back prop is[0.00055277]\n",
      "gradient using grad checker is[0.0005577]\n",
      "gradient using back prop is[0.00055769]\n",
      "gradient using grad checker is[0.00052679]\n",
      "gradient using back prop is[0.00052679]\n",
      "gradient using grad checker is[0.00041067]\n",
      "gradient using back prop is[0.00041068]\n",
      "gradient using grad checker is[0.00034619]\n",
      "gradient using back prop is[0.00034619]\n",
      "gradient using grad checker is[0.00023363]\n",
      "gradient using back prop is[0.00023363]\n",
      "gradient using grad checker is[8.40283398e-05]\n",
      "gradient using back prop is[8.40286504e-05]\n",
      "gradient using grad checker is[2.55195864e-05]\n",
      "gradient using back prop is[2.55198219e-05]\n",
      "gradient using grad checker is[2.98450153e-05]\n",
      "gradient using back prop is[2.98451221e-05]\n",
      "gradient using grad checker is[3.07509573e-05]\n",
      "gradient using back prop is[3.0748018e-05]\n",
      "gradient using grad checker is[1.28030919e-05]\n",
      "gradient using back prop is[1.28015245e-05]\n",
      "gradient using grad checker is[-5.06705788e-06]\n",
      "gradient using back prop is[-5.06548766e-06]\n",
      "gradient using grad checker is[-2.50688359e-06]\n",
      "gradient using back prop is[-2.50488278e-06]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n",
      "gradient using grad checker is[0.]\n",
      "gradient using back prop is[0.]\n"
     ]
    }
   ],
   "source": [
    "AL, cache = forward_prop(X_train, parameters)\n",
    "gradients = back_prop_without_regularization(X_train,Y_train,cache)\n",
    "difference = gradient_check(X_train,Y_train,parameters,gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
