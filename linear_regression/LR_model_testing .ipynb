{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our LR model written in LinearRegressionModel.py \n",
    "from LinearRegressionModel import linear_regression_model  \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA & Data Preparation to feed the dataset into written model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': '/Users/Apple/opt/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/boston_house_prices.csv'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bost = pd.DataFrame(boston['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2    3      4      5     6       7    8      9    10  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "\n",
       "       11    12  \n",
       "0  396.90  4.98  \n",
       "1  396.90  9.14  \n",
       "2  392.83  4.03  \n",
       "3  394.63  2.94  \n",
       "4  396.90  5.33  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bost.columns = boston['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bost.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize input matrix so that data lies in the range of -1 to +1\n",
    "X = (bost - bost.mean())/(bost.max() -bost.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-3.208896e-18</td>\n",
       "      <td>1.148072e-16</td>\n",
       "      <td>-6.812595e-16</td>\n",
       "      <td>-1.189760e-16</td>\n",
       "      <td>6.223338e-16</td>\n",
       "      <td>-1.521044e-15</td>\n",
       "      <td>-3.491388e-16</td>\n",
       "      <td>1.206490e-16</td>\n",
       "      <td>6.406821e-17</td>\n",
       "      <td>1.933017e-16</td>\n",
       "      <td>-2.300312e-15</td>\n",
       "      <td>1.881620e-15</td>\n",
       "      <td>-1.082797e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>9.667929e-02</td>\n",
       "      <td>2.332245e-01</td>\n",
       "      <td>2.514792e-01</td>\n",
       "      <td>2.539940e-01</td>\n",
       "      <td>2.384314e-01</td>\n",
       "      <td>1.346268e-01</td>\n",
       "      <td>2.898956e-01</td>\n",
       "      <td>1.914822e-01</td>\n",
       "      <td>3.785765e-01</td>\n",
       "      <td>3.216357e-01</td>\n",
       "      <td>2.303134e-01</td>\n",
       "      <td>2.302054e-01</td>\n",
       "      <td>1.970492e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-4.054410e-02</td>\n",
       "      <td>-1.136364e-01</td>\n",
       "      <td>-3.913775e-01</td>\n",
       "      <td>-6.916996e-02</td>\n",
       "      <td>-3.491668e-01</td>\n",
       "      <td>-5.218690e-01</td>\n",
       "      <td>-6.763636e-01</td>\n",
       "      <td>-2.423813e-01</td>\n",
       "      <td>-3.717134e-01</td>\n",
       "      <td>-4.222083e-01</td>\n",
       "      <td>-6.229291e-01</td>\n",
       "      <td>-8.985678e-01</td>\n",
       "      <td>-3.014090e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-3.969297e-02</td>\n",
       "      <td>-1.136364e-01</td>\n",
       "      <td>-2.179904e-01</td>\n",
       "      <td>-6.916996e-02</td>\n",
       "      <td>-2.174795e-01</td>\n",
       "      <td>-7.647718e-02</td>\n",
       "      <td>-2.425325e-01</td>\n",
       "      <td>-1.541223e-01</td>\n",
       "      <td>-2.412786e-01</td>\n",
       "      <td>-2.466358e-01</td>\n",
       "      <td>-1.122908e-01</td>\n",
       "      <td>4.716191e-02</td>\n",
       "      <td>-1.573693e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-3.773202e-02</td>\n",
       "      <td>-1.136364e-01</td>\n",
       "      <td>-5.303441e-02</td>\n",
       "      <td>-6.916996e-02</td>\n",
       "      <td>-3.435197e-02</td>\n",
       "      <td>-1.458793e-02</td>\n",
       "      <td>9.191657e-02</td>\n",
       "      <td>-5.343258e-02</td>\n",
       "      <td>-1.978003e-01</td>\n",
       "      <td>-1.493075e-01</td>\n",
       "      <td>6.324111e-02</td>\n",
       "      <td>8.766445e-02</td>\n",
       "      <td>-3.568055e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7.143872e-04</td>\n",
       "      <td>1.136364e-02</td>\n",
       "      <td>2.552500e-01</td>\n",
       "      <td>-6.916996e-02</td>\n",
       "      <td>1.426028e-01</td>\n",
       "      <td>6.492922e-02</td>\n",
       "      <td>2.626169e-01</td>\n",
       "      <td>1.267068e-01</td>\n",
       "      <td>6.282866e-01</td>\n",
       "      <td>4.919138e-01</td>\n",
       "      <td>1.855815e-01</td>\n",
       "      <td>9.973011e-02</td>\n",
       "      <td>1.187069e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>9.594559e-01</td>\n",
       "      <td>8.863636e-01</td>\n",
       "      <td>6.086225e-01</td>\n",
       "      <td>9.308300e-01</td>\n",
       "      <td>6.508332e-01</td>\n",
       "      <td>4.781310e-01</td>\n",
       "      <td>3.236364e-01</td>\n",
       "      <td>7.576187e-01</td>\n",
       "      <td>6.282866e-01</td>\n",
       "      <td>5.777917e-01</td>\n",
       "      <td>3.770709e-01</td>\n",
       "      <td>1.014322e-01</td>\n",
       "      <td>6.985910e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CRIM            ZN         INDUS          CHAS           NOX  \\\n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean  -3.208896e-18  1.148072e-16 -6.812595e-16 -1.189760e-16  6.223338e-16   \n",
       "std    9.667929e-02  2.332245e-01  2.514792e-01  2.539940e-01  2.384314e-01   \n",
       "min   -4.054410e-02 -1.136364e-01 -3.913775e-01 -6.916996e-02 -3.491668e-01   \n",
       "25%   -3.969297e-02 -1.136364e-01 -2.179904e-01 -6.916996e-02 -2.174795e-01   \n",
       "50%   -3.773202e-02 -1.136364e-01 -5.303441e-02 -6.916996e-02 -3.435197e-02   \n",
       "75%    7.143872e-04  1.136364e-02  2.552500e-01 -6.916996e-02  1.426028e-01   \n",
       "max    9.594559e-01  8.863636e-01  6.086225e-01  9.308300e-01  6.508332e-01   \n",
       "\n",
       "                 RM           AGE           DIS           RAD           TAX  \\\n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02  5.060000e+02   \n",
       "mean  -1.521044e-15 -3.491388e-16  1.206490e-16  6.406821e-17  1.933017e-16   \n",
       "std    1.346268e-01  2.898956e-01  1.914822e-01  3.785765e-01  3.216357e-01   \n",
       "min   -5.218690e-01 -6.763636e-01 -2.423813e-01 -3.717134e-01 -4.222083e-01   \n",
       "25%   -7.647718e-02 -2.425325e-01 -1.541223e-01 -2.412786e-01 -2.466358e-01   \n",
       "50%   -1.458793e-02  9.191657e-02 -5.343258e-02 -1.978003e-01 -1.493075e-01   \n",
       "75%    6.492922e-02  2.626169e-01  1.267068e-01  6.282866e-01  4.919138e-01   \n",
       "max    4.781310e-01  3.236364e-01  7.576187e-01  6.282866e-01  5.777917e-01   \n",
       "\n",
       "            PTRATIO             B         LSTAT  \n",
       "count  5.060000e+02  5.060000e+02  5.060000e+02  \n",
       "mean  -2.300312e-15  1.881620e-15 -1.082797e-16  \n",
       "std    2.303134e-01  2.302054e-01  1.970492e-01  \n",
       "min   -6.229291e-01 -8.985678e-01 -3.014090e-01  \n",
       "25%   -1.122908e-01  4.716191e-02 -1.573693e-01  \n",
       "50%    6.324111e-02  8.766445e-02 -3.568055e-02  \n",
       "75%    1.855815e-01  9.973011e-02  1.187069e-01  \n",
       "max    3.770709e-01  1.014322e-01  6.985910e-01  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.040544</td>\n",
       "      <td>0.066364</td>\n",
       "      <td>-0.323562</td>\n",
       "      <td>-0.06917</td>\n",
       "      <td>-0.034352</td>\n",
       "      <td>0.055636</td>\n",
       "      <td>-0.034757</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>-0.371713</td>\n",
       "      <td>-0.214193</td>\n",
       "      <td>-0.335695</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.211729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.149075</td>\n",
       "      <td>-0.06917</td>\n",
       "      <td>-0.176327</td>\n",
       "      <td>0.026129</td>\n",
       "      <td>0.106335</td>\n",
       "      <td>0.106581</td>\n",
       "      <td>-0.328235</td>\n",
       "      <td>-0.317246</td>\n",
       "      <td>-0.069738</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.096939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.149075</td>\n",
       "      <td>-0.06917</td>\n",
       "      <td>-0.176327</td>\n",
       "      <td>0.172517</td>\n",
       "      <td>-0.076981</td>\n",
       "      <td>0.106581</td>\n",
       "      <td>-0.328235</td>\n",
       "      <td>-0.317246</td>\n",
       "      <td>-0.069738</td>\n",
       "      <td>0.091169</td>\n",
       "      <td>-0.237943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.040251</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.328328</td>\n",
       "      <td>-0.06917</td>\n",
       "      <td>-0.198961</td>\n",
       "      <td>0.136686</td>\n",
       "      <td>-0.234551</td>\n",
       "      <td>0.206163</td>\n",
       "      <td>-0.284757</td>\n",
       "      <td>-0.355414</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.095708</td>\n",
       "      <td>-0.268021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.039839</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.328328</td>\n",
       "      <td>-0.06917</td>\n",
       "      <td>-0.198961</td>\n",
       "      <td>0.165236</td>\n",
       "      <td>-0.148042</td>\n",
       "      <td>0.206163</td>\n",
       "      <td>-0.284757</td>\n",
       "      <td>-0.355414</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.202071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS     CHAS       NOX        RM       AGE  \\\n",
       "0 -0.040544  0.066364 -0.323562 -0.06917 -0.034352  0.055636 -0.034757   \n",
       "1 -0.040308 -0.113636 -0.149075 -0.06917 -0.176327  0.026129  0.106335   \n",
       "2 -0.040308 -0.113636 -0.149075 -0.06917 -0.176327  0.172517 -0.076981   \n",
       "3 -0.040251 -0.113636 -0.328328 -0.06917 -0.198961  0.136686 -0.234551   \n",
       "4 -0.039839 -0.113636 -0.328328 -0.06917 -0.198961  0.165236 -0.148042   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.026822 -0.371713 -0.214193 -0.335695  0.101432 -0.211729  \n",
       "1  0.106581 -0.328235 -0.317246 -0.069738  0.101432 -0.096939  \n",
       "2  0.106581 -0.328235 -0.317246 -0.069738  0.091169 -0.237943  \n",
       "3  0.206163 -0.284757 -0.355414  0.026007  0.095708 -0.268021  \n",
       "4  0.206163 -0.284757 -0.355414  0.026007  0.101432 -0.202071  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.33, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model needs X_training of dimension (number_features x number_training_examples)\n",
    "X_train = X_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 339)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>435</th>\n",
       "      <th>88</th>\n",
       "      <th>365</th>\n",
       "      <th>242</th>\n",
       "      <th>461</th>\n",
       "      <th>129</th>\n",
       "      <th>12</th>\n",
       "      <th>419</th>\n",
       "      <th>152</th>\n",
       "      <th>79</th>\n",
       "      <th>...</th>\n",
       "      <th>228</th>\n",
       "      <th>8</th>\n",
       "      <th>73</th>\n",
       "      <th>400</th>\n",
       "      <th>118</th>\n",
       "      <th>486</th>\n",
       "      <th>189</th>\n",
       "      <th>495</th>\n",
       "      <th>206</th>\n",
       "      <th>355</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>CRIM</td>\n",
       "      <td>0.084825</td>\n",
       "      <td>-0.039979</td>\n",
       "      <td>0.010592</td>\n",
       "      <td>-0.039459</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>-0.030710</td>\n",
       "      <td>-0.039561</td>\n",
       "      <td>0.092152</td>\n",
       "      <td>-0.027953</td>\n",
       "      <td>-0.039672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037264</td>\n",
       "      <td>-0.038241</td>\n",
       "      <td>-0.038419</td>\n",
       "      <td>0.240897</td>\n",
       "      <td>-0.039147</td>\n",
       "      <td>0.023359</td>\n",
       "      <td>-0.039674</td>\n",
       "      <td>-0.038603</td>\n",
       "      <td>-0.038033</td>\n",
       "      <td>-0.039417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ZN</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>0.186364</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>0.686364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>-0.283240</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>-0.227521</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>0.394180</td>\n",
       "      <td>-0.119750</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>0.309502</td>\n",
       "      <td>0.062068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180967</td>\n",
       "      <td>-0.119750</td>\n",
       "      <td>-0.011979</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>-0.041304</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>-0.282140</td>\n",
       "      <td>-0.053034</td>\n",
       "      <td>-0.020043</td>\n",
       "      <td>-0.338225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CHAS</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>0.930830</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NOX</td>\n",
       "      <td>0.381286</td>\n",
       "      <td>-0.135175</td>\n",
       "      <td>0.336018</td>\n",
       "      <td>-0.260689</td>\n",
       "      <td>0.325730</td>\n",
       "      <td>0.142603</td>\n",
       "      <td>-0.063159</td>\n",
       "      <td>0.336018</td>\n",
       "      <td>0.650833</td>\n",
       "      <td>-0.242171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104311</td>\n",
       "      <td>-0.063159</td>\n",
       "      <td>-0.291554</td>\n",
       "      <td>0.284578</td>\n",
       "      <td>-0.015833</td>\n",
       "      <td>0.058241</td>\n",
       "      <td>-0.242171</td>\n",
       "      <td>0.062356</td>\n",
       "      <td>-0.135175</td>\n",
       "      <td>-0.291554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RM</td>\n",
       "      <td>0.065983</td>\n",
       "      <td>0.138411</td>\n",
       "      <td>-0.521869</td>\n",
       "      <td>0.014057</td>\n",
       "      <td>0.017506</td>\n",
       "      <td>-0.124092</td>\n",
       "      <td>-0.075807</td>\n",
       "      <td>0.103347</td>\n",
       "      <td>-0.243846</td>\n",
       "      <td>-0.078681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268512</td>\n",
       "      <td>-0.125241</td>\n",
       "      <td>-0.007594</td>\n",
       "      <td>-0.057029</td>\n",
       "      <td>-0.079064</td>\n",
       "      <td>-0.032695</td>\n",
       "      <td>0.172517</td>\n",
       "      <td>-0.117769</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>-0.066801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AGE</td>\n",
       "      <td>0.268024</td>\n",
       "      <td>0.182545</td>\n",
       "      <td>0.199023</td>\n",
       "      <td>-0.161430</td>\n",
       "      <td>0.204172</td>\n",
       "      <td>0.269054</td>\n",
       "      <td>-0.304582</td>\n",
       "      <td>0.081618</td>\n",
       "      <td>0.200053</td>\n",
       "      <td>-0.329299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.531152</td>\n",
       "      <td>0.323636</td>\n",
       "      <td>-0.642378</td>\n",
       "      <td>0.323636</td>\n",
       "      <td>0.046602</td>\n",
       "      <td>0.115603</td>\n",
       "      <td>-0.305612</td>\n",
       "      <td>-0.409628</td>\n",
       "      <td>-0.165550</td>\n",
       "      <td>-0.505406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DIS</td>\n",
       "      <td>-0.151892</td>\n",
       "      <td>-0.033950</td>\n",
       "      <td>-0.198405</td>\n",
       "      <td>0.294670</td>\n",
       "      <td>-0.111663</td>\n",
       "      <td>-0.165059</td>\n",
       "      <td>0.150575</td>\n",
       "      <td>-0.181964</td>\n",
       "      <td>-0.198678</td>\n",
       "      <td>0.064342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038187</td>\n",
       "      <td>0.207973</td>\n",
       "      <td>0.135698</td>\n",
       "      <td>-0.200624</td>\n",
       "      <td>-0.119810</td>\n",
       "      <td>-0.022656</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>-0.090611</td>\n",
       "      <td>0.050910</td>\n",
       "      <td>0.617507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RAD</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.328235</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.154322</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.241279</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067366</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>-0.241279</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.154322</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>-0.154322</td>\n",
       "      <td>-0.241279</td>\n",
       "      <td>-0.241279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAX</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>-0.263811</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>0.054891</td>\n",
       "      <td>-0.185567</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>-0.009995</td>\n",
       "      <td>-0.019537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193201</td>\n",
       "      <td>-0.185567</td>\n",
       "      <td>-0.197017</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>0.045349</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>-0.019537</td>\n",
       "      <td>-0.032895</td>\n",
       "      <td>-0.250453</td>\n",
       "      <td>-0.141674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>-0.069738</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>-0.197397</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>0.291965</td>\n",
       "      <td>-0.346333</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>-0.399525</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112291</td>\n",
       "      <td>-0.346333</td>\n",
       "      <td>0.079199</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>-0.069738</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>-0.346333</td>\n",
       "      <td>0.079199</td>\n",
       "      <td>0.015369</td>\n",
       "      <td>0.377071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>-0.622381</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.004978</td>\n",
       "      <td>0.040537</td>\n",
       "      <td>0.087639</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>0.085294</td>\n",
       "      <td>-0.777205</td>\n",
       "      <td>-0.033774</td>\n",
       "      <td>0.099314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052539</td>\n",
       "      <td>0.075536</td>\n",
       "      <td>0.051682</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.045499</td>\n",
       "      <td>0.090791</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>0.092329</td>\n",
       "      <td>0.096313</td>\n",
       "      <td>0.048832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LSTAT</td>\n",
       "      <td>0.292962</td>\n",
       "      <td>-0.197380</td>\n",
       "      <td>-0.152678</td>\n",
       "      <td>-0.039544</td>\n",
       "      <td>0.055103</td>\n",
       "      <td>0.156924</td>\n",
       "      <td>0.084353</td>\n",
       "      <td>0.278337</td>\n",
       "      <td>-0.014709</td>\n",
       "      <td>-0.098043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240979</td>\n",
       "      <td>0.476737</td>\n",
       "      <td>-0.141089</td>\n",
       "      <td>0.389540</td>\n",
       "      <td>0.074971</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>-0.200416</td>\n",
       "      <td>0.136505</td>\n",
       "      <td>-0.046442</td>\n",
       "      <td>-0.195449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              435       88        365       242       461       129       12   \\\n",
       "CRIM     0.084825 -0.039979  0.010592 -0.039459  0.000895 -0.030710 -0.039561   \n",
       "ZN      -0.113636 -0.113636 -0.113636  0.186364 -0.113636 -0.113636  0.011364   \n",
       "INDUS    0.255250 -0.283240  0.255250 -0.227521  0.255250  0.394180 -0.119750   \n",
       "CHAS    -0.069170 -0.069170 -0.069170 -0.069170 -0.069170 -0.069170 -0.069170   \n",
       "NOX      0.381286 -0.135175  0.336018 -0.260689  0.325730  0.142603 -0.063159   \n",
       "RM       0.065983  0.138411 -0.521869  0.014057  0.017506 -0.124092 -0.075807   \n",
       "AGE      0.268024  0.182545  0.199023 -0.161430  0.204172  0.269054 -0.304582   \n",
       "DIS     -0.151892 -0.033950 -0.198405  0.294670 -0.111663 -0.165059  0.150575   \n",
       "RAD      0.628287 -0.328235  0.628287 -0.154322  0.628287 -0.241279 -0.197800   \n",
       "TAX      0.491914 -0.263811  0.491914 -0.206559  0.491914  0.054891 -0.185567   \n",
       "PTRATIO  0.185582 -0.069738  0.185582 -0.197397  0.185582  0.291965 -0.346333   \n",
       "B       -0.622381  0.101432 -0.004978  0.040537  0.087639  0.101432  0.085294   \n",
       "LSTAT    0.292962 -0.197380 -0.152678 -0.039544  0.055103  0.156924  0.084353   \n",
       "\n",
       "              419       152       79   ...       228       8         73   \\\n",
       "CRIM     0.092152 -0.027953 -0.039672  ... -0.037264 -0.038241 -0.038419   \n",
       "ZN      -0.113636 -0.113636 -0.113636  ... -0.113636  0.011364 -0.113636   \n",
       "INDUS    0.255250  0.309502  0.062068  ... -0.180967 -0.119750 -0.011979   \n",
       "CHAS    -0.069170  0.930830 -0.069170  ... -0.069170 -0.069170 -0.069170   \n",
       "NOX      0.336018  0.650833 -0.242171  ... -0.104311 -0.063159 -0.291554   \n",
       "RM       0.103347 -0.243846 -0.078681  ...  0.268512 -0.125241 -0.007594   \n",
       "AGE      0.081618  0.200053 -0.329299  ... -0.531152  0.323636 -0.642378   \n",
       "DIS     -0.181964 -0.198678  0.064342  ... -0.038187  0.207973  0.135698   \n",
       "RAD      0.628287 -0.197800 -0.197800  ... -0.067366 -0.197800 -0.241279   \n",
       "TAX      0.491914 -0.009995 -0.019537  ... -0.193201 -0.185567 -0.197017   \n",
       "PTRATIO  0.185582 -0.399525  0.026007  ... -0.112291 -0.346333  0.079199   \n",
       "B       -0.777205 -0.033774  0.099314  ...  0.052539  0.075536  0.051682   \n",
       "LSTAT    0.278337 -0.014709 -0.098043  ... -0.240979  0.476737 -0.141089   \n",
       "\n",
       "              400       118       486       189       495       206       355  \n",
       "CRIM     0.240897 -0.039147  0.023359 -0.039674 -0.038603 -0.038033 -0.039417  \n",
       "ZN      -0.113636 -0.113636 -0.113636  0.336364 -0.113636 -0.113636  0.686364  \n",
       "INDUS    0.255250 -0.041304  0.255250 -0.282140 -0.053034 -0.020043 -0.338225  \n",
       "CHAS    -0.069170 -0.069170 -0.069170 -0.069170 -0.069170 -0.069170 -0.069170  \n",
       "NOX      0.284578 -0.015833  0.058241 -0.242171  0.062356 -0.135175 -0.291554  \n",
       "RM      -0.057029 -0.079064 -0.032695  0.172517 -0.117769  0.007926 -0.066801  \n",
       "AGE      0.323636  0.046602  0.115603 -0.305612 -0.409628 -0.165550 -0.505406  \n",
       "DIS     -0.200624 -0.119810 -0.022656  0.070170 -0.090611  0.050910  0.617507  \n",
       "RAD      0.628287 -0.154322  0.628287 -0.197800 -0.154322 -0.241279 -0.241279  \n",
       "TAX      0.491914  0.045349  0.491914 -0.019537 -0.032895 -0.250453 -0.141674  \n",
       "PTRATIO  0.185582 -0.069738  0.185582 -0.346333  0.079199  0.015369  0.377071  \n",
       "B        0.101432 -0.045499  0.090791  0.101432  0.092329  0.096313  0.048832  \n",
       "LSTAT    0.389540  0.074971  0.064209 -0.200416  0.136505 -0.046442 -0.195449  \n",
       "\n",
       "[13 rows x 339 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(339,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need y_train of dimension 1xm_train where m_train = number of training examples\n",
    "y_train = np.array([y_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 339)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model needs X_validation of dimension (number_features x number_validation_examples)\n",
    "X_val = X_val.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 167)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need y_val of dimension 1xm_val where m_val = number of training examples\n",
    "y_val = np.array([y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 167)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>435</th>\n",
       "      <th>88</th>\n",
       "      <th>365</th>\n",
       "      <th>242</th>\n",
       "      <th>461</th>\n",
       "      <th>129</th>\n",
       "      <th>12</th>\n",
       "      <th>419</th>\n",
       "      <th>152</th>\n",
       "      <th>79</th>\n",
       "      <th>...</th>\n",
       "      <th>228</th>\n",
       "      <th>8</th>\n",
       "      <th>73</th>\n",
       "      <th>400</th>\n",
       "      <th>118</th>\n",
       "      <th>486</th>\n",
       "      <th>189</th>\n",
       "      <th>495</th>\n",
       "      <th>206</th>\n",
       "      <th>355</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>CRIM</td>\n",
       "      <td>0.084825</td>\n",
       "      <td>-0.039979</td>\n",
       "      <td>0.010592</td>\n",
       "      <td>-0.039459</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>-0.030710</td>\n",
       "      <td>-0.039561</td>\n",
       "      <td>0.092152</td>\n",
       "      <td>-0.027953</td>\n",
       "      <td>-0.039672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037264</td>\n",
       "      <td>-0.038241</td>\n",
       "      <td>-0.038419</td>\n",
       "      <td>0.240897</td>\n",
       "      <td>-0.039147</td>\n",
       "      <td>0.023359</td>\n",
       "      <td>-0.039674</td>\n",
       "      <td>-0.038603</td>\n",
       "      <td>-0.038033</td>\n",
       "      <td>-0.039417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ZN</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>0.186364</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>-0.113636</td>\n",
       "      <td>0.686364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>INDUS</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>-0.283240</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>-0.227521</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>0.394180</td>\n",
       "      <td>-0.119750</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>0.309502</td>\n",
       "      <td>0.062068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180967</td>\n",
       "      <td>-0.119750</td>\n",
       "      <td>-0.011979</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>-0.041304</td>\n",
       "      <td>0.255250</td>\n",
       "      <td>-0.282140</td>\n",
       "      <td>-0.053034</td>\n",
       "      <td>-0.020043</td>\n",
       "      <td>-0.338225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CHAS</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>0.930830</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "      <td>-0.069170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NOX</td>\n",
       "      <td>0.381286</td>\n",
       "      <td>-0.135175</td>\n",
       "      <td>0.336018</td>\n",
       "      <td>-0.260689</td>\n",
       "      <td>0.325730</td>\n",
       "      <td>0.142603</td>\n",
       "      <td>-0.063159</td>\n",
       "      <td>0.336018</td>\n",
       "      <td>0.650833</td>\n",
       "      <td>-0.242171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104311</td>\n",
       "      <td>-0.063159</td>\n",
       "      <td>-0.291554</td>\n",
       "      <td>0.284578</td>\n",
       "      <td>-0.015833</td>\n",
       "      <td>0.058241</td>\n",
       "      <td>-0.242171</td>\n",
       "      <td>0.062356</td>\n",
       "      <td>-0.135175</td>\n",
       "      <td>-0.291554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RM</td>\n",
       "      <td>0.065983</td>\n",
       "      <td>0.138411</td>\n",
       "      <td>-0.521869</td>\n",
       "      <td>0.014057</td>\n",
       "      <td>0.017506</td>\n",
       "      <td>-0.124092</td>\n",
       "      <td>-0.075807</td>\n",
       "      <td>0.103347</td>\n",
       "      <td>-0.243846</td>\n",
       "      <td>-0.078681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268512</td>\n",
       "      <td>-0.125241</td>\n",
       "      <td>-0.007594</td>\n",
       "      <td>-0.057029</td>\n",
       "      <td>-0.079064</td>\n",
       "      <td>-0.032695</td>\n",
       "      <td>0.172517</td>\n",
       "      <td>-0.117769</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>-0.066801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AGE</td>\n",
       "      <td>0.268024</td>\n",
       "      <td>0.182545</td>\n",
       "      <td>0.199023</td>\n",
       "      <td>-0.161430</td>\n",
       "      <td>0.204172</td>\n",
       "      <td>0.269054</td>\n",
       "      <td>-0.304582</td>\n",
       "      <td>0.081618</td>\n",
       "      <td>0.200053</td>\n",
       "      <td>-0.329299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.531152</td>\n",
       "      <td>0.323636</td>\n",
       "      <td>-0.642378</td>\n",
       "      <td>0.323636</td>\n",
       "      <td>0.046602</td>\n",
       "      <td>0.115603</td>\n",
       "      <td>-0.305612</td>\n",
       "      <td>-0.409628</td>\n",
       "      <td>-0.165550</td>\n",
       "      <td>-0.505406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DIS</td>\n",
       "      <td>-0.151892</td>\n",
       "      <td>-0.033950</td>\n",
       "      <td>-0.198405</td>\n",
       "      <td>0.294670</td>\n",
       "      <td>-0.111663</td>\n",
       "      <td>-0.165059</td>\n",
       "      <td>0.150575</td>\n",
       "      <td>-0.181964</td>\n",
       "      <td>-0.198678</td>\n",
       "      <td>0.064342</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038187</td>\n",
       "      <td>0.207973</td>\n",
       "      <td>0.135698</td>\n",
       "      <td>-0.200624</td>\n",
       "      <td>-0.119810</td>\n",
       "      <td>-0.022656</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>-0.090611</td>\n",
       "      <td>0.050910</td>\n",
       "      <td>0.617507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RAD</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.328235</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.154322</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.241279</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067366</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>-0.241279</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.154322</td>\n",
       "      <td>0.628287</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>-0.154322</td>\n",
       "      <td>-0.241279</td>\n",
       "      <td>-0.241279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAX</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>-0.263811</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>-0.206559</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>0.054891</td>\n",
       "      <td>-0.185567</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>-0.009995</td>\n",
       "      <td>-0.019537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193201</td>\n",
       "      <td>-0.185567</td>\n",
       "      <td>-0.197017</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>0.045349</td>\n",
       "      <td>0.491914</td>\n",
       "      <td>-0.019537</td>\n",
       "      <td>-0.032895</td>\n",
       "      <td>-0.250453</td>\n",
       "      <td>-0.141674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PTRATIO</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>-0.069738</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>-0.197397</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>0.291965</td>\n",
       "      <td>-0.346333</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>-0.399525</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112291</td>\n",
       "      <td>-0.346333</td>\n",
       "      <td>0.079199</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>-0.069738</td>\n",
       "      <td>0.185582</td>\n",
       "      <td>-0.346333</td>\n",
       "      <td>0.079199</td>\n",
       "      <td>0.015369</td>\n",
       "      <td>0.377071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>B</td>\n",
       "      <td>-0.622381</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.004978</td>\n",
       "      <td>0.040537</td>\n",
       "      <td>0.087639</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>0.085294</td>\n",
       "      <td>-0.777205</td>\n",
       "      <td>-0.033774</td>\n",
       "      <td>0.099314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052539</td>\n",
       "      <td>0.075536</td>\n",
       "      <td>0.051682</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>-0.045499</td>\n",
       "      <td>0.090791</td>\n",
       "      <td>0.101432</td>\n",
       "      <td>0.092329</td>\n",
       "      <td>0.096313</td>\n",
       "      <td>0.048832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LSTAT</td>\n",
       "      <td>0.292962</td>\n",
       "      <td>-0.197380</td>\n",
       "      <td>-0.152678</td>\n",
       "      <td>-0.039544</td>\n",
       "      <td>0.055103</td>\n",
       "      <td>0.156924</td>\n",
       "      <td>0.084353</td>\n",
       "      <td>0.278337</td>\n",
       "      <td>-0.014709</td>\n",
       "      <td>-0.098043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240979</td>\n",
       "      <td>0.476737</td>\n",
       "      <td>-0.141089</td>\n",
       "      <td>0.389540</td>\n",
       "      <td>0.074971</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>-0.200416</td>\n",
       "      <td>0.136505</td>\n",
       "      <td>-0.046442</td>\n",
       "      <td>-0.195449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              435       88        365       242       461       129       12   \\\n",
       "CRIM     0.084825 -0.039979  0.010592 -0.039459  0.000895 -0.030710 -0.039561   \n",
       "ZN      -0.113636 -0.113636 -0.113636  0.186364 -0.113636 -0.113636  0.011364   \n",
       "INDUS    0.255250 -0.283240  0.255250 -0.227521  0.255250  0.394180 -0.119750   \n",
       "CHAS    -0.069170 -0.069170 -0.069170 -0.069170 -0.069170 -0.069170 -0.069170   \n",
       "NOX      0.381286 -0.135175  0.336018 -0.260689  0.325730  0.142603 -0.063159   \n",
       "RM       0.065983  0.138411 -0.521869  0.014057  0.017506 -0.124092 -0.075807   \n",
       "AGE      0.268024  0.182545  0.199023 -0.161430  0.204172  0.269054 -0.304582   \n",
       "DIS     -0.151892 -0.033950 -0.198405  0.294670 -0.111663 -0.165059  0.150575   \n",
       "RAD      0.628287 -0.328235  0.628287 -0.154322  0.628287 -0.241279 -0.197800   \n",
       "TAX      0.491914 -0.263811  0.491914 -0.206559  0.491914  0.054891 -0.185567   \n",
       "PTRATIO  0.185582 -0.069738  0.185582 -0.197397  0.185582  0.291965 -0.346333   \n",
       "B       -0.622381  0.101432 -0.004978  0.040537  0.087639  0.101432  0.085294   \n",
       "LSTAT    0.292962 -0.197380 -0.152678 -0.039544  0.055103  0.156924  0.084353   \n",
       "\n",
       "              419       152       79   ...       228       8         73   \\\n",
       "CRIM     0.092152 -0.027953 -0.039672  ... -0.037264 -0.038241 -0.038419   \n",
       "ZN      -0.113636 -0.113636 -0.113636  ... -0.113636  0.011364 -0.113636   \n",
       "INDUS    0.255250  0.309502  0.062068  ... -0.180967 -0.119750 -0.011979   \n",
       "CHAS    -0.069170  0.930830 -0.069170  ... -0.069170 -0.069170 -0.069170   \n",
       "NOX      0.336018  0.650833 -0.242171  ... -0.104311 -0.063159 -0.291554   \n",
       "RM       0.103347 -0.243846 -0.078681  ...  0.268512 -0.125241 -0.007594   \n",
       "AGE      0.081618  0.200053 -0.329299  ... -0.531152  0.323636 -0.642378   \n",
       "DIS     -0.181964 -0.198678  0.064342  ... -0.038187  0.207973  0.135698   \n",
       "RAD      0.628287 -0.197800 -0.197800  ... -0.067366 -0.197800 -0.241279   \n",
       "TAX      0.491914 -0.009995 -0.019537  ... -0.193201 -0.185567 -0.197017   \n",
       "PTRATIO  0.185582 -0.399525  0.026007  ... -0.112291 -0.346333  0.079199   \n",
       "B       -0.777205 -0.033774  0.099314  ...  0.052539  0.075536  0.051682   \n",
       "LSTAT    0.278337 -0.014709 -0.098043  ... -0.240979  0.476737 -0.141089   \n",
       "\n",
       "              400       118       486       189       495       206       355  \n",
       "CRIM     0.240897 -0.039147  0.023359 -0.039674 -0.038603 -0.038033 -0.039417  \n",
       "ZN      -0.113636 -0.113636 -0.113636  0.336364 -0.113636 -0.113636  0.686364  \n",
       "INDUS    0.255250 -0.041304  0.255250 -0.282140 -0.053034 -0.020043 -0.338225  \n",
       "CHAS    -0.069170 -0.069170 -0.069170 -0.069170 -0.069170 -0.069170 -0.069170  \n",
       "NOX      0.284578 -0.015833  0.058241 -0.242171  0.062356 -0.135175 -0.291554  \n",
       "RM      -0.057029 -0.079064 -0.032695  0.172517 -0.117769  0.007926 -0.066801  \n",
       "AGE      0.323636  0.046602  0.115603 -0.305612 -0.409628 -0.165550 -0.505406  \n",
       "DIS     -0.200624 -0.119810 -0.022656  0.070170 -0.090611  0.050910  0.617507  \n",
       "RAD      0.628287 -0.154322  0.628287 -0.197800 -0.154322 -0.241279 -0.241279  \n",
       "TAX      0.491914  0.045349  0.491914 -0.019537 -0.032895 -0.250453 -0.141674  \n",
       "PTRATIO  0.185582 -0.069738  0.185582 -0.346333  0.079199  0.015369  0.377071  \n",
       "B        0.101432 -0.045499  0.090791  0.101432  0.092329  0.096313  0.048832  \n",
       "LSTAT    0.389540  0.074971  0.064209 -0.200416  0.136505 -0.046442 -0.195449  \n",
       "\n",
       "[13 rows x 339 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding prepared dataset in our Linear Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 1/500: \n",
      "Training cost 295.76628961844835|Validation cost 135.01196703457362\n",
      "Training MAE 22.529026234948876|Validation MAE 13.582347972694881\n",
      "Epochs 2/500: \n",
      "Training cost 127.7798910358148|Validation cost 73.07740190991572\n",
      "Training MAE 13.572054643003636|Validation MAE 8.628948122089996\n",
      "Epochs 3/500: \n",
      "Training cost 65.66038239510812|Validation cost 49.43322921034916\n",
      "Training MAE 8.630757980439347|Validation MAE 6.351606479551205\n",
      "Epochs 4/500: \n",
      "Training cost 42.05429225868819|Validation cost 39.90261381076111\n",
      "Training MAE 6.182344136009521|Validation MAE 5.5454493870958\n",
      "Epochs 5/500: \n",
      "Training cost 32.6042356375534|Validation cost 35.69015261508335\n",
      "Training MAE 5.215291259187475|Validation MAE 5.313272990285027\n",
      "Epochs 6/500: \n",
      "Training cost 28.459384227006037|Validation cost 33.55976900477639\n",
      "Training MAE 4.941493288376403|Validation MAE 5.284080511947825\n",
      "Epochs 7/500: \n",
      "Training cost 26.37407790199285|Validation cost 32.29598561684301\n",
      "Training MAE 4.8863014519892065|Validation MAE 5.292391379103824\n",
      "Epochs 8/500: \n",
      "Training cost 25.13763455500955|Validation cost 31.42567398884533\n",
      "Training MAE 4.873983401291748|Validation MAE 5.2831004705491695\n",
      "Epochs 9/500: \n",
      "Training cost 24.28435400405447|Validation cost 30.75389487804293\n",
      "Training MAE 4.855693156029187|Validation MAE 5.25646895458486\n",
      "Epochs 10/500: \n",
      "Training cost 23.62554489938882|Validation cost 30.193624736074156\n",
      "Training MAE 4.828752775610308|Validation MAE 5.220470396746767\n",
      "Epochs 11/500: \n",
      "Training cost 23.078458703662147|Validation cost 29.702096697500508\n",
      "Training MAE 4.794573339684574|Validation MAE 5.1797814378458735\n",
      "Epochs 12/500: \n",
      "Training cost 22.60285653376844|Validation cost 29.256192753492364\n",
      "Training MAE 4.755560727079814|Validation MAE 5.138100963111533\n",
      "Epochs 13/500: \n",
      "Training cost 22.17686785444069|Validation cost 28.84240041710643\n",
      "Training MAE 4.714991955677462|Validation MAE 5.095407007694626\n",
      "Epochs 14/500: \n",
      "Training cost 21.78738254427961|Validation cost 28.452378510034062\n",
      "Training MAE 4.675913645628255|Validation MAE 5.051856753740821\n",
      "Epochs 15/500: \n",
      "Training cost 21.425949289651328|Validation cost 28.08080020557183\n",
      "Training MAE 4.636068433804822|Validation MAE 5.0083044281637585\n",
      "Epochs 16/500: \n",
      "Training cost 21.08684904002512|Validation cost 27.72419498378622\n",
      "Training MAE 4.596515021592649|Validation MAE 4.965356483554974\n",
      "Epochs 17/500: \n",
      "Training cost 20.76608661467719|Validation cost 27.380273334525246\n",
      "Training MAE 4.557245471584136|Validation MAE 4.923410124272184\n",
      "Epochs 18/500: \n",
      "Training cost 20.460807434602746|Validation cost 27.0475093805232\n",
      "Training MAE 4.519254646074456|Validation MAE 4.88217192557123\n",
      "Epochs 19/500: \n",
      "Training cost 20.168933468562187|Validation cost 26.724873585493498\n",
      "Training MAE 4.4819516422644545|Validation MAE 4.842028970554181\n",
      "Epochs 20/500: \n",
      "Training cost 19.888924368191248|Validation cost 26.41165830605923\n",
      "Training MAE 4.445622352458254|Validation MAE 4.8040126066434965\n",
      "Epochs 21/500: \n",
      "Training cost 19.619616024358844|Validation cost 26.107363018838573\n",
      "Training MAE 4.409959680260867|Validation MAE 4.767214601797425\n",
      "Epochs 22/500: \n",
      "Training cost 19.360109615364273|Validation cost 25.811618738394632\n",
      "Training MAE 4.375708125023631|Validation MAE 4.732053952505819\n",
      "Epochs 23/500: \n",
      "Training cost 19.10969464771066|Validation cost 25.524138451556507\n",
      "Training MAE 4.3425773391991145|Validation MAE 4.69878058394266\n",
      "Epochs 24/500: \n",
      "Training cost 18.867795292778993|Validation cost 25.24468489320111\n",
      "Training MAE 4.310286101764332|Validation MAE 4.66628539234198\n",
      "Epochs 25/500: \n",
      "Training cost 18.63393284329965|Validation cost 24.97304987860597\n",
      "Training MAE 4.278568565040821|Validation MAE 4.634594630717112\n",
      "Epochs 26/500: \n",
      "Training cost 18.407699381723262|Validation cost 24.709041310882967\n",
      "Training MAE 4.247465161894719|Validation MAE 4.603431970075716\n",
      "Epochs 27/500: \n",
      "Training cost 18.188739268722667|Validation cost 24.45247525330748\n",
      "Training MAE 4.217401484235173|Validation MAE 4.57278413183669\n",
      "Epochs 28/500: \n",
      "Training cost 17.976736094867768|Validation cost 24.203171311872822\n",
      "Training MAE 4.187946729483381|Validation MAE 4.542638217255647\n",
      "Epochs 29/500: \n",
      "Training cost 17.77140345285646|Validation cost 23.960950151266527\n",
      "Training MAE 4.159301570591877|Validation MAE 4.513173055721422\n",
      "Epochs 30/500: \n",
      "Training cost 17.572478383769532|Validation cost 23.725632358360134\n",
      "Training MAE 4.13126226302935|Validation MAE 4.484815257542244\n",
      "Epochs 31/500: \n",
      "Training cost 17.37971669641345|Validation cost 23.497038131697973\n",
      "Training MAE 4.104043055373333|Validation MAE 4.458111638432566\n",
      "Epochs 32/500: \n",
      "Training cost 17.19288959996629|Validation cost 23.274987454057015\n",
      "Training MAE 4.077779466749953|Validation MAE 4.433516151626942\n",
      "Epochs 33/500: \n",
      "Training cost 17.011781258557686|Validation cost 23.059300525460525\n",
      "Training MAE 4.05205273950701|Validation MAE 4.41101338974682\n",
      "Epochs 34/500: \n",
      "Training cost 16.83618699408459|Validation cost 22.84979831475129\n",
      "Training MAE 4.026934083502432|Validation MAE 4.388872745158107\n",
      "Epochs 35/500: \n",
      "Training cost 16.66591194580105|Validation cost 22.64630314167462\n",
      "Training MAE 4.002215340085256|Validation MAE 4.3672685200495005\n",
      "Epochs 36/500: \n",
      "Training cost 16.50077005270132|Validation cost 22.448639237044514\n",
      "Training MAE 3.9785897186587116|Validation MAE 4.3464857630569655\n",
      "Epochs 37/500: \n",
      "Training cost 16.340583264897447|Validation cost 22.256633251866123\n",
      "Training MAE 3.9562670217347122|Validation MAE 4.326017894808018\n",
      "Epochs 38/500: \n",
      "Training cost 16.18518091828407|Validation cost 22.07011470128377\n",
      "Training MAE 3.934730134626283|Validation MAE 4.305858587878406\n",
      "Epochs 39/500: \n",
      "Training cost 16.034399226424593|Validation cost 21.888916338654788\n",
      "Training MAE 3.913807725603552|Validation MAE 4.286069026441264\n",
      "Epochs 40/500: \n",
      "Training cost 15.888080857327212|Validation cost 21.71287446077664\n",
      "Training MAE 3.8932028675078687|Validation MAE 4.26722842766272\n",
      "Epochs 41/500: \n",
      "Training cost 15.746074572385357|Validation cost 21.541829148582615\n",
      "Training MAE 3.8730202941517335|Validation MAE 4.248982160926884\n",
      "Epochs 42/500: \n",
      "Training cost 15.608234911476671|Validation cost 21.375624449324732\n",
      "Training MAE 3.8538292628283193|Validation MAE 4.231639287433512\n",
      "Epochs 43/500: \n",
      "Training cost 15.474421912917013|Validation cost 21.214108506956254\n",
      "Training MAE 3.835228987599157|Validation MAE 4.214544457955782\n",
      "Epochs 44/500: \n",
      "Training cost 15.344500860257545|Validation cost 21.05713364749673\n",
      "Training MAE 3.817179424337214|Validation MAE 4.197693062157078\n",
      "Epochs 45/500: \n",
      "Training cost 15.218342050218947|Validation cost 20.90455642586364\n",
      "Training MAE 3.799661485595168|Validation MAE 4.181080635471447\n",
      "Epochs 46/500: \n",
      "Training cost 15.09582057767272|Validation cost 20.75623764015471\n",
      "Training MAE 3.7825549527994866|Validation MAE 4.16470284694132\n",
      "Epochs 47/500: \n",
      "Training cost 14.976816134714108|Validation cost 20.612042318771007\n",
      "Training MAE 3.7662963082532963|Validation MAE 4.148948694011043\n",
      "Epochs 48/500: \n",
      "Training cost 14.861212821667738|Validation cost 20.471839685150965\n",
      "Training MAE 3.750693964121301|Validation MAE 4.133611835737603\n",
      "Epochs 49/500: \n",
      "Training cost 14.748898968428524|Validation cost 20.33550310427989\n",
      "Training MAE 3.736176585003208|Validation MAE 4.118869203532842\n",
      "Epochs 50/500: \n",
      "Training cost 14.639766964936237|Validation cost 20.20291001457261\n",
      "Training MAE 3.722164854766168|Validation MAE 4.105014914161414\n",
      "Epochs 51/500: \n",
      "Training cost 14.533713099862815|Validation cost 20.073941848209323\n",
      "Training MAE 3.709050281972834|Validation MAE 4.09135013196323\n",
      "Epochs 52/500: \n",
      "Training cost 14.430637406791057|Validation cost 19.948483942542378\n",
      "Training MAE 3.696561970109059|Validation MAE 4.078352317100405\n",
      "Epochs 53/500: \n",
      "Training cost 14.330443517306245|Validation cost 19.826425444783343\n",
      "Training MAE 3.6842505858355605|Validation MAE 4.0657643225997555\n",
      "Epochs 54/500: \n",
      "Training cost 14.233038520525422|Validation cost 19.707659211823948\n",
      "Training MAE 3.6721964400406044|Validation MAE 4.053343827677504\n",
      "Epochs 55/500: \n",
      "Training cost 14.138332828664154|Validation cost 19.5920817067367\n",
      "Training MAE 3.6604098917285066|Validation MAE 4.041088092983069\n",
      "Epochs 56/500: \n",
      "Training cost 14.046240048296074|Validation cost 19.4795928932362\n",
      "Training MAE 3.64912605569803|Validation MAE 4.028994426441671\n",
      "Epochs 57/500: \n",
      "Training cost 13.956676857002227|Validation cost 19.370096129156554\n",
      "Training MAE 3.6381244347583195|Validation MAE 4.017080272750696\n",
      "Epochs 58/500: \n",
      "Training cost 13.869562885138846|Validation cost 19.26349805980811\n",
      "Training MAE 3.6272725182201473|Validation MAE 4.006324634626171\n",
      "Epochs 59/500: \n",
      "Training cost 13.784820602477065|Validation cost 19.15970851191422\n",
      "Training MAE 3.6165679171660168|Validation MAE 3.9958339924447044\n",
      "Epochs 60/500: \n",
      "Training cost 13.702375209487885|Validation cost 19.058640388691693\n",
      "Training MAE 3.6060082833213833|Validation MAE 3.9854722396474527\n",
      "Epochs 61/500: \n",
      "Training cost 13.622154533061762|Validation cost 18.9602095665234\n",
      "Training MAE 3.5955913086105284|Validation MAE 3.9752373795504914\n",
      "Epochs 62/500: \n",
      "Training cost 13.544088926465925|Validation cost 18.864334793574965\n",
      "Training MAE 3.5853147246658907|Validation MAE 3.9651274490389463\n",
      "Epochs 63/500: \n",
      "Training cost 13.468111173353915|Validation cost 18.770937590627103\n",
      "Training MAE 3.575178225943834|Validation MAE 3.9552744052833764\n",
      "Epochs 64/500: \n",
      "Training cost 13.394156395652349|Validation cost 18.679942154328003\n",
      "Training MAE 3.5652711388501506|Validation MAE 3.945798552038143\n",
      "Epochs 65/500: \n",
      "Training cost 13.322161965158635|Validation cost 18.591275263014676\n",
      "Training MAE 3.55566821988276|Validation MAE 3.9364348805599296\n",
      "Epochs 66/500: \n",
      "Training cost 13.252067418691821|Validation cost 18.50486618520636\n",
      "Training MAE 3.546397967087928|Validation MAE 3.927465953373721\n",
      "Epochs 67/500: \n",
      "Training cost 13.183814376646271|Validation cost 18.42064659083539\n",
      "Training MAE 3.5375857074526555|Validation MAE 3.918965483102993\n",
      "Epochs 68/500: \n",
      "Training cost 13.117346464804784|Validation cost 18.338550465249867\n",
      "Training MAE 3.5288898456992097|Validation MAE 3.9106440605331425\n",
      "Epochs 69/500: \n",
      "Training cost 13.052609239274323|Validation cost 18.258514025997734\n",
      "Training MAE 3.5203085379961987|Validation MAE 3.902615213502193\n",
      "Epochs 70/500: \n",
      "Training cost 12.989550114413728|Validation cost 18.180475642381168\n",
      "Training MAE 3.511946380375528|Validation MAE 3.894673017824289\n",
      "Epochs 71/500: \n",
      "Training cost 12.928118293628422|Validation cost 18.104375757754188\n",
      "Training MAE 3.5038467195863334|Validation MAE 3.886816309609875\n",
      "Epochs 72/500: \n",
      "Training cost 12.868264702912805|Validation cost 18.03015681452345\n",
      "Training MAE 3.4961525498372397|Validation MAE 3.8791424128152467\n",
      "Epochs 73/500: \n",
      "Training cost 12.80994192702598|Validation cost 17.957763181801944\n",
      "Training MAE 3.4885590903454196|Validation MAE 3.8716402517395054\n",
      "Epochs 74/500: \n",
      "Training cost 12.753104148191658|Validation cost 17.887141085657614\n",
      "Training MAE 3.481064748831719|Validation MAE 3.8642151285646897\n",
      "Epochs 75/500: \n",
      "Training cost 12.697707087217614|Validation cost 17.8182385418931\n",
      "Training MAE 3.47371146089731|Validation MAE 3.857294008686601\n",
      "Epochs 76/500: \n",
      "Training cost 12.643707946934668|Validation cost 17.7510052912884\n",
      "Training MAE 3.466521676253581|Validation MAE 3.8507640870269673\n",
      "Epochs 77/500: \n",
      "Training cost 12.59106535785939|Validation cost 17.68539273723528\n",
      "Training MAE 3.459424833858643|Validation MAE 3.8442978317808496\n",
      "Epochs 78/500: \n",
      "Training cost 12.539739325988899|Validation cost 17.62135388569046\n",
      "Training MAE 3.4524194759685836|Validation MAE 3.837894476505963\n",
      "Epochs 79/500: \n",
      "Training cost 12.489691182639913|Validation cost 17.55884328737342\n",
      "Training MAE 3.445504170546744|Validation MAE 3.8315532658657343\n",
      "Epochs 80/500: \n",
      "Training cost 12.440883536248121|Validation cost 17.497816982134506\n",
      "Training MAE 3.4388601499779714|Validation MAE 3.8254468407949154\n",
      "Epochs 81/500: \n",
      "Training cost 12.393280226047379|Validation cost 17.438232445419043\n",
      "Training MAE 3.4326368269517515|Validation MAE 3.8200629111624087\n",
      "Epochs 82/500: \n",
      "Training cost 12.346846277551693|Validation cost 17.380048536754124\n",
      "Training MAE 3.426573751687213|Validation MAE 3.815300649618993\n",
      "Epochs 83/500: \n",
      "Training cost 12.301547859766234|Validation cost 17.323225450185628\n",
      "Training MAE 3.4207395361737762|Validation MAE 3.8105726126477144\n",
      "Epochs 84/500: \n",
      "Training cost 12.257352244056786|Validation cost 17.267724666594322\n",
      "Training MAE 3.4149798480192977|Validation MAE 3.805878565786242\n",
      "Epochs 85/500: \n",
      "Training cost 12.214227764609932|Validation cost 17.213508907821836\n",
      "Training MAE 3.409293513436351|Validation MAE 3.8012182754207955\n",
      "Epochs 86/500: \n",
      "Training cost 12.172143780419185|Validation cost 17.16054209253844\n",
      "Training MAE 3.403753797838003|Validation MAE 3.796591508811456\n",
      "Epochs 87/500: \n",
      "Training cost 12.131070638735098|Validation cost 17.108789293786995\n",
      "Training MAE 3.398286360788368|Validation MAE 3.7919980341147834\n",
      "Epochs 88/500: \n",
      "Training cost 12.090979639919786|Validation cost 17.058216698139024\n",
      "Training MAE 3.392887078391853|Validation MAE 3.7874376204041194\n",
      "Epochs 89/500: \n",
      "Training cost 12.05184300364904|Validation cost 17.008791566400955\n",
      "Training MAE 3.387554910344908|Validation MAE 3.7829100376879032\n",
      "Epochs 90/500: \n",
      "Training cost 12.013633836407447|Validation cost 16.960482195810595\n",
      "Training MAE 3.3822888342227815|Validation MAE 3.778415056926285\n",
      "Epochs 91/500: \n",
      "Training cost 11.976326100224256|Validation cost 16.913257883665956\n",
      "Training MAE 3.3771481940508776|Validation MAE 3.773952450046231\n",
      "Epochs 92/500: \n",
      "Training cost 11.939894582599994|Validation cost 16.86708889233054\n",
      "Training MAE 3.3721468759359117|Validation MAE 3.7695219899553685\n",
      "Epochs 93/500: \n",
      "Training cost 11.90431486757581|Validation cost 16.82194641556113\n",
      "Training MAE 3.3672059548737816|Validation MAE 3.7651234505546776\n",
      "Epochs 94/500: \n",
      "Training cost 11.869563307899655|Validation cost 16.777802546106347\n",
      "Training MAE 3.3624563956301214|Validation MAE 3.7607566067501983\n",
      "Epochs 95/500: \n",
      "Training cost 11.835616998245246|Validation cost 16.73463024452582\n",
      "Training MAE 3.357957840352868|Validation MAE 3.756421234463857\n",
      "Epochs 96/500: \n",
      "Training cost 11.802453749441627|Validation cost 16.69240330918197\n",
      "Training MAE 3.353568762872978|Validation MAE 3.752117110643503\n",
      "Epochs 97/500: \n",
      "Training cost 11.770052063672908|Validation cost 16.65109634735822\n",
      "Training MAE 3.3493074291999267|Validation MAE 3.747872083414484\n",
      "Epochs 98/500: \n",
      "Training cost 11.738391110609474|Validation cost 16.610684747459054\n",
      "Training MAE 3.345259171245235|Validation MAE 3.7436974247581354\n",
      "Epochs 99/500: \n",
      "Training cost 11.707450704433423|Validation cost 16.571144652249412\n",
      "Training MAE 3.341258164568959|Validation MAE 3.7395529098036633\n",
      "Epochs 100/500: \n",
      "Training cost 11.67721128172283|Validation cost 16.532452933092202\n",
      "Training MAE 3.3373552889382174|Validation MAE 3.7354383178400234\n",
      "Epochs 101/500: \n",
      "Training cost 11.647653880160517|Validation cost 16.494587165144658\n",
      "Training MAE 3.3335628380581603|Validation MAE 3.7313534293861648\n",
      "Epochs 102/500: \n",
      "Training cost 11.618760118034816|Validation cost 16.457525603475734\n",
      "Training MAE 3.3298143859242075|Validation MAE 3.7274764298757286\n",
      "Epochs 103/500: \n",
      "Training cost 11.590512174500859|Validation cost 16.42124716006812\n",
      "Training MAE 3.326142232591557|Validation MAE 3.7237080233180313\n",
      "Epochs 104/500: \n",
      "Training cost 11.562892770572436|Validation cost 16.385731381670194\n",
      "Training MAE 3.3225997855122418|Validation MAE 3.7199658536447466\n",
      "Epochs 105/500: \n",
      "Training cost 11.535885150815522|Validation cost 16.350958428464335\n",
      "Training MAE 3.3190978402981877|Validation MAE 3.7162497238563423\n",
      "Epochs 106/500: \n",
      "Training cost 11.509473065715952|Validation cost 16.31690905351955\n",
      "Training MAE 3.315635794109642|Validation MAE 3.7125594385215583\n",
      "Epochs 107/500: \n",
      "Training cost 11.483640754694717|Validation cost 16.283564582997702\n",
      "Training MAE 3.3122130545035082|Validation MAE 3.708894803758284\n",
      "Epochs 108/500: \n",
      "Training cost 11.458372929745455|Validation cost 16.250906897083745\n",
      "Training MAE 3.3088290392358086|Validation MAE 3.705255627214882\n",
      "Epochs 109/500: \n",
      "Training cost 11.433654759669881|Validation cost 16.218918411611572\n",
      "Training MAE 3.3055085083673568|Validation MAE 3.701731118814787\n",
      "Epochs 110/500: \n",
      "Training cost 11.409471854887697|Validation cost 16.18758206035844\n",
      "Training MAE 3.3024047619054113|Validation MAE 3.698348188484526\n",
      "Epochs 111/500: \n",
      "Training cost 11.385810252798677|Validation cost 16.15688127798179\n",
      "Training MAE 3.299376070442377|Validation MAE 3.6949883841597218\n",
      "Epochs 112/500: \n",
      "Training cost 11.3626564036754|Validation cost 16.12679998357342\n",
      "Training MAE 3.296379480734117|Validation MAE 3.6916515344885394\n",
      "Epochs 113/500: \n",
      "Training cost 11.339997157066032|Validation cost 16.097322564807175\n",
      "Training MAE 3.293478308213141|Validation MAE 3.688337469485409\n",
      "Epochs 114/500: \n",
      "Training cost 11.317819748687421|Validation cost 16.06843386265691\n",
      "Training MAE 3.290736785283153|Validation MAE 3.6850460205134867\n",
      "Epochs 115/500: \n",
      "Training cost 11.296111787789537|Validation cost 16.04011915666285\n",
      "Training MAE 3.288061301793481|Validation MAE 3.6817770202675764\n",
      "Epochs 116/500: \n",
      "Training cost 11.274861244973023|Validation cost 16.012364150725013\n",
      "Training MAE 3.2854651834660675|Validation MAE 3.678530302757514\n",
      "Epochs 117/500: \n",
      "Training cost 11.254056440442506|Validation cost 15.985154959403438\n",
      "Training MAE 3.282921404881158|Validation MAE 3.675305703291981\n",
      "Epochs 118/500: \n",
      "Training cost 11.233686032678854|Validation cost 15.958478094705704\n",
      "Training MAE 3.2804027624864456|Validation MAE 3.6721030584627523\n",
      "Epochs 119/500: \n",
      "Training cost 11.213739007514294|Validation cost 15.93232045334304\n",
      "Training MAE 3.277908922174571|Validation MAE 3.668922206129358\n",
      "Epochs 120/500: \n",
      "Training cost 11.194204667595088|Validation cost 15.90666930443703\n",
      "Training MAE 3.275439555159065|Validation MAE 3.6657629854041365\n",
      "Epochs 121/500: \n",
      "Training cost 11.17507262221682|Validation cost 15.881512277659738\n",
      "Training MAE 3.2729943378780124|Validation MAE 3.662641585201183\n",
      "Epochs 122/500: \n",
      "Training cost 11.156332777518255|Validation cost 15.856837351790663\n",
      "Training MAE 3.270572951899604|Validation MAE 3.6596766183697667\n",
      "Epochs 123/500: \n",
      "Training cost 11.137975327020012|Validation cost 15.832632843674789\n",
      "Training MAE 3.2681750838295636|Validation MAE 3.6569270984620594\n",
      "Epochs 124/500: \n",
      "Training cost 11.119990742495041|Validation cost 15.808887397566266\n",
      "Training MAE 3.26580042522039|Validation MAE 3.654231394675635\n",
      "Epochs 125/500: \n",
      "Training cost 11.102369765158354|Validation cost 15.785589974843376\n",
      "Training MAE 3.263448672482407|Validation MAE 3.651550472606974\n",
      "Epochs 126/500: \n",
      "Training cost 11.08510339716391|Validation cost 15.762729844080571\n",
      "Training MAE 3.2611195267965436|Validation MAE 3.6488842820650302\n",
      "Epochs 127/500: \n",
      "Training cost 11.068182893397125|Validation cost 15.740296571464226\n",
      "Training MAE 3.258812694028837|Validation MAE 3.6462327721030294\n",
      "Epochs 128/500: \n",
      "Training cost 11.051599753551878|Validation cost 15.718280011539083\n",
      "Training MAE 3.2565278846466157|Validation MAE 3.643595891044044\n",
      "Epochs 129/500: \n",
      "Training cost 11.035345714481357|Validation cost 15.696670298273109\n",
      "Training MAE 3.2542648136363272|Validation MAE 3.64104615787525\n",
      "Epochs 130/500: \n",
      "Training cost 11.01941274281249|Validation cost 15.67545783642872\n",
      "Training MAE 3.252023200422977|Validation MAE 3.638711577107646\n",
      "Epochs 131/500: \n",
      "Training cost 11.003793027814107|Validation cost 15.654633293229033\n",
      "Training MAE 3.249896227256357|Validation MAE 3.636388730569637\n",
      "Epochs 132/500: \n",
      "Training cost 10.988478974509455|Validation cost 15.634187590308116\n",
      "Training MAE 3.24787961063504|Validation MAE 3.634077592928788\n",
      "Epochs 133/500: \n",
      "Training cost 10.973463197023902|Validation cost 15.614111895934705\n",
      "Training MAE 3.2458814505066123|Validation MAE 3.631778137934844\n",
      "Epochs 134/500: \n",
      "Training cost 10.958738512159155|Validation cost 15.594397617499231\n",
      "Training MAE 3.2440737392733534|Validation MAE 3.629490338445625\n",
      "Epochs 135/500: \n",
      "Training cost 10.944297933185661|Validation cost 15.575036394254495\n",
      "Training MAE 3.2423442530567694|Validation MAE 3.627214166452455\n",
      "Epochs 136/500: \n",
      "Training cost 10.930134663845054|Validation cost 15.55602009030055\n",
      "Training MAE 3.2406298767073785|Validation MAE 3.6249495931051383\n",
      "Epochs 137/500: \n",
      "Training cost 10.916242092555018|Validation cost 15.53734078780491\n",
      "Training MAE 3.2389304222212645|Validation MAE 3.6226965887364777\n",
      "Epochs 138/500: \n",
      "Training cost 10.902613786809052|Validation cost 15.51899078044942\n",
      "Training MAE 3.2372799430950776|Validation MAE 3.6204551228863435\n",
      "Epochs 139/500: \n",
      "Training cost 10.889243487764093|Validation cost 15.500962567095453\n",
      "Training MAE 3.235681298543442|Validation MAE 3.6182251643253105\n",
      "Epochs 140/500: \n",
      "Training cost 10.876125105009049|Validation cost 15.48324884565959\n",
      "Training MAE 3.2342052210901335|Validation MAE 3.616006681077852\n",
      "Epochs 141/500: \n",
      "Training cost 10.863252711507734|Validation cost 15.465842507192011\n",
      "Training MAE 3.232741681593004|Validation MAE 3.613799640445096\n",
      "Epochs 142/500: \n",
      "Training cost 10.85062053870981|Validation cost 15.448736630150352\n",
      "Training MAE 3.2312905244143555|Validation MAE 3.6116040090271735\n",
      "Epochs 143/500: \n",
      "Training cost 10.838222971823694|Validation cost 15.431924474861873\n",
      "Training MAE 3.2298515963322676|Validation MAE 3.6094197527451395\n",
      "Epochs 144/500: \n",
      "Training cost 10.826054545245537|Validation cost 15.415399478167199\n",
      "Training MAE 3.2284247464971605|Validation MAE 3.607246836862472\n",
      "Epochs 145/500: \n",
      "Training cost 10.814109938138685|Validation cost 15.399155248239124\n",
      "Training MAE 3.227009826389224|Validation MAE 3.6050852260061736\n",
      "Epochs 146/500: \n",
      "Training cost 10.802383970158218|Validation cost 15.383185559570155\n",
      "Training MAE 3.2256066897766833|Validation MAE 3.6029348841874715\n",
      "Epochs 147/500: \n",
      "Training cost 10.790871597315299|Validation cost 15.367484348122758\n",
      "Training MAE 3.2242151926748903|Validation MAE 3.6007957748221067\n",
      "Epochs 148/500: \n",
      "Training cost 10.779567907976434|Validation cost 15.352045706636593\n",
      "Training MAE 3.22291642861218|Validation MAE 3.59866786075025\n",
      "Epochs 149/500: \n",
      "Training cost 10.76846811899276|Validation cost 15.336863880087042\n",
      "Training MAE 3.2216410971430567|Validation MAE 3.5965511042560143\n",
      "Epochs 150/500: \n",
      "Training cost 10.757567571954745|Validation cost 15.321933261289788\n",
      "Training MAE 3.220375878753991|Validation MAE 3.5944454670865986\n",
      "Epochs 151/500: \n",
      "Training cost 10.746861729567899|Validation cost 15.307248386646139\n",
      "Training MAE 3.2191206513574055|Validation MAE 3.5923509104710516\n",
      "Epochs 152/500: \n",
      "Training cost 10.736346172145153|Validation cost 15.292803932024315\n",
      "Training MAE 3.2178752947569147|Validation MAE 3.5902673951386634\n",
      "Epochs 153/500: \n",
      "Training cost 10.726016594211842|Validation cost 15.278594708771777\n",
      "Training MAE 3.2167155210275693|Validation MAE 3.588194881336999\n",
      "Epochs 154/500: \n",
      "Training cost 10.71586880121929|Validation cost 15.26461565985407\n",
      "Training MAE 3.215574479806375|Validation MAE 3.5861333288495603\n",
      "Epochs 155/500: \n",
      "Training cost 10.70589870636324|Validation cost 15.250861856115757\n",
      "Training MAE 3.214525457337421|Validation MAE 3.5840826970131077\n",
      "Epochs 156/500: \n",
      "Training cost 10.696102327503388|Validation cost 15.237328492659206\n",
      "Training MAE 3.2134941955242606|Validation MAE 3.582042944734628\n",
      "Epochs 157/500: \n",
      "Training cost 10.68647578418057|Validation cost 15.22401088533711\n",
      "Training MAE 3.2124784982275534|Validation MAE 3.580014030507949\n",
      "Epochs 158/500: \n",
      "Training cost 10.677015294728157|Validation cost 15.210904467354828\n",
      "Training MAE 3.211520970932651|Validation MAE 3.5779959124300325\n",
      "Epochs 159/500: \n",
      "Training cost 10.667717173474417|Validation cost 15.198004785978737\n",
      "Training MAE 3.210637583825171|Validation MAE 3.575988548216917\n",
      "Epochs 160/500: \n",
      "Training cost 10.65857782803265|Validation cost 15.185307499347006\n",
      "Training MAE 3.209759958326065|Validation MAE 3.573991895219349\n",
      "Epochs 161/500: \n",
      "Training cost 10.649593756676165|Validation cost 15.172808373379166\n",
      "Training MAE 3.2088880276416982|Validation MAE 3.572005910438071\n",
      "Epochs 162/500: \n",
      "Training cost 10.640761545795066|Validation cost 15.16050327878126\n",
      "Training MAE 3.2080217260707236|Validation MAE 3.570121356295516\n",
      "Epochs 163/500: \n",
      "Training cost 10.632077867432129|Validation cost 15.148388188143132\n",
      "Training MAE 3.2071609889829817|Validation MAE 3.5682595977644014\n",
      "Epochs 164/500: \n",
      "Training cost 10.623539476895024|Validation cost 15.136459173124912\n",
      "Training MAE 3.2063386527965103|Validation MAE 3.5664069542943366\n",
      "Epochs 165/500: \n",
      "Training cost 10.615143210442294|Validation cost 15.124712401729521\n",
      "Training MAE 3.2055370174531888|Validation MAE 3.5645735623148176\n",
      "Epochs 166/500: \n",
      "Training cost 10.606885983040577|Validation cost 15.113144135658354\n",
      "Training MAE 3.204740274140958|Validation MAE 3.5627750680895818\n",
      "Epochs 167/500: \n",
      "Training cost 10.598764786190655|Validation cost 15.101750727747424\n",
      "Training MAE 3.2039483673866993|Validation MAE 3.560985172124059\n",
      "Epochs 168/500: \n",
      "Training cost 10.590776685820027|Validation cost 15.090528619481066\n",
      "Training MAE 3.203161242639557|Validation MAE 3.5592038586970265\n",
      "Epochs 169/500: \n",
      "Training cost 10.582918820239724|Validation cost 15.079474338580843\n",
      "Training MAE 3.2024286073641424|Validation MAE 3.5574311113224675\n",
      "Epochs 170/500: \n",
      "Training cost 10.575188398163254|Validation cost 15.068584496666949\n",
      "Training MAE 3.201728422857657|Validation MAE 3.5556669127722396\n",
      "Epochs 171/500: \n",
      "Training cost 10.567582696785548|Validation cost 15.057855786989828\n",
      "Training MAE 3.201031812644522|Validation MAE 3.5539221950006756\n",
      "Epochs 172/500: \n",
      "Training cost 10.560099059919953|Validation cost 15.047284982229641\n",
      "Training MAE 3.2003387417950178|Validation MAE 3.552267124996413\n",
      "Epochs 173/500: \n",
      "Training cost 10.552734896191309|Validation cost 15.0368689323613\n",
      "Training MAE 3.1996491759382963|Validation MAE 3.550619550980922\n",
      "Epochs 174/500: \n",
      "Training cost 10.54548767728324|Validation cost 15.026604562582989\n",
      "Training MAE 3.1989630812512235|Validation MAE 3.549015978947433\n",
      "Epochs 175/500: \n",
      "Training cost 10.538354936237905|Validation cost 15.01648887130604\n",
      "Training MAE 3.1982804244474674|Validation MAE 3.5475504199180006\n",
      "Epochs 176/500: \n",
      "Training cost 10.531334265806432|Validation cost 15.006518928204153\n",
      "Training MAE 3.197616664203997|Validation MAE 3.546091693108881\n",
      "Epochs 177/500: \n",
      "Training cost 10.52442331684841|Validation cost 14.996691872320037\n",
      "Training MAE 3.1970058522410545|Validation MAE 3.544639792047058\n",
      "Epochs 178/500: \n",
      "Training cost 10.517619796778783|Validation cost 14.987004910227643\n",
      "Training MAE 3.1963973472453615|Validation MAE 3.5431947095216314\n",
      "Epochs 179/500: \n",
      "Training cost 10.51092146806067|Validation cost 14.977455314248099\n",
      "Training MAE 3.1957911354516093|Validation MAE 3.541756437604239\n",
      "Epochs 180/500: \n",
      "Training cost 10.504326146742516|Validation cost 14.968040420717717\n",
      "Training MAE 3.1951872032711224|Validation MAE 3.540324967669047\n",
      "Epochs 181/500: \n",
      "Training cost 10.497831701038205|Validation cost 14.958757628306307\n",
      "Training MAE 3.194585537287978|Validation MAE 3.538900290412322\n",
      "Epochs 182/500: \n",
      "Training cost 10.491436049948753|Validation cost 14.949604396384261\n",
      "Training MAE 3.1939895032547567|Validation MAE 3.537482395871596\n",
      "Epochs 183/500: \n",
      "Training cost 10.485137161924163|Validation cost 14.940578243436768\n",
      "Training MAE 3.193402157404395|Validation MAE 3.536071273444433\n",
      "Epochs 184/500: \n",
      "Training cost 10.478933053564237|Validation cost 14.931676745523728\n",
      "Training MAE 3.1928169757813993|Validation MAE 3.5347873392460656\n",
      "Epochs 185/500: \n",
      "Training cost 10.472821788357017|Validation cost 14.922897534783866\n",
      "Training MAE 3.19223394561276|Validation MAE 3.533629423826203\n",
      "Epochs 186/500: \n",
      "Training cost 10.46680147545372|Validation cost 14.91423829798169\n",
      "Training MAE 3.1916671991835948|Validation MAE 3.53247628711007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 187/500: \n",
      "Training cost 10.46087026847895|Validation cost 14.905696775095883\n",
      "Training MAE 3.1911041121923645|Validation MAE 3.5313432171954116\n",
      "Epochs 188/500: \n",
      "Training cost 10.455026364375096|Validation cost 14.897270757947869\n",
      "Training MAE 3.190543051559662|Validation MAE 3.530254789776037\n",
      "Epochs 189/500: \n",
      "Training cost 10.449268002279817|Validation cost 14.88895808886929\n",
      "Training MAE 3.189984004960612|Validation MAE 3.529170503826758\n",
      "Epochs 190/500: \n",
      "Training cost 10.443593462435588|Validation cost 14.88075665940715\n",
      "Training MAE 3.189427813487731|Validation MAE 3.5280903743186296\n",
      "Epochs 191/500: \n",
      "Training cost 10.438001065130255|Validation cost 14.87266440906547\n",
      "Training MAE 3.1889150019575903|Validation MAE 3.527014415334495\n",
      "Epochs 192/500: \n",
      "Training cost 10.432489169667681|Validation cost 14.864679324082347\n",
      "Training MAE 3.188403592262164|Validation MAE 3.5259426400899025\n",
      "Epochs 193/500: \n",
      "Training cost 10.42705617336751|Validation cost 14.856799436241257\n",
      "Training MAE 3.1878935818943748|Validation MAE 3.524875060953609\n",
      "Epochs 194/500: \n",
      "Training cost 10.421700510593114|Validation cost 14.84902282171558\n",
      "Training MAE 3.1873849683493685|Validation MAE 3.523811689467673\n",
      "Epochs 195/500: \n",
      "Training cost 10.41642065180693|Validation cost 14.841347599945383\n",
      "Training MAE 3.1868777491238336|Validation MAE 3.5227525363671353\n",
      "Epochs 196/500: \n",
      "Training cost 10.411215102652232|Validation cost 14.833771932545314\n",
      "Training MAE 3.1863719217153457|Validation MAE 3.5216976115993264\n",
      "Epochs 197/500: \n",
      "Training cost 10.40608240306059|Validation cost 14.82629402224285\n",
      "Training MAE 3.185867483621757|Validation MAE 3.520646924342769\n",
      "Epochs 198/500: \n",
      "Training cost 10.401021126384222|Validation cost 14.818912111845822\n",
      "Training MAE 3.1853644323405996|Validation MAE 3.5196004830257\n",
      "Epochs 199/500: \n",
      "Training cost 10.396029878552433|Validation cost 14.811624483238415\n",
      "Training MAE 3.1848627653685266|Validation MAE 3.5185582953442323\n",
      "Epochs 200/500: \n",
      "Training cost 10.391107297251448|Validation cost 14.804429456404703\n",
      "Training MAE 3.1843725260575897|Validation MAE 3.5175203682801417\n",
      "Epochs 201/500: \n",
      "Training cost 10.386252051126895|Validation cost 14.797325388479011\n",
      "Training MAE 3.183890149113074|Validation MAE 3.516486708118291\n",
      "Epochs 202/500: \n",
      "Training cost 10.381462839008254|Validation cost 14.790310672822143\n",
      "Training MAE 3.1834089483650643|Validation MAE 3.5154573204637187\n",
      "Epochs 203/500: \n",
      "Training cost 10.376738389154635|Validation cost 14.783383738122811\n",
      "Training MAE 3.1829289230179416|Validation MAE 3.5144322102583554\n",
      "Epochs 204/500: \n",
      "Training cost 10.372077458521177|Validation cost 14.776543047523495\n",
      "Training MAE 3.1825055590079367|Validation MAE 3.5134113817974297\n",
      "Epochs 205/500: \n",
      "Training cost 10.367478832045508|Validation cost 14.769787097769942\n",
      "Training MAE 3.1821092820963113|Validation MAE 3.512394838745519\n",
      "Epochs 206/500: \n",
      "Training cost 10.362941321953643|Validation cost 14.76311441838369\n",
      "Training MAE 3.181713516270663|Validation MAE 3.511382584152284\n",
      "Epochs 207/500: \n",
      "Training cost 10.358463767084718|Validation cost 14.756523570856857\n",
      "Training MAE 3.1813565010613547|Validation MAE 3.5104630850093037\n",
      "Epochs 208/500: \n",
      "Training cost 10.354045032234005|Validation cost 14.750013147868597\n",
      "Training MAE 3.1810025191675564|Validation MAE 3.5095575165870483\n",
      "Epochs 209/500: \n",
      "Training cost 10.349684007513705|Validation cost 14.743581772522534\n",
      "Training MAE 3.1806487627190747|Validation MAE 3.5086553554586217\n",
      "Epochs 210/500: \n",
      "Training cost 10.345379607730907|Validation cost 14.737228097604609\n",
      "Training MAE 3.1802952387887045|Validation MAE 3.507756612987275\n",
      "Epochs 211/500: \n",
      "Training cost 10.34113077178231|Validation cost 14.73095080486071\n",
      "Training MAE 3.1799419543756846|Validation MAE 3.5068612998443425\n",
      "Epochs 212/500: \n",
      "Training cost 10.336936462065093|Validation cost 14.724748604293481\n",
      "Training MAE 3.179588916405522|Validation MAE 3.5059694260255694\n",
      "Epochs 213/500: \n",
      "Training cost 10.33279566390358|Validation cost 14.718620233477834\n",
      "Training MAE 3.1792361317298523|Validation MAE 3.505081000867127\n",
      "Epochs 214/500: \n",
      "Training cost 10.328707384991146|Validation cost 14.712564456894551\n",
      "Training MAE 3.1788836071263242|Validation MAE 3.5041960330613016\n",
      "Epochs 215/500: \n",
      "Training cost 10.324670654846953|Validation cost 14.706580065281454\n",
      "Training MAE 3.178531349298509|Validation MAE 3.5033145306718594\n",
      "Epochs 216/500: \n",
      "Training cost 10.320684524287092|Validation cost 14.700665875001675\n",
      "Training MAE 3.1781793648758394|Validation MAE 3.5024365011491088\n",
      "Epochs 217/500: \n",
      "Training cost 10.316748064909683|Validation cost 14.69482072742855\n",
      "Training MAE 3.1778276604135742|Validation MAE 3.5015619513446516\n",
      "Epochs 218/500: \n",
      "Training cost 10.312860368593563|Validation cost 14.689043488346536\n",
      "Training MAE 3.1774893073696338|Validation MAE 3.5006908875258356\n",
      "Epochs 219/500: \n",
      "Training cost 10.30902054701016|Validation cost 14.683333047367887\n",
      "Training MAE 3.1771562849650743|Validation MAE 3.4998233153899188\n",
      "Epochs 220/500: \n",
      "Training cost 10.305227731148122|Validation cost 14.677688317364437\n",
      "Training MAE 3.1768233402495367|Validation MAE 3.498959240077938\n",
      "Epochs 221/500: \n",
      "Training cost 10.301481070850427|Validation cost 14.672108233914253\n",
      "Training MAE 3.1764904833325236|Validation MAE 3.4980986661882967\n",
      "Epochs 222/500: \n",
      "Training cost 10.297779734363543|Validation cost 14.666591754762582\n",
      "Training MAE 3.176157724175486|Validation MAE 3.4972415977900844\n",
      "Epochs 223/500: \n",
      "Training cost 10.294122907898318|Validation cost 14.661137859296732\n",
      "Training MAE 3.1758250725934123|Validation MAE 3.496388038436111\n",
      "Epochs 224/500: \n",
      "Training cost 10.290509795202274|Validation cost 14.65574554803458\n",
      "Training MAE 3.1754925382563917|Validation MAE 3.4955379911756777\n",
      "Epochs 225/500: \n",
      "Training cost 10.286939617142965|Validation cost 14.650413842126207\n",
      "Training MAE 3.175160130691182|Validation MAE 3.4946914585671\n",
      "Epochs 226/500: \n",
      "Training cost 10.283411611302093|Validation cost 14.64514178286835\n",
      "Training MAE 3.174827859282755|Validation MAE 3.493848442689955\n",
      "Epochs 227/500: \n",
      "Training cost 10.279925031580097|Validation cost 14.63992843123129\n",
      "Training MAE 3.1744957332758412|Validation MAE 3.493008945157087\n",
      "Epochs 228/500: \n",
      "Training cost 10.27647914781087|Validation cost 14.634772867397885\n",
      "Training MAE 3.1741637617764518|Validation MAE 3.4921729671263675\n",
      "Epochs 229/500: \n",
      "Training cost 10.273073245386378|Validation cost 14.629674190314303\n",
      "Training MAE 3.1738319537533957|Validation MAE 3.4913405093122076\n",
      "Epochs 230/500: \n",
      "Training cost 10.269706624890876|Validation cost 14.624631517252247\n",
      "Training MAE 3.1735003180397845|Validation MAE 3.4905115719968403\n",
      "Epochs 231/500: \n",
      "Training cost 10.26637860174443|Validation cost 14.619643983382316\n",
      "Training MAE 3.1731688633345283|Validation MAE 3.489692241880497\n",
      "Epochs 232/500: \n",
      "Training cost 10.263088505855539|Validation cost 14.614710741358106\n",
      "Training MAE 3.1728375982038117|Validation MAE 3.4889130451904413\n",
      "Epochs 233/500: \n",
      "Training cost 10.259835681282562|Validation cost 14.60983096091089\n",
      "Training MAE 3.1725065310825666|Validation MAE 3.488186483957778\n",
      "Epochs 234/500: \n",
      "Training cost 10.256619485903727|Validation cost 14.605003828454544\n",
      "Training MAE 3.17217567027593|Validation MAE 3.48746298482102\n",
      "Epochs 235/500: \n",
      "Training cost 10.253439291095468|Validation cost 14.600228546700382\n",
      "Training MAE 3.171845023960694|Validation MAE 3.486742547206754\n",
      "Epochs 236/500: \n",
      "Training cost 10.250294481418882|Validation cost 14.595504334281674\n",
      "Training MAE 3.171524103076491|Validation MAE 3.4860251702192864\n",
      "Epochs 237/500: \n",
      "Training cost 10.247184454314059|Validation cost 14.590830425387619\n",
      "Training MAE 3.1712039481580723|Validation MAE 3.485310852648701\n",
      "Epochs 238/500: \n",
      "Training cost 10.244108619802105|Validation cost 14.586206069406419\n",
      "Training MAE 3.170883976864939|Validation MAE 3.484599592978747\n",
      "Epochs 239/500: \n",
      "Training cost 10.2410664001946|Validation cost 14.581630530577327\n",
      "Training MAE 3.170564198273867|Validation MAE 3.4838913893945738\n",
      "Epochs 240/500: \n",
      "Training cost 10.23805722981033|Validation cost 14.577103087651341\n",
      "Training MAE 3.1702446213039956|Validation MAE 3.4831862397903053\n",
      "Epochs 241/500: \n",
      "Training cost 10.235080554699076|Validation cost 14.572623033560328\n",
      "Training MAE 3.169925254719051|Validation MAE 3.4824841417764723\n",
      "Epochs 242/500: \n",
      "Training cost 10.232135832372272|Validation cost 14.56818967509436\n",
      "Training MAE 3.169606107129538|Validation MAE 3.481785092687283\n",
      "Epochs 243/500: \n",
      "Training cost 10.229222531540346|Validation cost 14.563802332587068\n",
      "Training MAE 3.1693080682912833|Validation MAE 3.481089089587759\n",
      "Epochs 244/500: \n",
      "Training cost 10.22634013185657|Validation cost 14.559460339608735\n",
      "Training MAE 3.1690304542986123|Validation MAE 3.4803961292807113\n",
      "Epochs 245/500: \n",
      "Training cost 10.22348812366723|Validation cost 14.555163042667026\n",
      "Training MAE 3.168752879567685|Validation MAE 3.4797062083136043\n",
      "Epochs 246/500: \n",
      "Training cost 10.220666007767969|Validation cost 14.550909800914972\n",
      "Training MAE 3.1684801877515185|Validation MAE 3.4790748012296153\n",
      "Epochs 247/500: \n",
      "Training cost 10.217873295166102|Validation cost 14.546699985866292\n",
      "Training MAE 3.1682119114922003|Validation MAE 3.478488239868805\n",
      "Epochs 248/500: \n",
      "Training cost 10.21510950684881|Validation cost 14.542532981117517\n",
      "Training MAE 3.1679435849197337|Validation MAE 3.4779040814367304\n",
      "Epochs 249/500: \n",
      "Training cost 10.212374173556944|Validation cost 14.538408182077074\n",
      "Training MAE 3.167675219224254|Validation MAE 3.4773223274249894\n",
      "Epochs 250/500: \n",
      "Training cost 10.209666835564441|Validation cost 14.534324995700882\n",
      "Training MAE 3.167406825403897|Validation MAE 3.476742979034671\n",
      "Epochs 251/500: \n",
      "Training cost 10.20698704246306|Validation cost 14.530282840234452\n",
      "Training MAE 3.16713841426771|Validation MAE 3.4761660371832597\n",
      "Epochs 252/500: \n",
      "Training cost 10.204334352952383|Validation cost 14.526281144961235\n",
      "Training MAE 3.166869996438527|Validation MAE 3.475591502511401\n",
      "Epochs 253/500: \n",
      "Training cost 10.201708334634922|Validation cost 14.522319349957112\n",
      "Training MAE 3.1666015823557916|Validation MAE 3.475019375389539\n",
      "Epochs 254/500: \n",
      "Training cost 10.199108563816191|Validation cost 14.51839690585078\n",
      "Training MAE 3.1663520611789027|Validation MAE 3.474449655924421\n",
      "Epochs 255/500: \n",
      "Training cost 10.196534625309607|Validation cost 14.51451327359005\n",
      "Training MAE 3.1661226365102624|Validation MAE 3.4738823439654674\n",
      "Epochs 256/500: \n",
      "Training cost 10.193986112246122|Validation cost 14.510667924213632\n",
      "Training MAE 3.1658930077600758|Validation MAE 3.4733174391110366\n",
      "Epochs 257/500: \n",
      "Training cost 10.191462625888438|Validation cost 14.506860338628584\n",
      "Training MAE 3.165663186877056|Validation MAE 3.472757046072743\n",
      "Epochs 258/500: \n",
      "Training cost 10.188963775449679|Validation cost 14.503090007392993\n",
      "Training MAE 3.165433185616972|Validation MAE 3.47220295013327\n",
      "Epochs 259/500: \n",
      "Training cost 10.186489177916433|Validation cost 14.499356430503967\n",
      "Training MAE 3.1652030155454787|Validation MAE 3.4716511006577155\n",
      "Epochs 260/500: \n",
      "Training cost 10.184038457876042|Validation cost 14.495659117190655\n",
      "Training MAE 3.164982400296518|Validation MAE 3.4711014992627365\n",
      "Epochs 261/500: \n",
      "Training cost 10.181611247347991|Validation cost 14.491997585712232\n",
      "Training MAE 3.164761956072875|Validation MAE 3.4705541472871766\n",
      "Epochs 262/500: \n",
      "Training cost 10.179207185619363|Validation cost 14.488371363160748\n",
      "Training MAE 3.1645457855103523|Validation MAE 3.470009045798721\n",
      "Epochs 263/500: \n",
      "Training cost 10.176825919084191|Validation cost 14.48477998526866\n",
      "Training MAE 3.1643473699065354|Validation MAE 3.469466195600402\n",
      "Epochs 264/500: \n",
      "Training cost 10.174467101086641|Validation cost 14.481222996220888\n",
      "Training MAE 3.164148581892602|Validation MAE 3.46892559723699\n",
      "Epochs 265/500: \n",
      "Training cost 10.172130391767913|Validation cost 14.477699948471477\n",
      "Training MAE 3.1639494358250633|Validation MAE 3.4683872510012517\n",
      "Epochs 266/500: \n",
      "Training cost 10.169815457916775|Validation cost 14.474210402564463\n",
      "Training MAE 3.163749945824055|Validation MAE 3.4678511569400827\n",
      "Epochs 267/500: \n",
      "Training cost 10.16752197282364|Validation cost 14.470753926959095\n",
      "Training MAE 3.1635501257769856|Validation MAE 3.4673412676014377\n",
      "Epochs 268/500: \n",
      "Training cost 10.16524961613807|Validation cost 14.467330097859119\n",
      "Training MAE 3.1633499893421235|Validation MAE 3.466863202134015\n",
      "Epochs 269/500: \n",
      "Training cost 10.162998073729662|Validation cost 14.463938499046128\n",
      "Training MAE 3.1631495499521245|Validation MAE 3.466386871173724\n",
      "Epochs 270/500: \n",
      "Training cost 10.1607670375522|Validation cost 14.460578721716843\n",
      "Training MAE 3.1629488208175096|Validation MAE 3.4659122796291006\n",
      "Epochs 271/500: \n",
      "Training cost 10.158556205510978|Validation cost 14.457250364324212\n",
      "Training MAE 3.1627478149300767|Validation MAE 3.465439432123698\n",
      "Epochs 272/500: \n",
      "Training cost 10.156365281333278|Validation cost 14.453953032422238\n",
      "Training MAE 3.1625465450662684|Validation MAE 3.4649683330023384\n",
      "Epochs 273/500: \n",
      "Training cost 10.154193974441837|Validation cost 14.450686338514464\n",
      "Training MAE 3.1623619997180517|Validation MAE 3.4645006225611845\n",
      "Epochs 274/500: \n",
      "Training cost 10.152041999831296|Validation cost 14.447449901906003\n",
      "Training MAE 3.16218124871602|Validation MAE 3.4640367290136793\n",
      "Epochs 275/500: \n",
      "Training cost 10.149909077947523|Validation cost 14.444243348559016\n",
      "Training MAE 3.162000539449255|Validation MAE 3.4635745910118465\n",
      "Epochs 276/500: \n",
      "Training cost 10.147794934569756|Validation cost 14.441066310951564\n",
      "Training MAE 3.161819429723522|Validation MAE 3.4631142121724183\n",
      "Epochs 277/500: \n",
      "Training cost 10.145699300695474|Validation cost 14.437918427939769\n",
      "Training MAE 3.161637933468563|Validation MAE 3.4626555958571688\n",
      "Epochs 278/500: \n",
      "Training cost 10.14362191242794|Validation cost 14.43479934462317\n",
      "Training MAE 3.161463332420911|Validation MAE 3.4621987451785303\n",
      "Epochs 279/500: \n",
      "Training cost 10.141562510866374|Validation cost 14.431708712213211\n",
      "Training MAE 3.161299171696612|Validation MAE 3.461743663005116\n",
      "Epochs 280/500: \n",
      "Training cost 10.139520841998637|Validation cost 14.42864618790475\n",
      "Training MAE 3.1611346190944114|Validation MAE 3.461290351967127\n",
      "Epochs 281/500: \n",
      "Training cost 10.137496656596408|Validation cost 14.425611434750607\n",
      "Training MAE 3.1609696877647657|Validation MAE 3.4608388144616575\n",
      "Epochs 282/500: \n",
      "Training cost 10.135489710112786|Validation cost 14.422604121538951\n",
      "Training MAE 3.160804390646007|Validation MAE 3.4603890526579115\n",
      "Epochs 283/500: \n",
      "Training cost 10.13349976258224|Validation cost 14.41962392267355\n",
      "Training MAE 3.1606463177713984|Validation MAE 3.4599410685023\n",
      "Epochs 284/500: \n",
      "Training cost 10.131526578522845|Validation cost 14.41667051805678\n",
      "Training MAE 3.1604882564866412|Validation MAE 3.459494863723456\n",
      "Epochs 285/500: \n",
      "Training cost 10.129569926840814|Validation cost 14.413743592975303\n",
      "Training MAE 3.1603298082129836|Validation MAE 3.459050439837156\n",
      "Epochs 286/500: \n",
      "Training cost 10.127629580737143|Validation cost 14.410842837988397\n",
      "Training MAE 3.1601709855933704|Validation MAE 3.4586077981511356\n",
      "Epochs 287/500: \n",
      "Training cost 10.125705317616456|Validation cost 14.407967948818861\n",
      "Training MAE 3.1600118010686216|Validation MAE 3.458166939769821\n",
      "Epochs 288/500: \n",
      "Training cost 10.123796918997906|Validation cost 14.405118626246356\n",
      "Training MAE 3.1598522668804727|Validation MAE 3.457727865598971\n",
      "Epochs 289/500: \n",
      "Training cost 10.121904170428103|Validation cost 14.402294576003268\n",
      "Training MAE 3.159692395074565|Validation MAE 3.4573420366250462\n",
      "Epochs 290/500: \n",
      "Training cost 10.120026861396035|Validation cost 14.39949550867287\n",
      "Training MAE 3.1595321975034003|Validation MAE 3.456971179145818\n",
      "Epochs 291/500: \n",
      "Training cost 10.118164785249926|Validation cost 14.396721139589879\n",
      "Training MAE 3.1593716858292424|Validation MAE 3.4566016247236693\n",
      "Epochs 292/500: \n",
      "Training cost 10.116317739115983|Validation cost 14.393971188743224\n",
      "Training MAE 3.15921087152697|Validation MAE 3.4562333774852285\n",
      "Epochs 293/500: \n",
      "Training cost 10.114485523818965|Validation cost 14.391245380681044\n",
      "Training MAE 3.1590497658868903|Validation MAE 3.4558664413532165\n",
      "Epochs 294/500: \n",
      "Training cost 10.112667943804583|Validation cost 14.388543444417847\n",
      "Training MAE 3.158888380017508|Validation MAE 3.4555008200505837\n",
      "Epochs 295/500: \n",
      "Training cost 10.110864807063624|Validation cost 14.385865113343757\n",
      "Training MAE 3.1587267248482496|Validation MAE 3.45513651710457\n",
      "Epochs 296/500: \n",
      "Training cost 10.109075925057814|Validation cost 14.38321012513583\n",
      "Training MAE 3.1585648111321443|Validation MAE 3.454773535850688\n",
      "Epochs 297/500: \n",
      "Training cost 10.107301112647324|Validation cost 14.38057822167137\n",
      "Training MAE 3.15840264944847|Validation MAE 3.4544118794366527\n",
      "Epochs 298/500: \n",
      "Training cost 10.105540188019942|Validation cost 14.377969148943187\n",
      "Training MAE 3.158240250205343|Validation MAE 3.4540515508262186\n",
      "Epochs 299/500: \n",
      "Training cost 10.103792972621799|Validation cost 14.3753826569768\n",
      "Training MAE 3.1580776236422876|Validation MAE 3.4536925528029636\n",
      "Epochs 300/500: \n",
      "Training cost 10.102059291089686|Validation cost 14.372818499749442\n",
      "Training MAE 3.157914779832753|Validation MAE 3.453334887973999\n",
      "Epochs 301/500: \n",
      "Training cost 10.100338971184854|Validation cost 14.370276435110956\n",
      "Training MAE 3.1577517286865913|Validation MAE 3.452978558773618\n",
      "Epochs 302/500: \n",
      "Training cost 10.098631843728331|Validation cost 14.367756224706385\n",
      "Training MAE 3.1575884799525005|Validation MAE 3.452623567466868\n",
      "Epochs 303/500: \n",
      "Training cost 10.096937742537651|Validation cost 14.365257633900393\n",
      "Training MAE 3.1574250432204347|Validation MAE 3.4522699161530803\n",
      "Epochs 304/500: \n",
      "Training cost 10.095256504365015|Validation cost 14.362780431703264\n",
      "Training MAE 3.157261427923961|Validation MAE 3.451917606769309\n",
      "Epochs 305/500: \n",
      "Training cost 10.093587968836829|Validation cost 14.360324390698645\n",
      "Training MAE 3.1570976433426043|Validation MAE 3.451621295507479\n",
      "Epochs 306/500: \n",
      "Training cost 10.091931978394577|Validation cost 14.35788928697286\n",
      "Training MAE 3.156933698604131|Validation MAE 3.4513515961834127\n",
      "Epochs 307/500: \n",
      "Training cost 10.09028837823702|Validation cost 14.355474900045785\n",
      "Training MAE 3.156769602686816|Validation MAE 3.4510828693207873\n",
      "Epochs 308/500: \n",
      "Training cost 10.088657016263667|Validation cost 14.35308101280328\n",
      "Training MAE 3.1566053644216647|Validation MAE 3.450815119094695\n",
      "Epochs 309/500: \n",
      "Training cost 10.087037743019524|Validation cost 14.350707411431133\n",
      "Training MAE 3.1564409924946064|Validation MAE 3.4505483495016116\n",
      "Epochs 310/500: \n",
      "Training cost 10.085430411641005|Validation cost 14.348353885350425\n",
      "Training MAE 3.156276495448652|Validation MAE 3.450282564362976\n",
      "Epochs 311/500: \n",
      "Training cost 10.083834877803131|Validation cost 14.346020227154352\n",
      "Training MAE 3.156111881686016|Validation MAE 3.450017767328702\n",
      "Epochs 312/500: \n",
      "Training cost 10.082250999667801|Validation cost 14.343706232546458\n",
      "Training MAE 3.155947159470213|Validation MAE 3.449753961880632\n",
      "Epochs 313/500: \n",
      "Training cost 10.080678637833275|Validation cost 14.341411700280187\n",
      "Training MAE 3.155782336928116|Validation MAE 3.449491151335933\n",
      "Epochs 314/500: \n",
      "Training cost 10.079117655284715|Validation cost 14.339136432099798\n",
      "Training MAE 3.1556174220519835|Validation MAE 3.4492293388504156\n",
      "Epochs 315/500: \n",
      "Training cost 10.077567917345865|Validation cost 14.336880232682583\n",
      "Training MAE 3.1554524227014626|Validation MAE 3.4489685274218163\n",
      "Epochs 316/500: \n",
      "Training cost 10.076029291631741|Validation cost 14.33464290958233\n",
      "Training MAE 3.1552873466055518|Validation MAE 3.448708719893003\n",
      "Epochs 317/500: \n",
      "Training cost 10.074501648002396|Validation cost 14.332424273174022\n",
      "Training MAE 3.1551222013645437|Validation MAE 3.448449918955129\n",
      "Epochs 318/500: \n",
      "Training cost 10.072984858517678|Validation cost 14.330224136599792\n",
      "Training MAE 3.1549717025445365|Validation MAE 3.4482002728124623\n",
      "Epochs 319/500: \n",
      "Training cost 10.071478797392986|Validation cost 14.328042315715999\n",
      "Training MAE 3.1548211391553567|Validation MAE 3.4479686188677223\n",
      "Epochs 320/500: \n",
      "Training cost 10.069983340955991|Validation cost 14.325878629041508\n",
      "Training MAE 3.1546704545088162|Validation MAE 3.4477378225823228\n",
      "Epochs 321/500: \n",
      "Training cost 10.068498367604292|Validation cost 14.323732897707046\n",
      "Training MAE 3.1545196563487368|Validation MAE 3.4475078876064402\n",
      "Epochs 322/500: \n",
      "Training cost 10.067023757764003|Validation cost 14.321604945405724\n",
      "Training MAE 3.1543687522911608|Validation MAE 3.4472788174370073\n",
      "Epochs 323/500: \n",
      "Training cost 10.06555939384926|Validation cost 14.319494598344583\n",
      "Training MAE 3.1542177498262576|Validation MAE 3.447050615420711\n",
      "Epochs 324/500: \n",
      "Training cost 10.064105160222548|Validation cost 14.317401685197195\n",
      "Training MAE 3.154066656320196|Validation MAE 3.44682328475694\n",
      "Epochs 325/500: \n",
      "Training cost 10.062660943155969|Validation cost 14.315326037057298\n",
      "Training MAE 3.153924377293148|Validation MAE 3.44659682850068\n",
      "Epochs 326/500: \n",
      "Training cost 10.061226630793271|Validation cost 14.31326748739347\n",
      "Training MAE 3.1537878026717125|Validation MAE 3.446371249565363\n",
      "Epochs 327/500: \n",
      "Training cost 10.059802113112776|Validation cost 14.311225872004705\n",
      "Training MAE 3.153651092059155|Validation MAE 3.4461465507256626\n",
      "Epochs 328/500: \n",
      "Training cost 10.058387281891031|Validation cost 14.30920102897701\n",
      "Training MAE 3.1535142528659814|Validation MAE 3.445922734620237\n",
      "Epochs 329/500: \n",
      "Training cost 10.056982030667314|Validation cost 14.307192798640912\n",
      "Training MAE 3.153377292381352|Validation MAE 3.445699803754432\n",
      "Epochs 330/500: \n",
      "Training cost 10.055586254708848|Validation cost 14.30520102352986\n",
      "Training MAE 3.153243043779571|Validation MAE 3.44547776050293\n",
      "Epochs 331/500: \n",
      "Training cost 10.054199850976802|Validation cost 14.30322554833956\n",
      "Training MAE 3.1531177322669683|Validation MAE 3.445256607112362\n",
      "Epochs 332/500: \n",
      "Training cost 10.052822718093019|Validation cost 14.301266219888147\n",
      "Training MAE 3.1529969915583784|Validation MAE 3.445036345703863\n",
      "Epochs 333/500: \n",
      "Training cost 10.051454756307429|Validation cost 14.299322887077215\n",
      "Training MAE 3.152882039087103|Validation MAE 3.4448169782755858\n",
      "Epochs 334/500: \n",
      "Training cost 10.050095867466199|Validation cost 14.297395400853699\n",
      "Training MAE 3.152766847809205|Validation MAE 3.4445985067051765\n",
      "Epochs 335/500: \n",
      "Training cost 10.048745954980538|Validation cost 14.29548361417252\n",
      "Training MAE 3.1526514250488304|Validation MAE 3.444380932752202\n",
      "Epochs 336/500: \n",
      "Training cost 10.04740492379619|Validation cost 14.293587381960094\n",
      "Training MAE 3.1525357780224943|Validation MAE 3.4441642580605314\n",
      "Epochs 337/500: \n",
      "Training cost 10.046072680363562|Validation cost 14.291706561078549\n",
      "Training MAE 3.152419913840555|Validation MAE 3.443948484160686\n",
      "Epochs 338/500: \n",
      "Training cost 10.04474913260849|Validation cost 14.289841010290747\n",
      "Training MAE 3.1523038395086713|Validation MAE 3.4437336124721383\n",
      "Epochs 339/500: \n",
      "Training cost 10.043434189903653|Validation cost 14.28799059022601\n",
      "Training MAE 3.15218756192924|Validation MAE 3.4435196443055753\n",
      "Epochs 340/500: \n",
      "Training cost 10.04212776304055|Validation cost 14.286155163346612\n",
      "Training MAE 3.15207108790281|Validation MAE 3.4433065808651175\n",
      "Epochs 341/500: \n",
      "Training cost 10.040829764202131|Validation cost 14.28433459391494\n",
      "Training MAE 3.151954424129481|Validation MAE 3.443094423250512\n",
      "Epochs 342/500: \n",
      "Training cost 10.03954010693595|Validation cost 14.282528747961358\n",
      "Training MAE 3.1518375772102725|Validation MAE 3.4428831724592683\n",
      "Epochs 343/500: \n",
      "Training cost 10.038258706127927|Validation cost 14.280737493252749\n",
      "Training MAE 3.151720553648491|Validation MAE 3.4426728293887696\n",
      "Epochs 344/500: \n",
      "Training cost 10.036985477976659|Validation cost 14.278960699261734\n",
      "Training MAE 3.1516033598510567|Validation MAE 3.4424633948383465\n",
      "Epochs 345/500: \n",
      "Training cost 10.03572033996825|Validation cost 14.277198237136487\n",
      "Training MAE 3.151486002129836|Validation MAE 3.442254869511302\n",
      "Epochs 346/500: \n",
      "Training cost 10.034463210851722|Validation cost 14.275449979671242\n",
      "Training MAE 3.1513684867029244|Validation MAE 3.442047254016923\n",
      "Epochs 347/500: \n",
      "Training cost 10.033214010614884|Validation cost 14.27371580127738\n",
      "Training MAE 3.151250819695945|Validation MAE 3.4418405488724315\n",
      "Epochs 348/500: \n",
      "Training cost 10.03197266046076|Validation cost 14.271995577955092\n",
      "Training MAE 3.151133007143306|Validation MAE 3.441634754504922\n",
      "Epochs 349/500: \n",
      "Training cost 10.030739082784477|Validation cost 14.270289187265707\n",
      "Training MAE 3.1510150549894496|Validation MAE 3.44142987125325\n",
      "Epochs 350/500: \n",
      "Training cost 10.029513201150676|Validation cost 14.268596508304539\n",
      "Training MAE 3.1508969690900765|Validation MAE 3.4412258993698965\n",
      "Epochs 351/500: \n",
      "Training cost 10.028294940271358|Validation cost 14.266917421674282\n",
      "Training MAE 3.1507787552133606|Validation MAE 3.4410228390227964\n",
      "Epochs 352/500: \n",
      "Training cost 10.027084225984225|Validation cost 14.265251809459022\n",
      "Training MAE 3.150660419041153|Validation MAE 3.4408206902971328\n",
      "Epochs 353/500: \n",
      "Training cost 10.02588098523145|Validation cost 14.263599555198708\n",
      "Training MAE 3.1505419661701457|Validation MAE 3.4406194531971046\n",
      "Epochs 354/500: \n",
      "Training cost 10.02468514603891|Validation cost 14.261960543864209\n",
      "Training MAE 3.1504234021130446|Validation MAE 3.440419127647657\n",
      "Epochs 355/500: \n",
      "Training cost 10.023496637495855|Validation cost 14.260334661832866\n",
      "Training MAE 3.1503047322997118|Validation MAE 3.4402197134961847\n",
      "Epochs 356/500: \n",
      "Training cost 10.022315389734972|Validation cost 14.258721796864508\n",
      "Training MAE 3.1501859620782993|Validation MAE 3.440021210514207\n",
      "Epochs 357/500: \n",
      "Training cost 10.021141333912901|Validation cost 14.257121838078044\n",
      "Training MAE 3.150067096716358|Validation MAE 3.439823618399005\n",
      "Epochs 358/500: \n",
      "Training cost 10.019974402191135|Validation cost 14.255534675928427\n",
      "Training MAE 3.149948141401941|Validation MAE 3.4396269367752423\n",
      "Epochs 359/500: \n",
      "Training cost 10.018814527717318|Validation cost 14.253960202184187\n",
      "Training MAE 3.1498291012446877|Validation MAE 3.439431165196544\n",
      "Epochs 360/500: \n",
      "Training cost 10.017661644606939|Validation cost 14.25239830990536\n",
      "Training MAE 3.1497099812768914|Validation MAE 3.4392363031470605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs 361/500: \n",
      "Training cost 10.016515687925402|Validation cost 14.250848893421884\n",
      "Training MAE 3.149590786454552|Validation MAE 3.4390423500429876\n",
      "Epochs 362/500: \n",
      "Training cost 10.015376593670458|Validation cost 14.24931184831244\n",
      "Training MAE 3.14947152165842|Validation MAE 3.4388493052340805\n",
      "Epochs 363/500: \n",
      "Training cost 10.014244298755028|Validation cost 14.247787071383707\n",
      "Training MAE 3.1493521916950185|Validation MAE 3.4386571680051197\n",
      "Epochs 364/500: \n",
      "Training cost 10.013118740990333|Validation cost 14.24627446065006\n",
      "Training MAE 3.1492328012976563|Validation MAE 3.438465937577362\n",
      "Epochs 365/500: \n",
      "Training cost 10.011999859069421|Validation cost 14.24477391531365\n",
      "Training MAE 3.1491133551274215|Validation MAE 3.43827561310997\n",
      "Epochs 366/500: \n",
      "Training cost 10.010887592551015|Validation cost 14.243285335744893\n",
      "Training MAE 3.1489938577741707|Validation MAE 3.438086193701404\n",
      "Epochs 367/500: \n",
      "Training cost 10.00978188184367|Validation cost 14.241808623463378\n",
      "Training MAE 3.1488743137574957|Validation MAE 3.4378976783907973\n",
      "Epochs 368/500: \n",
      "Training cost 10.008682668190296|Validation cost 14.240343681119109\n",
      "Training MAE 3.148754727527679|Validation MAE 3.437710066159305\n",
      "Epochs 369/500: \n",
      "Training cost 10.007589893652963|Validation cost 14.238890412474168\n",
      "Training MAE 3.1486351034666393|Validation MAE 3.437523355931431\n",
      "Epochs 370/500: \n",
      "Training cost 10.00650350109805|Validation cost 14.237448722384723\n",
      "Training MAE 3.148515445888864|Validation MAE 3.4373388378881344\n",
      "Epochs 371/500: \n",
      "Training cost 10.005423434181662|Validation cost 14.236018516783378\n",
      "Training MAE 3.148395759042323|Validation MAE 3.437157975098797\n",
      "Epochs 372/500: \n",
      "Training cost 10.004349637335379|Validation cost 14.23459970266193\n",
      "Training MAE 3.148276047109376|Validation MAE 3.436977896500916\n",
      "Epochs 373/500: \n",
      "Training cost 10.003282055752264|Validation cost 14.233192188054396\n",
      "Training MAE 3.1481563142076667|Validation MAE 3.436798602030328\n",
      "Epochs 374/500: \n",
      "Training cost 10.002220635373186|Validation cost 14.231795882020426\n",
      "Training MAE 3.148036564391001|Validation MAE 3.436620091560402\n",
      "Epochs 375/500: \n",
      "Training cost 10.001165322873408|Validation cost 14.230410694629033\n",
      "Training MAE 3.1479168016502146|Validation MAE 3.4364423649033418\n",
      "Epochs 376/500: \n",
      "Training cost 10.000116065649431|Validation cost 14.22903653694263\n",
      "Training MAE 3.1477970299140376|Validation MAE 3.4362654218114814\n",
      "Epochs 377/500: \n",
      "Training cost 9.99907281180614|Validation cost 14.227673321001403\n",
      "Training MAE 3.1476772530499297|Validation MAE 3.436089261978548\n",
      "Epochs 378/500: \n",
      "Training cost 9.998035510144184|Validation cost 14.226320959807973\n",
      "Training MAE 3.1475686564090695|Validation MAE 3.435913885040906\n",
      "Epochs 379/500: \n",
      "Training cost 9.99700411014761|Validation cost 14.224979367312356\n",
      "Training MAE 3.1474822759951273|Validation MAE 3.435739290578775\n",
      "Epochs 380/500: \n",
      "Training cost 9.995978561971778|Validation cost 14.223648458397244\n",
      "Training MAE 3.147395806951101|Validation MAE 3.4355654781174394\n",
      "Epochs 381/500: \n",
      "Training cost 9.994958816431469|Validation cost 14.222328148863538\n",
      "Training MAE 3.1473092530951403|Validation MAE 3.4353924471284167\n",
      "Epochs 382/500: \n",
      "Training cost 9.993944824989288|Validation cost 14.221018355416188\n",
      "Training MAE 3.14722261818907|Validation MAE 3.435220197030628\n",
      "Epochs 383/500: \n",
      "Training cost 9.992936539744262|Validation cost 14.219718995650299\n",
      "Training MAE 3.1471359059391473|Validation MAE 3.4350487271915324\n",
      "Epochs 384/500: \n",
      "Training cost 9.991933913420672|Validation cost 14.218429988037496\n",
      "Training MAE 3.147049119996821|Validation MAE 3.4348780369282426\n",
      "Epochs 385/500: \n",
      "Training cost 9.990936899357136|Validation cost 14.217151251912577\n",
      "Training MAE 3.146962263959463|Validation MAE 3.434708125508633\n",
      "Epochs 386/500: \n",
      "Training cost 9.98994545149587|Validation cost 14.215882707460405\n",
      "Training MAE 3.1468753413711092|Validation MAE 3.434538992152416\n",
      "Epochs 387/500: \n",
      "Training cost 9.988959524372197|Validation cost 14.214624275703045\n",
      "Training MAE 3.146788355723172|Validation MAE 3.4343706360322046\n",
      "Epochs 388/500: \n",
      "Training cost 9.987979073104258|Validation cost 14.213375878487172\n",
      "Training MAE 3.1467013104551596|Validation MAE 3.4342030562745536\n",
      "Epochs 389/500: \n",
      "Training cost 9.987004053382908|Validation cost 14.212137438471697\n",
      "Training MAE 3.1466142089553637|Validation MAE 3.434036701659193\n",
      "Epochs 390/500: \n",
      "Training cost 9.986034421461845|Validation cost 14.210908879115653\n",
      "Training MAE 3.1465270545615667|Validation MAE 3.433872288504572\n",
      "Epochs 391/500: \n",
      "Training cost 9.98507013414791|Validation cost 14.209690124666286\n",
      "Training MAE 3.146439850561713|Validation MAE 3.433708609941604\n",
      "Epochs 392/500: \n",
      "Training cost 9.984111148791596|Validation cost 14.208481100147385\n",
      "Training MAE 3.1463526001945885|Validation MAE 3.4335456653915237\n",
      "Epochs 393/500: \n",
      "Training cost 9.983157423277742|Validation cost 14.207281731347836\n",
      "Training MAE 3.146265306650477|Validation MAE 3.4333834542290145\n",
      "Epochs 394/500: \n",
      "Training cost 9.982208916016392|Validation cost 14.206091944810389\n",
      "Training MAE 3.1461779730718193|Validation MAE 3.433221975783218\n",
      "Epochs 395/500: \n",
      "Training cost 9.981265585933867|Validation cost 14.204911667820632\n",
      "Training MAE 3.1460906025538615|Validation MAE 3.4330612293387093\n",
      "Epochs 396/500: \n",
      "Training cost 9.980327392463998|Validation cost 14.203740828396192\n",
      "Training MAE 3.146003198145285|Validation MAE 3.4329012141364768\n",
      "Epochs 397/500: \n",
      "Training cost 9.979394295539523|Validation cost 14.2025793552761\n",
      "Training MAE 3.1459157628488406|Validation MAE 3.432741929374868\n",
      "Epochs 398/500: \n",
      "Training cost 9.97846625558366|Validation cost 14.2014271779104\n",
      "Training MAE 3.1458282996219635|Validation MAE 3.4325833742105245\n",
      "Epochs 399/500: \n",
      "Training cost 9.977543233501862|Validation cost 14.20028422644992\n",
      "Training MAE 3.1457408113773866|Validation MAE 3.4324255477593\n",
      "Epochs 400/500: \n",
      "Training cost 9.976625190673712|Validation cost 14.199150431736255\n",
      "Training MAE 3.1456533009837453|Validation MAE 3.4322684490971724\n",
      "Epochs 401/500: \n",
      "Training cost 9.975712088944977|Validation cost 14.198025725291902\n",
      "Training MAE 3.145565771266168|Validation MAE 3.432112077261122\n",
      "Epochs 402/500: \n",
      "Training cost 9.974803890619835|Validation cost 14.19691003931063\n",
      "Training MAE 3.1454782250068662|Validation MAE 3.431956431250009\n",
      "Epochs 403/500: \n",
      "Training cost 9.973900558453245|Validation cost 14.19580330664799\n",
      "Training MAE 3.145390664945709|Validation MAE 3.431801510025431\n",
      "Epochs 404/500: \n",
      "Training cost 9.973002055643457|Validation cost 14.194705460811987\n",
      "Training MAE 3.1453030937808006|Validation MAE 3.4316473125125646\n",
      "Epochs 405/500: \n",
      "Training cost 9.972108345824681|Validation cost 14.193616435953984\n",
      "Training MAE 3.145215514169036|Validation MAE 3.4314938376009945\n",
      "Epochs 406/500: \n",
      "Training cost 9.971219393059899|Validation cost 14.192536166859705\n",
      "Training MAE 3.145127928726661|Validation MAE 3.4313410841455263\n",
      "Epochs 407/500: \n",
      "Training cost 9.970335161833802|Validation cost 14.191464588940441\n",
      "Training MAE 3.1450403400298197|Validation MAE 3.431189050966988\n",
      "Epochs 408/500: \n",
      "Training cost 9.969455617045872|Validation cost 14.190401638224401\n",
      "Training MAE 3.1449527506150936|Validation MAE 3.4310377368530176\n",
      "Epochs 409/500: \n",
      "Training cost 9.968580724003612|Validation cost 14.189347251348238\n",
      "Training MAE 3.1448651629800337|Validation MAE 3.43088714055883\n",
      "Epochs 410/500: \n",
      "Training cost 9.967710448415888|Validation cost 14.188301365548707\n",
      "Training MAE 3.1447775795836908|Validation MAE 3.430737260807983\n",
      "Epochs 411/500: \n",
      "Training cost 9.966844756386394|Validation cost 14.187263918654489\n",
      "Training MAE 3.1446900028471307|Validation MAE 3.4305880962931137\n",
      "Epochs 412/500: \n",
      "Training cost 9.965983614407278|Validation cost 14.186234849078142\n",
      "Training MAE 3.144602435153946|Validation MAE 3.4304396456766835\n",
      "Epochs 413/500: \n",
      "Training cost 9.96512698935285|Validation cost 14.185214095808231\n",
      "Training MAE 3.1445148788507677|Validation MAE 3.430291907591688\n",
      "Epochs 414/500: \n",
      "Training cost 9.964274848473426|Validation cost 14.184201598401573\n",
      "Training MAE 3.1444273362477504|Validation MAE 3.4301448806423696\n",
      "Epochs 415/500: \n",
      "Training cost 9.96342715938931|Validation cost 14.183197296975615\n",
      "Training MAE 3.1443398096190753|Validation MAE 3.429998563404911\n",
      "Epochs 416/500: \n",
      "Training cost 9.962583890084854|Validation cost 14.18220113220097\n",
      "Training MAE 3.1442523012034336|Validation MAE 3.4298529544281204\n",
      "Epochs 417/500: \n",
      "Training cost 9.961745008902668|Validation cost 14.181213045294074\n",
      "Training MAE 3.1441648132044993|Validation MAE 3.429708052234101\n",
      "Epochs 418/500: \n",
      "Training cost 9.960910484537907|Validation cost 14.180232978009983\n",
      "Training MAE 3.144077347791407|Validation MAE 3.4295638553189103\n",
      "Epochs 419/500: \n",
      "Training cost 9.9600802860327|Validation cost 14.179260872635252\n",
      "Training MAE 3.1439899070992143|Validation MAE 3.429420362153206\n",
      "Epochs 420/500: \n",
      "Training cost 9.959254382770647|Validation cost 14.178296671981034\n",
      "Training MAE 3.143902493229359|Validation MAE 3.4292775711828893\n",
      "Epochs 421/500: \n",
      "Training cost 9.958432744471468|Validation cost 14.177340319376183\n",
      "Training MAE 3.1438151082501204|Validation MAE 3.429135480829725\n",
      "Epochs 422/500: \n",
      "Training cost 9.957615341185711|Validation cost 14.176391758660575\n",
      "Training MAE 3.143727754197059|Validation MAE 3.428994089491955\n",
      "Epochs 423/500: \n",
      "Training cost 9.956802143289575|Validation cost 14.175450934178484\n",
      "Training MAE 3.1436457224427077|Validation MAE 3.4288565360460637\n",
      "Epochs 424/500: \n",
      "Training cost 9.955993121479837|Validation cost 14.174517790772114\n",
      "Training MAE 3.1435659590415996|Validation MAE 3.4287224850214817\n",
      "Epochs 425/500: \n",
      "Training cost 9.955188246768872|Validation cost 14.173592273775217\n",
      "Training MAE 3.143486204487763|Validation MAE 3.4285890791418314\n",
      "Epochs 426/500: \n",
      "Training cost 9.954387490479759|Validation cost 14.172674329006808\n",
      "Training MAE 3.1434064607749854|Validation MAE 3.428456317282242\n",
      "Epochs 427/500: \n",
      "Training cost 9.95359082424149|Validation cost 14.171763902765054\n",
      "Training MAE 3.1433267298666685|Validation MAE 3.4283241982898005\n",
      "Epochs 428/500: \n",
      "Training cost 9.95279821998425|Validation cost 14.170860941821179\n",
      "Training MAE 3.143247013696231|Validation MAE 3.4281927209842027\n",
      "Epochs 429/500: \n",
      "Training cost 9.952009649934821|Validation cost 14.169965393413552\n",
      "Training MAE 3.1431673141675076|Validation MAE 3.428061884158403\n",
      "Epochs 430/500: \n",
      "Training cost 9.951225086612032|Validation cost 14.169077205241816\n",
      "Training MAE 3.1430876331551403|Validation MAE 3.4279316865792424\n",
      "Epochs 431/500: \n",
      "Training cost 9.950444502822315|Validation cost 14.168196325461148\n",
      "Training MAE 3.1430079725049747|Validation MAE 3.427802126988077\n",
      "Epochs 432/500: \n",
      "Training cost 9.949667871655342|Validation cost 14.167322702676623\n",
      "Training MAE 3.1429283340344307|Validation MAE 3.4276732041013895\n",
      "Epochs 433/500: \n",
      "Training cost 9.948895166479739|Validation cost 14.166456285937649\n",
      "Training MAE 3.1428487195328914|Validation MAE 3.427544916611389\n",
      "Epochs 434/500: \n",
      "Training cost 9.948126360938886|Validation cost 14.165597024732504\n",
      "Training MAE 3.1427691307620704|Validation MAE 3.4274172631866056\n",
      "Epochs 435/500: \n",
      "Training cost 9.947361428946783|Validation cost 14.164744868982977\n",
      "Training MAE 3.142689569456382|Validation MAE 3.4272902424724667\n",
      "Epochs 436/500: \n",
      "Training cost 9.946600344684008|Validation cost 14.163899769039087\n",
      "Training MAE 3.1426100373233017|Validation MAE 3.427163853091872\n",
      "Epochs 437/500: \n",
      "Training cost 9.945843082593736|Validation cost 14.163061675673893\n",
      "Training MAE 3.1425305360437283|Validation MAE 3.427038093645753\n",
      "Epochs 438/500: \n",
      "Training cost 9.945089617377834|Validation cost 14.16223054007838\n",
      "Training MAE 3.1424510672723334|Validation MAE 3.426912962713627\n",
      "Epochs 439/500: \n",
      "Training cost 9.94433992399304|Validation cost 14.161406313856444\n",
      "Training MAE 3.142372698500761|Validation MAE 3.426788804285235\n",
      "Epochs 440/500: \n",
      "Training cost 9.943593977647186|Validation cost 14.160588949019976\n",
      "Training MAE 3.1422988941172583|Validation MAE 3.426666951028671\n",
      "Epochs 441/500: \n",
      "Training cost 9.94285175379553|Validation cost 14.15977839798397\n",
      "Training MAE 3.1422251064313342|Validation MAE 3.426545724442942\n",
      "Epochs 442/500: \n",
      "Training cost 9.942113228137107|Validation cost 14.158974613561774\n",
      "Training MAE 3.142151337156733|Validation MAE 3.426425122912228\n",
      "Epochs 443/500: \n",
      "Training cost 9.941378376611187|Validation cost 14.158177548960369\n",
      "Training MAE 3.1420775879809617|Validation MAE 3.4263051448038033\n",
      "Epochs 444/500: \n",
      "Training cost 9.940647175393769|Validation cost 14.157387157775776\n",
      "Training MAE 3.142003860565636|Validation MAE 3.4261857884685\n",
      "Epochs 445/500: \n",
      "Training cost 9.939919600894171|Validation cost 14.156603393988485\n",
      "Training MAE 3.141930156546824|Validation MAE 3.4260670522411663\n",
      "Epochs 446/500: \n",
      "Training cost 9.939195629751637|Validation cost 14.155826211958981\n",
      "Training MAE 3.141856477535378|Validation MAE 3.4259489344411094\n",
      "Epochs 447/500: \n",
      "Training cost 9.938475238832043|Validation cost 14.155055566423362\n",
      "Training MAE 3.14178282511727|Validation MAE 3.425831433372539\n",
      "Epochs 448/500: \n",
      "Training cost 9.937758405224654|Validation cost 14.154291412488995\n",
      "Training MAE 3.1417092008539176|Validation MAE 3.425714547325002\n",
      "Epochs 449/500: \n",
      "Training cost 9.937045106238926|Validation cost 14.153533705630247\n",
      "Training MAE 3.1416356062825073|Validation MAE 3.425598274573804\n",
      "Epochs 450/500: \n",
      "Training cost 9.936335319401378|Validation cost 14.152782401684304\n",
      "Training MAE 3.1415620429163154|Validation MAE 3.4254826133804275\n",
      "Epochs 451/500: \n",
      "Training cost 9.93562902245251|Validation cost 14.15203745684704\n",
      "Training MAE 3.141488512245022|Validation MAE 3.425367561992941\n",
      "Epochs 452/500: \n",
      "Training cost 9.934926193343799|Validation cost 14.151298827668949\n",
      "Training MAE 3.141415015735023|Validation MAE 3.4252531186464066\n",
      "Epochs 453/500: \n",
      "Training cost 9.934226810234716|Validation cost 14.150566471051164\n",
      "Training MAE 3.141341554829735|Validation MAE 3.4251392815632684\n",
      "Epochs 454/500: \n",
      "Training cost 9.933530851489813|Validation cost 14.149840344241484\n",
      "Training MAE 3.1412681309498995|Validation MAE 3.4250260489537463\n",
      "Epochs 455/500: \n",
      "Training cost 9.932838295675875|Validation cost 14.149120404830544\n",
      "Training MAE 3.1411947454938796|Validation MAE 3.4249134190162156\n",
      "Epochs 456/500: \n",
      "Training cost 9.932149121559098|Validation cost 14.148406610747983\n",
      "Training MAE 3.1411213998379632|Validation MAE 3.4248013899375853\n",
      "Epochs 457/500: \n",
      "Training cost 9.931463308102323|Validation cost 14.147698920258671\n",
      "Training MAE 3.14104809533664|Validation MAE 3.4246899598936618\n",
      "Epochs 458/500: \n",
      "Training cost 9.930780834462336|Validation cost 14.146997291959044\n",
      "Training MAE 3.1409748333229017|Validation MAE 3.4245791270495136\n",
      "Epochs 459/500: \n",
      "Training cost 9.93010167998719|Validation cost 14.146301684773444\n",
      "Training MAE 3.1409016151085223|Validation MAE 3.424468889559824\n",
      "Epochs 460/500: \n",
      "Training cost 9.929425824213606|Validation cost 14.145612057950542\n",
      "Training MAE 3.1408284419843335|Validation MAE 3.424359245569244\n",
      "Epochs 461/500: \n",
      "Training cost 9.928753246864373|Validation cost 14.144928371059807\n",
      "Training MAE 3.1407553152205048|Validation MAE 3.424253165037353\n",
      "Epochs 462/500: \n",
      "Training cost 9.928083927845849|Validation cost 14.14425058398804\n",
      "Training MAE 3.1406822360668176|Validation MAE 3.424173407151828\n",
      "Epochs 463/500: \n",
      "Training cost 9.92741784724546|Validation cost 14.14357865693593\n",
      "Training MAE 3.1406092057529302|Validation MAE 3.4240941437531967\n",
      "Epochs 464/500: \n",
      "Training cost 9.926754985329264|Validation cost 14.142912550414696\n",
      "Training MAE 3.1405362254886486|Validation MAE 3.4240153733420566\n",
      "Epochs 465/500: \n",
      "Training cost 9.92609532253956|Validation cost 14.142252225242785\n",
      "Training MAE 3.1404632964641843|Validation MAE 3.4239370944085907\n",
      "Epochs 466/500: \n",
      "Training cost 9.925438839492529|Validation cost 14.141597642542559\n",
      "Training MAE 3.1403904198504167|Validation MAE 3.423859305432885\n",
      "Epochs 467/500: \n",
      "Training cost 9.924785516975911|Validation cost 14.140948763737121\n",
      "Training MAE 3.140317596799144|Validation MAE 3.423782004885243\n",
      "Epochs 468/500: \n",
      "Training cost 9.924135335946742|Validation cost 14.1403055505471\n",
      "Training MAE 3.140244828443342|Validation MAE 3.423705191226495\n",
      "Epochs 469/500: \n",
      "Training cost 9.923488277529113|Validation cost 14.13966796498755\n",
      "Training MAE 3.1401721158974074|Validation MAE 3.4236288629083007\n",
      "Epochs 470/500: \n",
      "Training cost 9.922844323011969|Validation cost 14.139035969364862\n",
      "Training MAE 3.1400994602574066|Validation MAE 3.4235541042800195\n",
      "Epochs 471/500: \n",
      "Training cost 9.922203453846963|Validation cost 14.138409526273733\n",
      "Training MAE 3.1400268626013155|Validation MAE 3.4234816170582056\n",
      "Epochs 472/500: \n",
      "Training cost 9.921565651646306|Validation cost 14.137788598594156\n",
      "Training MAE 3.139954323989263|Validation MAE 3.423409646555629\n",
      "Epochs 473/500: \n",
      "Training cost 9.920930898180712|Validation cost 14.137173149488502\n",
      "Training MAE 3.139881845463764|Validation MAE 3.423338190734715\n",
      "Epochs 474/500: \n",
      "Training cost 9.920299175377329|Validation cost 14.136563142398602\n",
      "Training MAE 3.1398094280499547|Validation MAE 3.423267247554667\n",
      "Epochs 475/500: \n",
      "Training cost 9.919670465317719|Validation cost 14.135958541042864\n",
      "Training MAE 3.13973707275582|Validation MAE 3.4231968149716914\n",
      "Epochs 476/500: \n",
      "Training cost 9.919044750235896|Validation cost 14.135359309413502\n",
      "Training MAE 3.139664780572424|Validation MAE 3.423126890939226\n",
      "Epochs 477/500: \n",
      "Training cost 9.918422012516354|Validation cost 14.134765411773701\n",
      "Training MAE 3.1395925524741335|Validation MAE 3.423057473408157\n",
      "Epochs 478/500: \n",
      "Training cost 9.91780223469216|Validation cost 14.134176812654903\n",
      "Training MAE 3.1395203894188386|Validation MAE 3.422988560327037\n",
      "Epochs 479/500: \n",
      "Training cost 9.917185399443083|Validation cost 14.13359347685411\n",
      "Training MAE 3.1394482923481712|Validation MAE 3.4229201496422994\n",
      "Epochs 480/500: \n",
      "Training cost 9.916571489593716|Validation cost 14.133015369431208\n",
      "Training MAE 3.1393762621877235|Validation MAE 3.4228522392984635\n",
      "Epochs 481/500: \n",
      "Training cost 9.91596048811168|Validation cost 14.132442455706341\n",
      "Training MAE 3.1393042998472556|Validation MAE 3.42278482723834\n",
      "Epochs 482/500: \n",
      "Training cost 9.915352378105819|Validation cost 14.131874701257335\n",
      "Training MAE 3.1392324062209123|Validation MAE 3.422717911403234\n",
      "Epochs 483/500: \n",
      "Training cost 9.914747142824446|Validation cost 14.131312071917128\n",
      "Training MAE 3.1391605821874267|Validation MAE 3.422651489733134\n",
      "Epochs 484/500: \n",
      "Training cost 9.914144765653596|Validation cost 14.130754533771267\n",
      "Training MAE 3.1390888286103245|Validation MAE 3.422585560166913\n",
      "Epochs 485/500: \n",
      "Training cost 9.913545230115352|Validation cost 14.130202053155411\n",
      "Training MAE 3.1390171463381287|Validation MAE 3.422552561365328\n",
      "Epochs 486/500: \n",
      "Training cost 9.91294851986614|Validation cost 14.129654596652898\n",
      "Training MAE 3.138945536204559|Validation MAE 3.4225320049696784\n",
      "Epochs 487/500: \n",
      "Training cost 9.912354618695097|Validation cost 14.129112131092327\n",
      "Training MAE 3.138873999028727|Validation MAE 3.4225117803303884\n",
      "Epochs 488/500: \n",
      "Training cost 9.911763510522453|Validation cost 14.128574623545164\n",
      "Training MAE 3.138802535615333|Validation MAE 3.422491886188158\n",
      "Epochs 489/500: \n",
      "Training cost 9.91117517939792|Validation cost 14.128042041323413\n",
      "Training MAE 3.1387311467548553|Validation MAE 3.4224723212770956\n",
      "Epochs 490/500: \n",
      "Training cost 9.910589609499151|Validation cost 14.12751435197728\n",
      "Training MAE 3.138659833223742|Validation MAE 3.422453084324955\n",
      "Epochs 491/500: \n",
      "Training cost 9.910006785130172|Validation cost 14.126991523292908\n",
      "Training MAE 3.1385885957846007|Validation MAE 3.422434174053363\n",
      "Epochs 492/500: \n",
      "Training cost 9.90942669071988|Validation cost 14.126473523290105\n",
      "Training MAE 3.1385174351863747|Validation MAE 3.422415589178047\n",
      "Epochs 493/500: \n",
      "Training cost 9.908849310820536|Validation cost 14.125960320220132\n",
      "Training MAE 3.138446352164536|Validation MAE 3.422397328409057\n",
      "Epochs 494/500: \n",
      "Training cost 9.908274630106323|Validation cost 14.125451882563485\n",
      "Training MAE 3.1383753474412575|Validation MAE 3.4223793904509803\n",
      "Epochs 495/500: \n",
      "Training cost 9.90770263337187|Validation cost 14.124948179027768\n",
      "Training MAE 3.1383044217255947|Validation MAE 3.422361774003167\n",
      "Epochs 496/500: \n",
      "Training cost 9.907133305530849|Validation cost 14.124449178545536\n",
      "Training MAE 3.138233575713658|Validation MAE 3.4223444777599257\n",
      "Epochs 497/500: \n",
      "Training cost 9.90656663161457|Validation cost 14.12395485027218\n",
      "Training MAE 3.138168870116582|Validation MAE 3.4223275004107414\n",
      "Epochs 498/500: \n",
      "Training cost 9.906002596770607|Validation cost 14.123465163583841\n",
      "Training MAE 3.138105352050519|Validation MAE 3.4223108406404736\n",
      "Epochs 499/500: \n",
      "Training cost 9.905441186261436|Validation cost 14.12298008807539\n",
      "Training MAE 3.1380418968932164|Validation MAE 3.4222944971295606\n",
      "Epochs 500/500: \n",
      "Training cost 9.904882385463118|Validation cost 14.122499593558384\n",
      "Training MAE 3.1379785053755973|Validation MAE 3.422278468554208\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_regression_model(X_train,y_train,X_val,y_val,0.4,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's compare accuracy of our model with LR model from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = linear_model.LinearRegression()\n",
    "model = linear_regression.fit(X_train.T, y_train.T)\n",
    "predictions = linear_regression.predict(X_val.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE_val_with_sklearn = (1/y_val.shape[1])*np.sum(np.abs(predictions-y_val.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4550349322483527"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE_val_with_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
